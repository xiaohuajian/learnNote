*写在前面的思考？**

这门课连接了计算机组成原理、Linux 基础、其他各种编程语言的基础。它的下一级是计算机组成原理，对上其他的各种应用软件、编程语言，而各种编程语言的实现也是基于操作系统的，所以明白了最底层的操作系统，在来反过来理解编程语言，就会发现他们大同小异，或多或少都有操作系统的影子，包括思想、设计、概念。举例来说，操作系统讲进程调度，那对应的编程语言肯定也会涉及到这个东西，比如说线程的调度，而且线程中的中断，会对应到进程，甚至对应到计算机组成原理中讲的硬件中断，在到微机层面的中断，到数电模电的中断，你就会发现这一些列的东西原理如此，他们的之间的关系是这样的，就会发现大学里面的课程都是有其意义的，只不过明白了有点晚，哈哈。学东西，如果您能够高屋建瓴、俯视而下，系统综合的看待这门学科，把其和其他的东西练习起来，形成一个系统，这个系统就我讲的就是整个计算机领域，这样你就会豁然开朗，一往无前。

# 第一章 概述与引论

- 操作系统的概念、特征、功能和提供的服务
- 操作系统的发展与分类
- 运行环境：内核态与用户态：中断、异常、系统调用
- 体系结构

![image-20200925232140076](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj3b5qv1dyj313e0e6gux.jpg)

体系结构图：如上



## 发展历程

1. 人工处理：人工把带孔的纸带装入纸带机，进行输入

2. 脱机处理：用机器控制纸带的输入，而不是人工，提升输入效率；

3. 单道批处理：用晶体管替代真空管；**把一批作业以脱机方式输入到磁带上，并在系统中配上监督程序(Monitor)，使得作业能够持续进行，进一步提升效率，解决人机速度不匹配问题**——标志操作系统的出现

4. 多道批处理：集成电路替代单个晶体管；在单道批处理系统中，内存中仅有一道作业，系统资源利用不充分，引入多道处理，**同时在内存中装有若干道程序，并使它们交替地运行，当正在运行的程序因 I/O 而暂停执行时，系统可调度另一道程序运行**，从而保持了 CPU 处于忙碌状态；**实现作业自动控制无需人工干预，实现批处理的**

   > 其实这里，我们是不是可以知道为啥会有锁、资源共享的概念？因为在物理世界中不可能有两个物体同时占有一个东西，对应到计算机里面也是一样的，然而，由于计算机的处理和转换的速度很快，所以这时候可以在一段时间内，表现“共享”的现象，但本质仍然是来回切换独占，不过这个时间很短，就称之为一段时间内共享了。

5. 分时系统：把处理器运行时间分成很短的时间片，时间片轮流把处理器分给某个程序；将一台主机提供给多个用户同时使用，提高计算机的利用率；**分时系统是解决人机交互性的**

   - 多路性：一台主机上同时联接多台联机终端，系统按分时原则为每个用户服 

     务

   - 独立性：每个用户各占一个终端，彼此独立操作，互不干扰

   - 及时性：用户的请求能在很短的时间内获得响应

   - 交互性：用户可通过终端与系统进行广泛的人机对话

6. 实时系统：所谓“实时”，是表示“及时”，而实时系统(Real Time System)是指系统能及时(或即时)

   响应外部事件的请求，在规定的时间内完成对该事件的处理

   实时系统和分时系统有类似的特性，但他更强调了可靠性。

7. 微机时代：

   1. 单用户单任务

   2. 单用户多任务：单用户多任务操作系统的含义是，只允许一个用户上机，但允许用户把程序分为若干 

      个任务，使它们并发执行，从而有效地改善了系统的性能

   3. 多用户多任务：允许多个用户通过各自的终端使用同一台机器，共享主机系统中的各种资源，而每个用户程序又可进一步分为几个任务，使它们能并发执行

## 特征

1. **并发**

   系统从单人单任务——单人多任务——多人任务；从单任务到多任务就是并发（一段时间内，执行多个程序）

   > 并发（一段时间内，执行多个程序）;并行——同一时间，执行多个程序

   **引入进程**

   **进程是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆 栈等组成的，是一个能独立运行的活动实体。** 目的是为了并行执行程序，提升效率（提升的本质是有效的利用了计算机资源）。

   > 在操作系统中引入进程的目的，就是为了使多个 程序能并发执行。例如，在一个未引入进程的系统中，在属于同一个应用程序的计算程序 和 I/O 程序之间，两者只能是顺序执行，即只有在计算程序执行告一段落后，才允许 I/O 程 序执行；反之，在程序执行 I/O 操作时，计算程序也不能执行，这意味着处理机处于空闲状 态，这样就浪费了cpu资源。或者可以一边读取内存数据，一边用cpu进行处理，这样也可以提升效率。因为读取数据不需要cpu的参与，相当于我们可以实时的利用两种计算机资源。

   **引入线程**

   长期以来，进程都是操作系统中可以拥有资源并作为独立运行的基本单位。当一个进程因故不能继续运行时，操作系统便调度另一进程运行。由于进程拥有自己的资源，故使调度付出的开销较大；所以用线程来调度。通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源；==通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度 的基本单位==。由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多。

2. **共享**

   1. 互斥：就是编程概念上对某个资源上锁，线程独占的意思。在应用程序上就是进程独占；
   2. 同时访问：这里的“同时”指的一段时间内多个进程同时访问，同时是宏观概念上的，在微观上仍然是交替进行的。

3. **虚拟**

   虚拟指的是把物理上的实体变为若干逻辑上对应物；比如多处理器，虚拟多个cpu；虚拟多个终端设备；

   1．时分复用技术

   时分复用，亦即分时使用方式，它最早用于电信业中。为了提高信道的利用率，人们利用时分复用方式，将一条物理信道虚拟为多条逻辑信道，将每条信道供一对用户通话。我们在计算机网络原理中 看到了这个名词；比如说有多个进程，但只有一个cpu，一个cpu为多个进程服务，就是一种在时间上的复用。

   2. 空分复用技术

      电信业中就使用频分复用技术来提高信道的利用率。它是将一个频率 范围非常宽的信道，划分成多个频率范围较窄的信道，其中的任何一个频带都只供一对用户通话。早期的频分复用只能将一条物理信道划分为十几条到几十条话路，后来又很快发 展成上万条话路，每条话路也只供一对用户通话。之后，在计算机中也使用了空分复用技 术来提高存储空间的利用率。

      1) 虚拟磁盘技术：将一台硬盘虚拟为多台虚拟磁盘，

4. **异步**

   多道环境允许多个程序（进程）并发执行，由于资源有限，进程执行并不是一贯到底的，是走走停停的；

## 操作系统作用

操作系统管理计算机的资源（处理器cpu、存储器——内存、IO——设备、文件），连接硬件和软件的桥梁。会对 处理器管理、存储器管理、设备管理、文件管理；方便用户操作系统，还必须提供用户接口。

![image-20200925234100103](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj3bpsbkd8j30e808udgh.jpg)



### 处理机管理

在传统的多道程序系统中，处理机的分配和运行都是以进程为基本单位，因而对处理机的管理可归结为对进程的管理；在引入了线程OS 中，也包含对线程的管理。处理机管理的主要功能是创建和撤消进程(线程)，对诸进程(线程)的运行进行协调，实现进程(线程)之间的信息交换，以及按照一定的算法把处理机分配给进程(线程)。

#### 1 进程控制

创建、撤销进程，同时包含进程内的线程。

#### 2 进程同步

进程是以异步方式运行的，并以人们不可预知的速度向前推进。为使多个进程能有条不紊地运行，系统中必须设置进程同步机制。进程同步的主要任务是为多个进程(含线程)的运行进行协调。有两种协调方式：

(1) 进程互斥方式。这是指诸进程(线程)在对临界资源进行访问时，应采用互斥方式；

(2) 进程同步方式。这是指在相互合作去完成共同任务的诸进程(线程)间，由同步机构对它们的执行次序加以协调。

实现进程同步，必须有相应的同步机制，比如说锁机制，对共享资源访问时，用锁来控制谁该访问，其内部原理是信号量机制。

#### 3 进程通信

一个任务往往需要多个进程进行配合完成，这时候涉及到进程通信，IPC、binder；看到这里来是不是很熟悉，android里这些都有，因为android也是一个操作系统 

#### 4  调度

在后备队列上等待的每个作业都需经过调度才能执行。在传统的操作系统中，包括作业调度和进程调度两步。 

(1) **作业调度**。作业调度的基本任务是从后备队列中按照一定的算法，选择出若干个 作业，为它们分配运行所需的资源(首先是分配内存)。在将它们调入内存后，便分别为它们建立进程，使它们都成为可能获得处理机的就绪进程，并按照一定的算法将它们插入就 绪队列。

(2) **进程调度。**进程调度的任务是从进程的就绪队列中，按照一定的算法选出一个进程，把处理机分配给它，并为它设置运行现场，使进程投入执行。值得提出的是，在多线程 OS中，通常是把线程作为独立运行和分配处理机的基本单位，为此，须把就绪线程排成一个队列，每次调度时，是从就绪线程队列中选出一个线程，把处理机分配给它。 

### 存储器管理（内存管理）

存储器管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以及能从逻辑上扩充内存。为此，存储器管理应具有内存分配、内存保护、地址映射和内存扩充等功能。

#### 1 内存分配

内存分配的主要任务是为每道程序分配内存空间，使它们“各得其所”；提高存储器的利用率，以减少不可用的内存空间；允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。

#### 2 内存保护

内存保护的主要任务是确保每道用户程序都只在自己的内存空间内运行，彼此互不干 扰；绝不允许用户程序访问操作系统的程序和数据；也不允许用户程序转移到非共享的其 它用户程序中去执行。

> 内存保护和OOM异常有联系的，我们OOM就是因为内存不够，越界了导致发生了OOM。

#### 3 地址映射

一个应用程序(源程序)经编译后，通常会形成若干个目标程序；这些目标程序再经过链接便形成了可装入程序。这些程序的地址都是从“0”开始的，程序中的其它地址都是相对于起始地址计算的。**由这些地址所形成的地址范围称为“地址空间”，其中的地址称为“逻辑地址”或“相对地址”；**在多道程序环境下，每道程序不可能都从“0”地址开始装入(内存)，这就致使地址空间内的逻辑地址和内存空间中的物理地址不相一致。为使程序能正确运行，存储器管理必须提供地址映射功能，以将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。该功能应在硬件的支持下完成。

#### 4 **内存扩充**

存储器管理中的内存扩充任务并非是去扩大物理内存的容量，而是借助于虚拟存储技术，从逻辑上去扩充内存容量，使用户所感觉到的内存容量比实际内存容量大得多。

(1) 请求调入功能。允许在装入一部分用户程序和数据的情况下，便能启动该程序运行。在程序运行过程中，若发现要继续运行时所需的程序和数据尚未装入内存，可向 OS 发出请求，由 OS 从磁盘中将所需部分调入内存，以便继续运行。 

(2) 置换功能。若发现在内存中已无足够的空间来装入需要调入的程序和数据时，系统应能将内存中的一部分暂时不用的程序和数据调至盘上，以腾出内存空间，然后再将所需调入的部分装入内存。

### 设备管理

用于管理计算机系统中所有的外围设备，比如鼠标、键盘、光驱、磁盘等等外设；设备管理应具有缓存管理、设备分配和设备处理以及虚拟设备等功能。

#### 1．缓冲管理

CPU 运行的高速性和 I/O 低速性间的矛盾自计算机诞生时起便已存在了。而随着 CPU速度迅速提高，使得此矛盾更为突出，严重降低了 CPU 的利用率。如果在 I/O 设备和 CPU之间引入缓冲，则可有效地缓和 CPU 与 I/O 设备速度不匹配的矛盾，提高 CPU 的利用率， 进而提高系统吞吐量。因此，在现代计算机系统中，都无一例外地在内存中设置了缓冲区，而且还可通过增加缓冲区容量的方法来改善系统的性能。

最常见的缓冲区机制有单缓冲机制、 能实现双向同时传送数据的双缓冲机制，以及能供多个设备同时使用的公用缓冲池机制。 上述这些缓冲区都将由 OS 中的缓冲管理机制将它们管理起来。

#### 2．设备分配

设备分配的基本任务是根据用户进程的 I/O 请求、系统的现有资源情况以及按照某种设 备的分配策略，为之分配其所需的设备。如果在 I/O 设备和 CPU 之间还存在着设备控制器 和 I/O 通道时，还须为分配出去的设备分配相应的控制器和通道。

为了实现设备分配，系统中应设置设备控制表、控制器控制表等数据结构，用于记录 设备及控制器的标识符和状态。根据这些表格可以了解指定设备当前是否可用，是否忙碌， 以供进行设备分配时参考。在进行设备分配时，应针对不同的设备类型而采用不同的设备 分配方式。对于独占设备(临界资源)的分配，还应考虑到该设备被分配出去后系统是否安全。 在设备使用完后，应立即由系统回收。

#### 3 设备处理

设备处理程序又称为设备驱动程​序。其基本任务是用于**实现 CPU 和设备控制器之间的通信**，即由 CPU 向设备控制器发出 I/O 命令，要求它完成指定的 I/O 操作； 

### 文件管理

人们总是把程序和数据以文件的形式存储在磁盘和磁带上，供所有的或指定的用户使用。为此，在操作系统中必须配置文件管理机构。文件管理的主要任务 是对用户文件和系统文件进行管理，以方便用户使用，并保证文件的安全性。件 管理应具有对文件存储空间的管理、目录管理、文件的读/写管理，以及文件的共享与保护 等功能。

#### 1．文件存储空间的管理

#### 2 目录管理

为了使用户能方便地在外存上找到自己所需的文件，通常由系统为每个文件建立一个 目录项。目录项包括文件名、文件属性、文件在磁盘上的物理位置等。

#### 3 文件读/写

通过读写指针进行读写

### 操作系统与用户之间接口

为了让用户调用操作系统的服务，提供了接口，分为：

(1) 用户接口。它是提供给用户使用的接口，用户可通过该接口取得操作系统的服务；

(2) 程序接口。它是提供给程序员在编程时使用的接口，是用户程序取得操作系统服务的唯一途径

#### 用户接口

- 联机用户接口 ：当用户在终端或控制台上每键入一条命令后，系统便立即转入命令解释程序，对该 命令加以解释并执行该命令。
- 脱机用户接口 ： 该接口是为批处理作业的用户提供的，故也称为批处理用户接口。 该接口由一组作业控制语言(JCL)组成。批处理作业的用户不能直接与自己的作业交互作用， 只能委托系统代替用户对作业进行控制和干预。
- 图形用户接口 ：用户虽然可以通过联机用户接口来取得 OS 的服务，但这时要求用 户能熟记各种命令的名字和格式，并严格按照规定的格式输入命令。这既不方便又花时间， 于是，另一种形式的联机用户接口——图形用户接口便应运而生。

#### 程序接口

由一组系统调用组成，每一个系统调用都是一个能完成特定功能的子程 序，每当应用程序要求 OS 提供某种服务(功能)时，便调用具有相应功能的系统调用

- 

## 运行环境

计算机中，cpu通常执行两种不同的程序，一种是操作系统的内核程序，一种是用户自编程序。前者是后者的管理者，因此内核程序需要执行一些特权指令，而用户程序出于安全考虑其不能执行这些指令，比如IO指令、中断指令、存取寄存器等。我们可以理解为 cpu内部有一个开关，小开关为1 时，cpu处于核心态，可以执行特权指令，为0时，为用户态，不能执行。当然，操作系统运行在内核态，用户程序运行在用户态。

## 微内核

微内核(Micro Kernel)操作系统结构：微内核和多个服务器。微内核只提供基本的功能，把其他的非核心的功能用服务的形式提供，这样的做法目的保证os 灵活、易维护、可扩展。一般有以下特点：

1. 足够小的内核

2. 基于客户/服务器模式：**操作系统中最基本的部分放入内核中，而把操作系统的绝大部 分功能都放在微内核外面的一组服务器(进程)中实现**。例如用于提供对进程(线程)进行管理的进程(线程)服务器，提供虚拟存储器管理功能的虚拟存储器服务器，提供 I/O 设备管理的 I/O 设备管理服务器等，它们都是被作为进程来实现的，运行在用户态，客户与服务器之 间是借助微内核提供的消息传递机制来实现信息交互的。

   ![image-20200929224012349](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj7wft156jj30uw06gmy6.jpg)

3. 应用“机制与策略分离”原理

   所谓机制，是指实现某一功能的具体执行机构。而策略，则是在机制的基础上，借助于某 些参数和算法来实现该功能的优化，或达到不同的功能目标。通常，机制处于一个系统的 基层，而策略则处于系统的高层。在传统的 OS 中，将机制放在 OS 的内核的较低层，把策 略放在内核的较高层次中。而在微内核操作系统中，通常将机制放在 OS 的微内核中。正因 为如此，才有可能将内核做得很小。

4. 采用面向对象技术：这样便于程序的编写

### 微内核缺点

由于客户对 OS 提出的服务请求时，需要利用消息 实现多次交互和进行用户/内核模式及上下文的多次切换，频繁的状态（用户/内核态）切换导致效率低下。

> 在早期的 OS 中，用户进 程在请求取得 OS 服务时，一般只需进行两次上下文的切换：一次是在执行系统调用后，由 用户态转向系统态时；另一次是在系统完成用户请求的服务后，由系统态返回用户态时。 在微内核 OS 中，由于客户和服务器及服务器和服务器之间的通信，都需通过微内核，致使 同样的服务请求至少需要进行四次上下文切换。第一次是发生在客户发送请求消息给内核， 以请求取得某服务器特定的服务时；第二次是发生在由内核把客户的请求消息发往服务器 时；第三次是当服务器完成客户请求后，把响应消息发送到内核时；第四次是在内核将响 应消息发送给客户时。

![image-20200929224455196](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj7wkqzv8sj31080u01ky.jpg)

# 第二章 进程描述与控制

本章节重点：

- 进程和线程
  - 进程的概念与状态转换
  - 进程控制与管理
  - 进程通信：线程概念与多线程
- 处理机调度
  - 调度的概念、时机、切换
  - 调度基本准则、方式
- 进程同步
  - 信号量、管程，经典同步问题
  - 临界资源互斥
- 死锁
  - 概念、处理方法
  - 死锁预防、处理、检测

![image-20201014101050085](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjon2o27hdj30nh0cawm1.jpg)



## 2.1 前趋图和程序执行

### 2.1.1 前趋图

### 2.1.2 顺序执行

- 顺序性：处理机的操作严格按照程序所规定的顺序执行
- 封闭性：程序运行时独占全机资源，资源的状态(除初始状态外)只有本程序才能改变它。程序一旦开始执行，其执行结果不受外界因素影响
- 可再现性：只要程序执行时的环境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿地执行，还是“停停走走”地执行，都将获得相同的结果

### 2.1.3 并发执行

- 间断性：由于有多个程序在同一段时间执行，可能多个程序之间要相互协作，依赖，所以程序可能要等待其他程序，所以出现间断。
- 非封闭性：对比上面
- 不可再现性：对比上面

## 2.2 进程定义与特征

在多道程序环境下，程序的执行属于并发执行，此时它们将失去其封闭性，并具有间断性及不可再现性的特征。为了对并发执行的程序加以描述和控制，引入**进程**概念：

**进程 = 程序program + 数据 data + 进程控制块PCB（Process Control Block）** 

> 通常的程序是不能并发执行的。为使程序(含数据)能独立运行，应为之配置一进程控制块，即 PCB(Process Control Block)；而由程**序段、相关的数据段和 PCB 三部分便构成了进程实体**。在早期的 UNIX 版本中，把这三部分总称为“进程映像”。值得指出的是，在许多情况下所说的进程，实际上是指进程实体，例如，所谓创建进程，实质上是创建进程实体中的 PCB；而撤消进程，实质上是撤消进程的 PCB。

**「进程」**：是程序的一次执行，动态的；

**「程序」**：一组有序指令的集合，并存放于某种介质上，其本身并不具有运动的含义，因而是静态的；



下面说几个结论：

**(1) 进程是程序的一次执行。**

**(2) 进程是一个程序及其数据在处理机上顺序执行时所发生的活动。** 

**(3) 进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。**

### 进程控制块PCB

#### 作用：

1. 为了描述和控制进程的运行，系统为每个进程定义了一个数据结构——进程控制块 PCB(Process Control Block)，它是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB 中记录了操作系统所需的、用于描述进程的当前情况以及控制进程运行的全部信息。

2. 使一个在多道程序环境下不能独立运行的程序(含数据)，成为一个能独立运行的基本单位，一个能与其它进程并发执行的进程。或者说，OS 是根据 PCB 来对并发执行的进程进行控制和管理的。

> 当 OS 要调度某进程执行时，要从该进程的 PCB中查出其现行状态及优先级；在调度到某进程后，要根据其 PCB 中所保存的处理机状态信息，设置该进程恢复运行的现场，并根据其 PCB 中的程序和数据的内存始址，找到其程序和数据；进程在执行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也都需要访问 PCB；当进程由于某种原因而暂停执行时，又须将其断点的处理机环境保存在 PCB .

#### 信息

1) 进程标识符：自己id，父id，子id等等；

2) 处理机状态 

由处理机的各种寄存器中的内容组成的。处理机在运行时，许多信息都放在寄存器中。当处理机被中断时，所有这些信息都必须保存在 PCB 中，以便在该进程重新执行时，能从断点继续执行。

3) 进程调度信息

在 PCB 中还存放一些与进程调度和进程对换有关的信息，包括：① 进程状态，指明进程的当前状态，作为进程调度和对换时的依据；② 进程优先级，用于描述进程使用处理机的优先级别的一个整数，优先级高的进程应优先获得处理机；③ 进程调度所需的其它信息，它们与所采用的进程调度算法有关，比如，进程已等待 CPU 的时间总和、进程已执行的时间总和等；④ 事件，指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。

4) 进程控制信息

进程控制信息包括：① 程序和数据的地址，指进程的程序和数据所在的内存或外存地(首)址，以便再调度到该进程执行时，能从 PCB 中找到其程序和数据；② 进程同步和通信机制，指实现进程同步和进程通信时必需的机制，如消息队列指针、信号量等，它们可能 全部或部分地放在 PCB 中；③ 资源清单，即一张列出了除 CPU 以外的、进程所需的全部资源及已经分配到该进程的资源的清单；④ 链接指针，它给出了本进程(PCB)所在队列中的下一个进程的 PCB 的首地址。

###  进程管理中的数据结构

![image-20201014102223550](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjonep2qakj30fc0da76z.jpg)

计算机对各类资源进行抽象为各种数据结构，然后用表记录，这些包含内存、设备、文件、进程（多个进程）。

## 2.3 进程状态及转换

因为进程具有间断性，所以进程会处于不同的状态，下面探讨进程状态：

### 2.3.1 进程两状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnie8gs2vj30v40n447t.jpg" alt="进程2状态图" style="zoom:67%;" />

Running：进程获取cpu资源正在执行；

Not Running：非执行的进程就是Not Running；未执行的状态有可以分为阻塞和就绪状态。

如果展开来说非执行状态，其图例为：

![image-20201013105232980](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjninrkuxqj309q084aal.jpg)

**1) 就绪(Ready)状态**

当进程已分配到除 CPU 以外的所有必要资源后，只要再获得 CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。 

**2) 阻塞状态**

正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态， 亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求 I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。

> 阻塞状态是不能直接到运行态的，某个进程由于I/O 处于阻塞态，然后当事件发生获取到I/O资源后，此时进程需要先进入就绪队列，等待操作系统调度，当他被选中后，才能被执行

#### 进程阻塞与唤醒

##### 进程阻塞

正在执行的进程，当发现上述某事件时，由于无法继续执行，于是进程便通过调用阻塞原语 block 把自己阻塞。可见，进程的阻塞是进程自身的一种主动行为。进入 block 过程后，由于此时该进程还处于执行状态，所以应先立即停止执行，把进程控制块中的现行状 态由“执行”改为“阻塞”，并将 PCB 插入阻塞队列。如果系统中设置了因不同事件而阻塞的多个阻塞队列，则应将本进程插入到具有相同事件的阻塞(等待)队列。最后，转调度程序进行重新调度，将处理机分配给另一就绪进程并进行切换，亦即，保留被阻塞进程的处理机状态(在 PCB 中)，再按新进程的 PCB 中的处理机状态设置 CPU 的环境。

##### 进程唤醒过程

当被阻塞进程所期待的事件出现时，如 I/O 完成或其所期待的数据已经到达，则由有关进程(比如用完并释放了该 I/O 设备的进程)调用唤醒原语 wakeup( )，将等待该事件的进程唤醒。唤醒原语执行的过程是：首先把被阻塞的进程从等待该事件的阻塞队列中移出，将其 PCB 中的现行状态由阻塞改为就绪，然后再将该 PCB 插入到就绪队列中。应当指出，block 原语和 wakeup 原语是一对作用刚好相反的原语。因此，如果在某进程中调用了阻塞原语，则必须在与之相合作的另一进程中或其他相关的进程中安排唤醒原 语，以能唤醒阻塞进程；否则，被阻塞进程将会因不能被唤醒而长久地处于阻塞状态，从 而再无机会继续运行。

##### 引起进程阻塞和唤醒的事件

**1) 请求系统服务**

当正在执行的进程请求操作系统提供服务时，由于某种原因，操作系统并不立即满足该进程的要求时，该进程只能转变为阻塞状态来等待。例如，一进程请求使用某资源，如打印机，由于系统已将打印机分配给其他进程而不能分配给请求进程，这时请求者进程只能被阻塞，仅在其他进程在释放出打印机的同时，才将请求进程唤醒。 

**2) 启动某种操作**

当进程启动某种操作后，如果该进程必须在该操作完成之后才能继续执行，则必须先使该进程阻塞，以等待该操作完成。例如，进程启动了某 I/O 设备，如果只有在 I/O 设备完成了指定的 I/O 操作任务后进程才能继续执行，则该进程在启动了 I/O 操作后，便自动进入阻塞状态去等待。在 I/O 操作完成后，再由中断处理程序或中断进程将该进程唤醒。 

**3) 新数据尚未到达**

对于相互合作的进程，如果其中一个进程需要先获得另一(合作)进程提供的数据后才能 对数据进行处理，则只要其所需数据尚未到达，该进程只有(等待)阻塞。例如，有两个进程，进程 A 用于输入数据，进程 B 对输入数据进行加工。假如 A 尚未将数据输入完毕，则进程B 将因没有所需的处理数据而阻塞；一旦进程 A 把数据输入完毕，便可去唤醒进程 B。 

**4) 无新工作可做**

系统往往设置一些具有某特定功能的系统进程，每当这种进程完成任务后，便把自己阻塞起来以等待新任务到来。例如，系统中的发送进程，其主要工作是发送数据，若已有 的数据已全部发送完成而又无新的发送请求，这时(发送)进程将使自己进入阻塞状态； 仅 当又有进程提出新的发送请求时，才将发送进程唤醒。



### 2.3.2 进程五状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnitbm0jij30wo0m87br.jpg" alt="进程5状态图" style="zoom:67%;" />

或者：

<img src="../../../Desktop/进程图1.png" alt="进程图1" style="zoom:67%;" />

对比两状态、三状态，发现多了创建、退出状态，而且要搞明白创建状态和就绪状态的区别；

#### **「创建状态」**

进程是由PCB 描述的，包含进程id、名称等信息，当进程有了自己的PCB后，在装入内存，进入就绪队列。这样看到进程创建分两步1 是创建PCB，2是装入内存；所以在装入内存之前都是处于创建状态，所以要搞清楚这个概念。

> 程序是在内存中执行的，由于内存资源有限，所以创建好的进程不一定都会被及时的装入内存中，这就是我们平时说的加大内存可以提升电脑速度就是这个原因，这样我们就知道了创建的状态，和就绪状态区别是后者是需要等待处理机cpu的调度，当被调度后才能执行。这里就能明白如果cpu很强大，处理速度快，电脑性能也会比较好。但是要知道如果内存不够大，cpu的处理速度超过了内存数据处理速度，这时候单单提高cpu就没有意义，内存、cpu就像一个木桶效应。

**「进程的创建(Creation of Process)」** 

一旦操作系统发现了要求创建新进程的事件后，便调用进程创建原语 Creat( )按下述步 骤创建一个新进程。

(1) 申请空白 PCB。为新进程申请获得惟一的数字标识符，并从 PCB 集合中索取一个空白 PCB。 

(2) 为新进程分配资源。为新进程的程序和数据以及用户栈分配必要的内存空间。显然，此时操作系统必须知道新进程所需内存的大小。

(3) 初始化进程控制块。PCB 的初始化包括：① 初始化标识信息，将系统分配的标识符和父进程标识符填入新 PCB 中；② 初始化处理机状态信息，使程序计数器指向程序的入口地址，使栈指针指向栈顶；③ 初始化处理机控制信息，将进程的状态设置为就绪状态或 静止就绪状态，对于优先级，通常是将它设置为最低优先级，除非用户以显式方式提出高优先级要求。 

(4) 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列。

#### **「退出/终止状态」**

进程终止首先等待操作系统进行善后处理，然后将其 PCB 清零，并将 PCB 空间返还系统。终止的进程会在系统保留一些数据或记录，当这些数据被处理后，系统才会删除该进程。（我们看到终止的进程就是把PCB回收，返回给系统，这里也能看到PCB在进程中所起的作用）

**「进程的终止过程」**

如果系统中发生了上述要求终止进程的某事件，OS 便调用进程终止原语，按下述过程去终止指定的进程。

(1) 根据被终止进程的标识符，从 PCB 集合中检索出该进程的 PCB，从中读出该进程的状态。

(2) 若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度。 

(3) 若该进程还有子孙进程，还应将其所有子孙进程予以终止，以防它们成为不可控的进程。

(4) 将被终止进程所拥有的全部资源，或者归还给其父进程，或者归还给系统。

(5) 将被终止进程(PCB)从所在队列(或链表)中移出，等待其他程序来搜集信息。

> 会引起进程终止的原因：
>
> 1.正常执行完成后，执行退出、终止。
>
> 2.程序异常或错误——非法指令、运行超时、越界错误（访问的区域不存在）、算术错误等其他在编写程序时发生的错误；
>
> 3.外界干预——用户或操作系统终止某个进程、父进程请求终止子进程、父进程终止则其子进程也将被终止。

#### 「状态转换」

null——创建：进程创建，即为程序准备pcb 和数据；

创建——就绪：内存接纳外存中创建好的进程，把其放入就绪队列，成为就绪状态；

就绪——运行：系统调度就绪队列中的某个进程，获取了cpu资源，从就绪状态到执行状态；

运行——阻塞：在执行进程中，该进程需要从外部设备获取I/O数据，发生阻塞；

运行——就绪：在一个cpu执行周期内，该进程没有执行完，系统调度了其他进程，把该进程放入就绪队列中；

阻塞——就绪：当被阻塞的进程获取到相应的条件（IO事件完成），重新进入到就绪队列；

运行——终止：执行完成、外部干预、程序异常；

### 2.3.3 进程挂起

说起挂起，先了解一下 swaping 交换。 

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnzf1jd0pj30uy0ku15k.jpg" alt="swaping" style="zoom:67%;" />



#### 进程的挂起与激活

##### 进程的挂起

当出现了引起进程挂起的事件时，比如，用户进程请求将自己挂起，或父进程请求将自己的某个子进程挂起，系统将利用挂起原语 suspend( )将指定进程或处于阻塞状态的进程挂起。挂起原语的执行过程是：首先检查被挂起进程的状态，若处于活动就绪状态，便将其改为静止就绪； 对于活动阻塞状态的进程，则将之改为静止阻塞。**==为了方便用户或父进 程考查该进程的运行情况而把该进程的 PCB 复制到某指定的内存区域==**。

<!--处于挂起的时候，只是程序和数据被放到外存了，PCB放在内存中。这样系统才能感知进程状态，改变进程状态。这一个理解非常重要-->

##### 进程的激活过程

当发生激活进程的事件时，例如，父进程或用户进程请求激活指定进程，若该进程驻 留在外存而内存中已有足够的空间时，则可将在外存上处于静止就绪状态的该进程换入内 存。这时，系统将利用激活原语 active( )将指定进程激活。激活原语先将进程从外存调入内 存，检查该进程的现行状态，若是静止就绪，便将之改为活动就绪；若为静止阻塞，便将之改为活动阻塞。假如采用的是抢占调度策略，则每当有新进程进入就绪队列时，应检查 是否要进行重新调度，即由调度程序将被激活进程与当前进程进行优先级的比较，如果被激活进程的优先级更低，就不必重新调度；否则，立即剥夺当前进程的运行，把处理机分配给刚被激活的进程。

#### **进程什么时候会被挂起呢**？

(1) 终端用户的请求。当终端用户在自己的程序运行期间发现有可疑问题时，希望暂时使自己的程序静止下来。亦即，使正在执行的进程暂停执行；若此时用户进程正处于就绪状态而未执行，则该进程暂不接受调度，以便用户研究其执行情况或对程序进行修改。我们把这种静止状态称为挂起状态。 

(2) 父进程请求。有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，或者协调各子进程间的活动。 

(3) 负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。

(4) 操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。

**挂起的本质**

挂起实际上就是把进程从内存中调换到外存中，通过swaping 实现；

### 2.3.4进程七状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnzjfnmauj30v60pq7fs.jpg" alt="进程7状态" style="zoom:67%;" />

增加了就绪挂起、阻塞挂起；



#### 状态转换

就绪<——>就绪挂起：一般，OS挂起阻塞进程，但有时也会挂起就绪进程，释放内存；当某个时刻内存够用，则会把就绪挂起进程转变为就绪

阻塞<——>阻塞挂起：OS通常将阻塞进程换出，以腾出内存空间；当阻塞挂起的进程等待的事件发生时，也会被放入内存，变为block；

阻塞挂起——>就绪挂起：当进程等待的事件发生，可以从阻塞挂起到就绪挂起；



#### **Block vs Supend 挂起**

进程是否等待事件：阻塞与否

进程是否被换出内存：挂起与否

Ready：进程在内存，准备执行

Block：进程在内存，等待事件

Ready、Suspend：进程在外存，等待激活（调入内存）

Block、Suspend：进程在外存，等待事件。



![image-20201014101226368](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjon4c8vguj30fy0a8tc2.jpg)

P 代表进程、实现代表占用、虚线代表请求，p1、p2、p3 这三个进程会处于什么状态？

P1 为running、p2为block、p3为创建



## 2.4 进程控制

进程控制是进程管理中最基本的功能。它用于创建一个新进程，终止一个已完成的进程，或终止一个因出现某事件而使其无法运行下去的进程，还可负责进程运行中的状态转换。如当一个正在执行的进程因等待某事件而暂时不能继续执行时，将其转换为阻塞状态， 而当该进程所期待的事件出现时，又将该进程转换为就绪状态等等。进程控制一般是由 OS的内核中的**原语**来实现的。

一句话：**<u>进程控制负责进程的状态切换、进程创建及销毁，靠os中原语实现的</u>**；

<!--原语这个词是相对的，在操作系统层面，像wrtie、read这种系统指令对于程序员而言是不可分割的，原子性的，但是从系统本身来说，write、read指令也是由多条汇编语言组成，而每个汇编语言又是多个逻辑指令，即二进制的电极信号，这样说我们就明白了。 -->

### 2.4.1 操作系统功能

操作系统os内核一般有两大功能：**<u>支撑功能 、资源管理功能</u>**

#### 支撑功能

- Interrupt handing 中断处理 

  是多道程序系统最基本的功能，是其他活动赖以实现的基础。系统调用、I/O输入、进程调度、设备驱动都会用到中断。（想想，中断在现实生活中的含义）

- Timing 时钟管理 

  基本功能之一，时间片轮转调度中会用到时钟计功能；

- Primitive 原语 ：atomic operation 原子操作（这个原子操作其实也是基于中断实现的，所有锁的机制都是通过这个东西实现的）

  <!-- -->

- Accounting 统计

- Monitoring 监测

#### 资源管理功能

- 进程管理
- 内存管理
- 设备管理
- 文件管理

相关的介绍都在[第一章节](#操作系统作用) 

### 2.4.2 进程创建

[参考](# 「创建状态 )

### 2.4.3 进程终止

[参考](# 「退出/终止状态」)

### 2.4.4 进程阻塞

[参考](#进程阻塞与唤醒 )

### 2.4.5 进程挂起

[参考](#2.3.3 进程挂起 )

### 2.4.6 进程切换 vs 模式切换

![image-20201014154621913](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjowruf0yxj30ee09xafl.jpg)

用户进程切换一定引起模式切换，因为进程切换是os 在内核态提供的原语提供的指令，同时还有调度，这些都是内核态的功能，切换完之后去另一个进程，这样就会涉及模式的切换；但模式切换不一定会引起进程切换，因为从用户态到内核态不一定要新进程。

假如说：系统进程或者内核进程，这种不涉及到用户态的进程会有模式切换吗？

## 2.5 进程同步

主要掌握进程 并发、同步与互斥、死锁与饥饿、临界区；3个金典问题；

多进程系统在使用临界资源时，必须做好协调和同步工作，否则会造成竞争和死锁；

### 2.5.1基本概念

#### 临界资源

同处于一个系统中的进程，通常都共享着某种系统资源，如共 享 CPU、共享 I/O 设备等资源都是临界资源，进程间应采取互斥方式，实现对这种资源的共享。

#### 临界区

在每个进程中访问临界资源的那段代码称为临界区(critical section)。显然， 若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。

临界区前面增加一段用于进行上述检查的代码，把这段代码称为进入区(entry section)。相应 地，在临界区后面也要加上一段称为退出区(exit section)的代码，用于将临界区正被访问的 标志恢复为未被访问的标志。进程中除上述进入区、临界区及退出区之外的其它部分的代 码，在这里都称为剩余区。

```
while (true){
		进入区
		临界区
		退出区
		剩余区
}
```



#### 同步机制遵循的规则

(1) 空闲让进。当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求 进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。

(2) 忙则等待。当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进 入临界区的进程必须等待，以保证对临界资源的互斥访问。

(3) 有限等待。对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区， 以免陷入“死等”状态。

(4) 让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙 等”状态。



### 2.5.2 信号量机制

这个机制由荷兰科学家Dijkstra提出的，其机制为：

**进行代码抽象**

![IMG_5681](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjxwua2i4jj31sk0u04qp.jpg)



把临界资源定义为S，并提供**两个原子操作 Wait（S） 和Signal（S），不能被中断**，其操作如下：

```
wait(S)和 signal(S)操作可描述为：

procedure wait(S) 
		var S：semaphore； 
		begin 
			S.value:=S.value-1； 
			if S.value<0 then block(S.L)；
    end 
//value 表示临界资源可用数量    
procedure signal(S) 
		var S: semaphore； 
		begin 
			S.value:=S.value+1； 
			if S.value<=0 then wakeup(S.L)； 
		end
```

每次 wait 操作，意味着进程请求一个单位的该类资源，使系统中可供分配 的该类资源数减少一个，因此描述为 S.value:=S.value-1；当 S.value<0 时，表示该类资源已 分配完毕，**因此进程应调用 block 原语，进行自我阻塞，放弃处理机，并插入到信号量链表 S.L 中（不像软件、硬件中断出现忙等现象，因为他会进入阻塞状态，不占用processer）**。可见，该机制遵循了“让权等待”准则。此时 S.value 的绝对值表示在该信号量链 表中已阻塞进程的数目。对信号量的每次 signal 操作，表示执行进程释放一个单位资源，使 系统中可供分配的该类资源数增加一个，故 S.value:=S.value+1 操作表示资源数目加 1。若 加 1 后仍是 S.value≤0，则表示在该信号量链表中，仍有等待该资源的进程被阻塞，故还应 调用 wakeup 原语，将 S.L 链表中的第一个等待进程唤醒。**如果 S.value 的初值为 1，表示只允许一个进程访问临界资源，此时的信号量转化为互斥信号量，用于进程互斥。** 这就是用信号量实现进程互斥的原理；如何实现呢？

==我们只需要把 临界区代码 放到 互斥量mutex 的wait（mutex）和 signal（mutex）之间即可，并把互斥量的数量value设置为1。==  这就是实现核心精髓。

> 每个欲访问该临界资源的进程在进入临界区之前，都要先对 mutex 执行 wait 操作，若该资源此刻未被访问，本次 wait 操作必然成功，进程便可进入自己的临界区， 这时若再有其他进程也欲进入自己的临界区，此时由于对 mutex 执行 wait 操作定会失败，因而该进程阻塞，从而保证了该临界资源能被互斥地访问。当访问临界资源的进程退出临 界区后，又应对 mutex 执行 signal 操作，以便释放该临界资源。

假如说，有多个临界资源或者说某个资源的数目满足一定条件，则只需要在if 条件判断时，修改条件即可。

### 2.5.3 管程

由于进程同步很常见，会导致系统中存在很多临界资源，那每个临界资源都各自维护同步操作，带来了管理麻烦。于是用一种面向对象的“封装”的思想，引入管程来管理。它和信号量有同等的表达能力。

定义：

代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源 管理程序，共同构成了一个操作系统的资源管理模块，我们称之为管程。管程被请求和释放 资源的进程所调用。

管程由四部分组成：① 管程的名称；② 局部于管程内部的共享 数据结构说明；③ 对该数据结构进行操作的一组过程；④ 对局部于管程内部的共享数据 设置初始值的语句。

![image-20201020183042006](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvz8nk4oij30df09kq3h.jpg)

特性：

（1） 模块化：管程是一个基本程序单位，可以单独编译。

  (2) 抽象数据类型。管程中不仅有数据，而且有对数据的操作。

  (3) 信息掩蔽。管程中的数据结构只能被管程中的过程访问，这些过程也是在管程内部 定义的，供管程外的进程调用，而管程中的数据结构以及过程(函数)的具体实现外部不可见。

管程和进程不同，主要体现在以下几个方面：

(1) 虽然二者都定义了数据结构，但进程定义的是私有数据结构 PCB，管程定义的是公 共数据结构，如消息队列等；

(2) 二者都存在对各自数据结构上的操作，但进程是由顺序程序执行有关的操作，而管 程主要是进行同步操作和初始化操作；

(3) 设置进程的目的在于实现系统的并发性，而管程的设置则是解决共享资源的互斥使 用问题；

(4) 进程通过调用管程中的过程对共享数据结构实行操作，该过程就如通常的子程序一 样被调用，因而管程为被动工作方式，进程则为主动工作方式；

(5) 进程之间能并发执行，而管程则不能与其调用者并发；

(6) 进程具有动态性，由“创建”而诞生，由“撤销”而消亡，而管程则是操作系统中 的一个资源管理模块，供进程调用。

### **2.5.4 互斥方法**

软件方法 —— 内存中设置一个变量标记临界资源，使用时进行检查该变量，变量为true时表示为可用，否则不可用；缺陷：只能用于两个进程间互斥。或者说某个进程在进行检测和设置时，不能保证原子性；可能多个进程同时检查，同时进入了。

硬件方法

- 屏蔽中断：因为中断是程序调度的基础，所以通过屏蔽中断，不进行调度，达到原子目的。但是系统是多处理器，多个cpu就不适用了。相比软件方法：实现了原子操作，但缺点是代价太大，不能响应中断，如果此时有个高级别的任务则无法响应。
- 特殊机器指令：一个指令周期不产生中断。test-set 、exchange；缺陷：会产生忙等现象。占用资源，却不干事情。

信号量 ：[见上面](#2.5.2 信号量机制)

消息传递：是一种进程通信的方式，见[下面](#2.6 进程通信)。

## 2.6 进程通信

通信机制可归结为三大类： 共享存储器系统、消息传递系统以及管道通信系统。

### 2.6.1 简述

#### 共享存储器系统 Shared-Memory System  

基于共享存储区的通信方式。为了传输大量数据，在存储器中划出了一块共享存储 区，诸进程可通过对共享存储区中数据的读或写来实现通信。

#### 消息传递

应用最为广泛的一种进程间的通信机制。 在该机制中，进程间的数据交换是以格式化的消息(message)为单位的；在计算机网络中， 又把 message 称为报文。程序员直接利用操作系统提供的一组通信命令(原语)，不仅能实现 大量数据的传递，而且还隐藏了通信的实现细节，使通信过程对用户是透明的，从而大大 减化了通信程序编制的复杂性，因而获得了广泛的应用。

> 网络通信都是基于这个原理建立起来的，而这一块的内容又是一整个大块：计算机网络原理。而android 系统中进程间通信也是用的这种方式 Message。

#### 管道通信 pipe

所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享 文件，又名 pipe 文件。向管道(共享文件)提供输入的发送进程(即写进程)，以字符流形式将 大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。 由于发送进程和接收进程是利用管道进行通信的，故又称为管道通信。这种方式首创于 UNIX 系统，由于它能有效地传送大量数据，因而又被引入到许多其它的操作系统中。

#### 客户机-服务器系统

上面三种方式都可以应用于不同计算机之间通信，但是客户机——服务器这种方式更为流行，其实现是 socket 套接字、远程过程（方法）调用。

上述四种方式，重点理解消息传递系统实现的进程间通信。

### 2.6.2 消息传递通信实现

消息传递需要源进程和目标进程，系统要为其提供发送和接收原语。

#### 1 通信方式

直接通信：双方需要显示的知道对方的地址。

间接通信：有可能存在多个发送进程，比如打印请求，多个进程可以发送这个请求。

#### 2 通信链路

为使在发送进程和接收进程之间能进行通信， **必须在两者之间建立一条通信链路 (communication link)。有两种方式建立通信链路。第一种方式是由发送进程在通信之前用显 式的“建立连接”命令(原语)请求系统为之建立一条通信链路；在链路使用完后，也用显式 方式拆除链路。这种方式主要用于计算机网络中。**第二种方式是发送进程无须明确提出建 立链路的请求，只须利用系统提供的发送命令(原语)，系统会自动地为之建立一条链路。这 种方式主要用于单机系统中

#### 3 消息格式

message 包含什么信息；公用的消息头，包含主体消息的消息体；

#### 4 消息缓冲队列

这个东西，也在android 中看到，其实都是差不多的。这个东西的数据结构：

1 消息缓冲区：

```
typed struct message_buffer{
	int sender; //发送者进程标识
	int size;   //消息长度
	char text;  //消息内容
	struct message_buffer next; //下一个消息缓冲区指针
}
```

2 PCB 中新增的消息缓冲队列数据项

```
typedef struct processcontrol_block{
	struct message_buffer mq; 消息队列首指针
	semaphore mutex； 互斥信号量
	semaphore sm 资源信号量
}
```

3 发送原语

下图是 消息缓冲通信示意图：



![image-20201022144725282](https://tva1.sinaimg.cn/large/0081Kckwgy1gjy40ygmnpj30jw0al0tm.jpg)

```
procedure send(receiver，a)
	begin 
		getbuf(a.size,i)； 根据 a.size 申请缓冲区；
		i.sender:= a.sender； 将发送区 a 中的信息复制到消息缓冲区 i 中；
		i.size:=a.size； 
		i.text:=a.text； 
		i.next:=0； 
		getid(PCB set，receiver.j)； 获得接收进程内部标识符； 
		wait(j.mutex)； insert(j.mq，i)； 将消息缓冲区插入消息队列； 
		signal(j.mutex)； 
		signal(j.sm)；
end
```

4 接收原语

```
procedure receive(b)
	begin
  	j:= internal name；  j 为接收进程内部的标识符；
  	wait(j.sm)； 
  	wait(j.mutex)； 
  	remove(j.mq，i)；  将消息队列中第一个消息移出；
  	signal(j.mutex)； 
  	b.sender:=i.sender； 将消息缓冲区 i 中的信息复制到接收区 b；
  	b.size:=i.size； 
  	b.text:=i.text；

end
```



## 2.7 线程

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjoy84ppstj30fn0bz78r.jpg" alt="image-20201014163640010" style="zoom:80%;" />



为了减少程序在并发执行时所付出的时空开销，使 OS 具有更好的并发性，在进程的基础上引入线程；我们知道的进程两个基本属性: **① 进程是一个可拥有资源的独立单位；② 进程同时又是一个可独立调度和分派的基本单位**，使得进程能够独立运行而且并发执行。但是在进程的切换会消耗大量的资源，为了解决这个问题，把上述两个功能分开，引入线程承担第二个功能，进程只是拥有资源的独立单位。以线程作为调度和分派的基本单位，则可以有效地改善多处理机系统的性能。

### 2.7.1 线程vs 进程

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjoy84ppstj30fn0bz78r.jpg" alt="image-20201014163640010" style="zoom:80%;" />

​                                                                                            <!--单线程和多线程模型-->

线程具有许多传统进程所具有的特征，又称为轻型进程(Light-Weight Process)，传统进程相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都拥有若干个线程，至少也有一个线程。

1. 调度

在传统的操作系统中，作为拥有资源的基本单位和独立调度、分派的基本单位都是进程。而在引入线程的操作系统中，则把线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位，把传统进程的两个属性分开，使线程基本上不拥有资源，这样线程便能 轻装前进，从而可显著地提高系统的并发程度。在同一进程中，线程的切换不会引起进程的切换，但从一个进程中的线程切换到另一个进程中的线程时，将会引起进程的切换。 

2. 并发性

在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，使得操作系统具有更好的并发性，从而能更加有效地提高系统资源的利用率和系统的吞吐量。

3. 拥有资源 ：进程拥有资源，线程不拥有资源，但线程可以访问它隶属的进程的资源；
4. 系统开销

在创建或撤消进程时，系统都要为之创建和回收进程控制块，分配或回收资源，如内存空间和 I/O 设备等，操作系统所付出的开销明显大于线程创建或撤消时的开销。类似地，在进程切换时，涉及到当前进程 CPU 环境的保存及新被调度运行进程的 CPU 环境的设置，而线程的切换则仅需保存和设置少量寄存器内容，不涉及存储器管理方面的操作，所以就 切换代价而言，进程也是远高于线程的。此外，由于一个进程中的多个线程具有相同的地址空间，在同步和通信的实现方面线程也比进程容易。在一些操作系统中，线程的切换、 同步和通信都无须操作系统内核的干预。 

### 2.7.2 线程属性

在多线程os 中**（一定是多线程系统）**，一个进程包含多个线程，线程有下面属性：

1. 轻型：不具有系统资源，其组成有TCB 线程控制块，程序计数器，保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈；
2. 独立调度和分派的基本单位。在多线程 OS 中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位
3. 可并发执行。在一个进程中的多个线程之间可以并发执行，甚至允许在一个进程中的所有线程都能并发执行
4. 共享进程资源。在同一进程中的各个线程都可以共享该进程所拥有的资源，这首先表现在所有线程都具有相同的地址空间(进程的地址空间)

### 2.7.3 线程状态

线程的状态和进程一样，可以类比。

在多线程 OS 环境下，应用程序在启动时，通常仅有一个线程在执行，该线程被人们称 为“初始化线程”。它可根据需要再去创建若干个线程。在创建新线程时，需要利用一个线 程创建函数(或系统调用)。

> 这里我们可以想到android，创建了主线程(UI线程)，后面可以在主线程中去创建新的线程，

终止线程的方式有两种：一种是在线程完成了自己的工作后自愿退出；另一种是线程在运行中出现错误或由于某种原因而被其它线程 强行终止。。在大多数的 OS 中，线程被中止后并不立即释放它所占有的资源，只有当进程中的其它线程执行了分离函数后，被终止的线程才与资源分离，此时的资源才能被其它线程利用。

### 2.7.4 多线程OS中的进程

多线程os中，进程时拥有资源的独立单位，但不就不再作为一个执行的实体。是把线程作为独立运行的基本单位， 所以此时的进程已不再是一个可执行的实体。虽然如此，进程仍具有与执行相关的状态。例如，所谓进程处于“执行”状态，实际上是指该进程中的某线程正在执行。此外，对进程所施加的与进程状态有关的操作，也对其线程起作用。例如，在把某个进程挂起时，该进程中的所有线程也都将被挂起；又如，在把某进程激活时，属于该进程的所有线程也都将被激活。 

### 2.7.5 线程实现方式

#### **内核支持线程**

在内核的支持下运行的，即无论是用户进程中的线程，还是系统进程中的线程，他们的创建、撤消和切换等也是依靠内核，在内核空间实现的。此外，在内核空间还为每一个内核支持线程设置了一个线程控制块，内核是根据该控制块而感知某线程的存在，并对其加以控制。

这种线程实现方式主要有如下四个优点：

(1) 在多处理器系统中，内核能够同时调度同一进程中多个线程并行执行；

(2) 如果进程中的一个线程被阻塞了，内核可以调度该进程中的其它线程占有处理器运行，也可以运行其它进程中的线程；

(3) 内核支持线程具有很小的数据结构和堆栈，线程的切换比较快，切换开销小； 

(4) 内核本身也可以采用多线程技术，可以提高系统的执行速度和效率。 

内核支持线程的主要缺点是：对于用户的线程切换而言，其模式切换的开销较大，在同一个进程中，从一个线程切换到另一个线程时，需要从用户态转到内核态进行，这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的，系统开销较大。

#### **用户级线程**

用户级线程 ULT(User Level Threads)仅存在于用户空间中。对于这种线程的创建、撤消、线程之间的同步与通信等功能，都无须利用系统调用来实现。对于用户级线程的切换，通常发生在一个应用进程的诸多线程之间，这时，也同样无须内核的支持。由于这些线程的任务控制块都是设置在用户空间，而线程所执行的操作也无须内核的帮助，因而内核完全不知道用户级线程的存在。

> 对于设置了用户级线程的系统，其调度仍是以进程为单位进行的。在采用轮转调度算法时，各个进程轮流执行一个时间片，这对诸进程而言似乎是公平的。但 假如在进程 A 中包含了一个用户级线程，而在另一个进程 B 中含有 100 个用户级线程，这样，进程 A 中线程的运行时间将是进程 B 中各线程运行时间的 100 倍；相应地，其速度要 快上 100 倍。如果设置的是内核支持线程，则调度以线程为单位，B两个进程获取的时间片是A的100倍，则两个进程运行速度差不多。

**优缺点**

(1) 线程切换不需要转换到内核空间，对一个进程而言，其所有线程的管理数据结构均在该进程的用户空间中，线程管理在用户态完成即可，节省了模式切换带来的消耗。 

(2) 用户级线程的实现与操作系统平台无关，因为对于线程管理的代码是在用户程序内的，属于用户程序的一部分，所有的应用程序都可以对之进行共享。因此，用户级线程甚至可以在不支持线程机制的操作系统平台上实现。 

用户级线程实现方式的主要缺点在于如下两个方面： 

(1) 系统调用的阻塞问题。在基于进程机制的操作系统中，大多数系统调用将阻塞进程，因此，当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的所有线程都会被阻 塞。而在内核支持线程方式中，则进程中的其它线程仍然可以运行。

> 内核线程则不会，因为他们是调度的单位，而用户线程，进程是调度基本单位。

**实现**

用户级线程是在用户空间实现的。所有的用户级线程都具有相同的结构，它们都运行在一个中间系统的上面。当前有两种方式实现的中间系统，即运行时系统和内核控制线程。

1) 运行时系统(Runtime System) 

所谓“运行时系统”，实质上是用于管理和控制线程的函数(过程)的集合，其中包括用于创建和撤消线程的函数、 线程同步和通信的函数以及实现线程调度的函数等。正因为有这些函数，才能使用户级线程与内核无关。运行时系统中的所有函数都驻留在用户空间，并作为用户级线程与内核之间的接口。

 2) 内核控制线程

这种线程又称为轻型进程 LWP(Light Weight Process)。每一个进程都可拥有多个 LWP，同用户级线程一样，每个 LWP 都有自己的数据结构(如 TCB)，其中包括线程标识符、优先级、状态，另外还有栈和局部存储区等。它们也可以共享进程所拥有的资源。LWP 可通过系统调用来获得内核提供的服务，这样，当一个用户级线程运行时，只要将它连接到一个LWP 上，此时它便具有了内核支持线程的所有属性。

在一个系统中的用户级线程数量可能很大，为了节省系统开销，不可能设置太多的LWP，而把这些 LWP 做成一个缓冲池，称为“线程池”。

![image-20201014201117233](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjp4ffged0j30hc08tq3q.jpg)

#### 用户级线程与内核控制线程的连接

在不同的操作系统中，实现用户级线程与内核控制线程的连接有三种不同的模型：一对一模型、多对一模型和多对多模型。 

1) 一对一模型

该模型是为每一个用户线程都设置一个内核控制线程与之连接，当一个线程阻塞时，允许调度另一个线程运行。在多处理机系统中，则有多个线程并行执行。该模型并行能力较强，但每创建一个用户线程相应地就需要创建一个内核线程，开销 较大，因此需要限制整个系统的线程数。

2) 多对一模型

该模型是将多个用户线程映射到一个内核控制线程，为了管理方便，这些用户线程一般属于一个进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完成。当用户线程需要访问内核时，才将其映射到一个内核控制线程上，但每次 只允许一个线程进行映射。 该模型的主要优点是线程管理的开销小，效率高，但当一个线程在访问内核时发生阻 塞，则整个进程都会被阻塞，而且在多处理机系统中，一个进程的多个线程无法实现并行。

3) 多对多模型

该模型结合上述两种模型的优点，将多个用户线程映射到多个内核控制线程，内核控 制线程的数目可以根据应用进程和系统的不同而变化，可以比用户线程少，也可以与之相同。

## 2.8 调度

在多道程序环境下，主存中有着多个进程，其数目往往多于处理机数目。这就要求系统能按某种算法，动态地把处理机分配给就绪队列中的一个进程，使之执行。分配处理机的任务是由处理机调度程序完成的。由于处理机是最重要的计算机资源，提高处理机的利用率及改善系统性能(吞吐量、响应时间)，在很大程度上取决于处理机调度性能的好坏，因而，处理机调度便成为操作系统设计的中心问题之一.

**进程调度和状态转换关系**<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvmnx5hrtj30xg0pegwo.jpg" alt="image-20201020111536419" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvmrbq3kjj30wi0qak2s.jpg" alt="image-20201020111853154" style="zoom:67%;" />

### 2.8.1 长程调度

根据某种算法，**==把外存上处于外存队列中的那些作业选中某个调入内存==**，也就是说，它的调度对象是存在于外存中的作业队列。这时候还没有创建进程，对应的状态转换是：new——Ready/Suspend Ready；发生在内外存之间。就是选择哪个程序进入内存以及有多少程序被调入内存（注意：调入内存的程序不一定是ready态，还要给其分配资源、创建pcb时才能成为ready）；

#### 1．作业和作业步

(1) 作业(Job)。作业是一个比程序更为广泛的概念，它不仅包含了通常的程序和数据， 而且还应配有一份作业说明书，系统根据该说明书来对程序的运行进行控制。在批处理系统中，是以作业为基本单位从外存调入内存的。

(2) 作业步(Job Step)。通常，在作业运行期间，每个作业都必须经过若干个相对独立， 又相互关联的顺序加工步骤才能得到结果，我们把其中的每一个加工步骤称为一个作业步， 各作业步之间存在着相互联系，往往是把上一个作业步的输出作为下一个作业步的输入。例如，一个典型的作业可分成三个作业步：① “编译”作业步，通过执行编译程序对源程序进行编译，产生若干个目标程序段；② “连结装配”作业步，将“编译”作业步所产生的若干个目标程序段装配成可执行的目标程序；③ “运行”作业步，将可执行的目标程序读入内存并控制其运行。

(3) 作业流。若干个作业进入系统后，被依次存放在外存上，这便形形成了输入的作业流；在操作系统的控制下，逐个作业进行处理，于是便形成了处理作业流。 

#### 2. 作业控制块 JCB(Job Control Block) 

同进程控制块PCB一样, 为作业设置了作业控制块用来管理作业, 它是作业在系统中存在的标志，其中保存了

系统对作业进行管理和调度所需的全部信息。在 JCB 中所包含的内容因系统而异，通常应包含的内容有：作业标识、用户名称、用户帐户、作业类型(CPU 繁忙型、I/O 繁忙型、批量型、终端型)、作业状态、调度信息(优先级、作业已运行时间)、资源需求(预计运行时间、 要求内存大小、要求 I/O 设备的类型和数量等)、进入系统时间、开始处理时间、作业完成 时间、作业退出时间、资源使用情况等。 每当作业进入系统时，系统便为每个作业建立一个 JCB，根据作业类型将它插入相应的后备队列中。

#### 3. 作业调度

作业调度的主要功能是根据作业控制块中的信息，==<u>审查系统能否满足用户作业的资源需求</u>==，以及按照一定的算法，==<u>从外存的后备队列中选取某些作业调入内存</u>==，并为它们创建进程、分配必要的资源。然后再将新创建的进程插入就绪队列，准备执行。因此，有时也 把作业调度称为接纳调度(Admission Scheduling)。

<!-- 作业调度也是根据系统资源,比如系统规定的最大程序并发数,来进行接纳调度,有点像swapping 把进程挂起-->

### 2.8.2 中程调度

引入中程调度的主要目的是**<u>为了提高内存利用率和系统吞吐量</u>**。为此，应使那些暂时不能运行的进程不再占用宝贵的内存资源，而将它们调至外存上去等待，把此时的进程状态称为就**<u>绪驻外存状态或挂起状态</u>**。当这些进程重又具备运行条件且内存又稍有空闲时，由中程调度来决定把外存上的那些又具备运行条件的就绪进程重新调入内存，并修改其状态为就绪状态，挂在就绪队列上等待进程调度。中程调度实际上就是存储器管理中的对换功能swapping，

**发生在内外存之间.** **对应的状态转换：Ready——Ready Suspend ；Block —— Block Suspend**

### 2.8.3 短程调度

它所调度的对象是进程(或内核级线程)。进程调度是最基本的一种调度； 对应的状态转换是：Ready——Running， **发生在内存内**

#### 1．短程调度的功能

低级调度用于决定就绪队列中的哪个进程(或内核级线程，为叙述方便，以后只写进程) 应获得处理机，然后再由分派程序执行把处理机分配给该进程的具体操作。

**低级调度的主要功能如下：**

(1) 保存处理机的现场信息。在进程调度进行调度时，首先需要保存当前进程的处理机的现场信息，如程序计数器、多个通用寄存器中的内容等，将它们送入该进程的进程控制块(PCB)中的相应单元。 

(2) 按某种算法选取进程。如优先数算法、轮转法、剩余时间法等，从就绪队列中选取一个进程，把它的状态改为运行状态，并准备把处理机分配给它。 

(3) 把处理器分配给进程。由分派程序(Dispatcher)把处理器分配给进程。此时需为选中的进程恢复处理机现场，即把选中进程的进程控制块内有关处理机现场的信息装入处理器相应的各个寄存器中，把处理器的控制权交给该进程，让它从取出的断点处开始继续运行.

#### 2．进程调度中的三个基本机制

为了实现进程调度，应具有如下三个基本机制：

(1) 排队器。为了提高进程调度的效率，先将所有的就绪进程按照一定的方式排成**<u>一个或多个队列</u>**，以便调度程序能最快地找到它。 

(2) 分派器(分派程序)。分派器把由进程调度程序所选定的进程，从就绪队列中取出该进程，然后进行上下文切换，将处理机分配给它。 

(3) 上下文切换机制。当对处理机进行切换时，会发生两对上下文切换操作。在第一对上下文切换时，操作系统将保存当前进程的上下文，而装入分派程序的上下文，以便分派程序运行；在第二对上下文切换时，将移出分派程序，而把新选进程的 CPU 现场信息装入 到处理机的各个相应寄存器中。

> 应当指出，上下文切换将花去不少的处理机时间，即使是现代计算机，每一次上下文切换大约需要花费几毫秒的时间，该时间大约可执行上千条指令。为此，现在已有通过硬 件(采用两组或多组寄存器)的方法来减少上下文切换的时间。一组寄存器供处理机在系统态时使用，另一组寄存器供应用程序使用。在这种条件下的上下文切换只需改变指针，使其 指向当前寄存器组即可。

#### 3．进程调度方式

进程调度可采用下述两种调度方式。

**1) 非抢占方式(Nonpreemptive Mode)** 

在采用这种调度方式时，一旦把处理机分配给某进程后，不管它要运行多长时间，都一直让它运行下去，决不会因为时钟中断等原因而抢占正在运行进程的处理机，也不允许其它进程抢占已经分配给它的处理机。直至该进程完成，自愿释放处理机，或发生某事件而被阻塞时，才再把处理机分配给其他进程。

在采用非抢占调度方式时，可能引起进程调度的因素可归结为如下几个： 

**(1)** 正在执行的进程执行完毕，或因发生某事件而不能再继续执行；

**(2)** 执行中的进程因提出 I/O 请求而暂停执行；

**(3)** 在进程通信或同步过程中执行了某种原语操作，如 P 操作(wait 操作)、Block 原语、 Wakeup 原语等。 



**2) 抢占方式(Preemptive Mode)** 

这种调度方式允许调度程序根据某种原则去暂停某个正在执行的进程，将已分配给该进程的处理机重新分配给另一进程。抢占方式的优点是，可以防止一个长进程长时间占用处理机，能为大多数进程提供更公平的服务，特别是能满足对响应时间有着较严格要求的 实时任务的需求。但抢占方式比非抢占方式调度所需付出的开销较大。抢占调度方式是基于一定原则的，

(1) 优先权原则。通常是对一些重要的和紧急的作业赋予较高的优先权。当这种作业到 达时，如果其优先权比正在执行进程的优先权高，便停止正在执行(当前)的进程，将处理机分配给优先权高的新到的进程，使之执行；或者说，允许优先权高的新到进程抢占当前进程的处理机。

(2) 短作业(进程)优先原则。当新到达的作业(进程)比正在执行的作业(进程)明显的短时，将暂停当前长作业(进程)的执行，将处理机分配给新到的短作业(进程)，使之优先执行；或者说，短作业(进程)可以抢占当前较长作业(进程)的处理机。

(3) 时间片原则。各进程按时间片轮流运行，当一个时间片用完后，便停止该进程的执行而重新进行调度。这种原则适用于分时系统、大多数的实时系统，以及要求较高的批处理系统。

#### 4 发生时机

时钟中断、IO中断、系统请求、信号发生

---

总结：

> 搞、中、低是以调度频率起名的, 进程最频繁、其次内存、最后作业. 而且他们面对的对象也不一样, 都是计算机中最重要的进程、内存、作业这样的对象.

在上述三种调度中，进程调度的运行频率最高，在分时系统中通常是 10～100 ms 便进行一次进程调度，因此把它称为短程调度。为避免进程调度占用太多的 CPU 时间，进程调度算法不宜太复杂。作业调度往往是发生在一个(批)作业运行完毕，退出系统，而需要重新调入一个(批)作业进入内存时，故作业调度的周期较长，大约几分钟一次，因此把它称为长程调度。由于其运行频率较低，故允许作业调度算法花费较多的时间。中级调度的运行频 率基本上介于上述两种调度之间，因此把它称为中程调度。

### 2.8.4 调度队列和准则

#### 1. 仅有进程调度的调度队列模型

在分时系统中，常把就绪进程组织成 FIFO 队列形式。每当 OS 创建一个新进程时，便将它挂 在就绪队列的末尾，然后按时间片轮转方式运行。

每个进程在执行时都可能出现以下三种情况： 

(1) 任务在给定的时间片内已经完成，该进程便在释放处理机后进入完成状态； 

(2) 任务在本次分得的时间片内尚未完成，OS 便将该任务再放入就绪队列的末尾； 

(3) 在执行期间，进程因为某事件而被阻塞后，被 OS 放入阻塞队列。

![image-20201016183355362](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd1yyrp0j30jy07fmxs.jpg)

#### 2．具有高级和低级调度的调度队列模型

在批处理系统中，不仅需要进程调度，而且还需有作业调度，由后者按一定的作业调度算法，从外存的后备队列中选择一批作业调入内存，并为它们建立进程，送入就绪队列，然 后才由进程调度按照一定的进程调度算法选择一个进程，把处理机分配给该进程。图 3-2 示 出了具有高、低两级调度的调度队列模型。该模型与上一模型的主要区别在于如下两个方面。

(1) 就绪队列的形式。在批处理系统中，最常用的是最高优先权优先调度算法，相应地， 最常用的就绪队列形式是优先权队列。进程在进入优先级队列时，根据其优先权的高低，被插入具有相应优先权的位置上，这样，调度程序总是把处理机分配给就绪队列中的队首进程。

![image-20201016183601081](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd1wqlwwj30oy0bjdgv.jpg)

(2) 设置多个阻塞队列。对于小型系统，可以只设置一个阻塞队列；但当系统较大时， 若仍只有一个阻塞队列，其长度必然会很长，队列中的进程数可以达到数百个，这将严重影响对阻塞队列操作的效率。故在大、中型系统中通常都设置了若干个阻塞队列，每个队 列对应于某一种进程阻塞事件。 

#### 3．同时具有三级调度的调度队列模型

在 OS 中引入中级调度后，人们可把进程的就绪状态分为内存就绪(表示进程在内存中就绪)和外存就绪(进程在外存中就绪)。类似地，也可把阻塞状态进一步分成内存阻塞和外存阻塞两种状态。在调出操作的作用下，可使进程状态由内存就绪转为外存就绪，由内 存阻塞转为外存阻塞；在中级调度的作用下，又可使外存就绪转为内存就绪.

![image-20201016183747798](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd2gmsp5j30nh0cqt9x.jpg)

#### 4. 调度算法选择准则

在一个操作系统的设计中，应如何选择调度方式和算法，在很大程度上取决于操作系统的类型及其目标。选择调度方式和算法的准则，有的是面向用户的，有的是面向系统的。

##### 面向用户

(1) 周转时间短: 通常把周转时间的长短作为评价批处理系统的性能、选择作业调度方式与算法的重要准则之一。所谓周转时间，是指从作业被提交给系统开始，到作业完成为 止的这段时间间隔(称为作业周转时间)。

(2) 响应时间快: 是选择分时系统中进程调度算法的重要准则之一。所谓响应时间，是从用户通过键盘提交一个请求开始，直至系统首次产生响应为止的时间

(3) 截止时间的保证。这是评价实时系统性能的重要指标，因而是选择实时调度算法的重要准则。

(4) 优先权准则。在批处理、分时和实时系统中选择调度算法时，都可遵循优先权准则，以便让某些紧急的作业能得到及时处理。

##### 面向系统的准则

(1) 系统吞吐量高: 指在单位时间内系统所完成的作业数

(2) 处理机利用率好: 因为cpu资源很宝贵, 要多利用cpu资源,尽量不让其空闲, 

(3) 各类资源的平衡利用: 在大、中型系统中，不仅要使处理机的利用率高，而且还应 能有效地利用其它各类资源，如内存、外存和 I/O 设备等。选择适当的调度方式和算法可以 保持系统中各类资源都处于忙碌状态。但对于微型机和某些实时系统而言，该准则并不重要。

### 2.8.5 调度算法

调度的实质是一种资源分配，因而调度算法是指：根据系统的资源分配策略所 规定的资源分配算法。对于不同的系统和系统目标，通常采用不同的调度算法。

#### 1 先来先服务 FCFS 和 短作业(进程)优先调度算法

##### 先来先服务 FCFS —— first come first server

先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也 可用于进程调度。FCFS 算法比较有利于长作业(进程)，而不利于短作业(进程)。FCFS 调度算法有利于 CPU 繁忙型的作业，而 不利于 I/O 繁忙型的作业(进程)。CPU 繁忙型作业是指该类作业需要大量的 CPU 时间进行 计算，而很少请求 I/O。通常的科学计算便属于 CPU 繁忙型作业。I/O 繁忙型作业是指 CPU 进行处理时需频繁地请求 I/O。目前的大多数事务处理都属于 I/O 繁忙型作业。

> 当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一 个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放 入就绪队列。在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进 入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件 而阻塞后才放弃处理机。
>
> 后面的调度算法，都可以参考这个定义来去看，比如短作业调度

##### 短作业(进程)优先调度算法 SJF——short job first

短作业(进程)优先调度算法 SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以 分别用于作业调度和进程调度。

SJ(P)F 调度算法也存在不容忽视的缺点：

(1) 该算法对长作业不利，更严重的是，如果有一长作业(进程)进入系统的后备队列(就绪队列)，由于调度程序 总是优先调度那些(即使是后进来的)短作业(进程)，将导致长作业(进程)长期不被调度。

(2) 该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业(进程)会被及时处理。

(3) 由于作业(进程)的长短只是根据用户所提供的估计执行时间而定的，而用户又可能 会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先 调度。

#### 2 高优先权调度

##### a 优先权调度算法的类型

根据进程、作业的优先级按顺序调度。算法分成如下两种：

1) 非抢占式优先权算法

系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便 一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机 重新分配给另一优先权最高的进程。用于批处理系统，或实时性不严的情况；

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执 行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原 优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。用于要求严格的实时系统；

##### b 优先权类型

对于最高优先权优先调度算法，其关键在于：它是使用静态优先权，还是用动态优先 权，以及如何确定进程的优先权。

- 静态：静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。
- 动态：动态优先权是指在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间 的增加而改变的，以便获得更好的调度性能。例如，我们可以规定，在就绪队列中的进程， 随其等待时间的增长，其优先权以速率 a 提高。

##### C 高响应比优先调度算法

在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业 的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先 级随着等待时间的增加而以速率 a 提高，则长作业在等待一定的时间后，必然有机会分配 到处理机。该优先权的变化规律可描述为：

![image-20201020104024760](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvlnaiouij30ax01yjrf.jpg)

#### 3 基于时间片的轮转调度算法

##### 1．时间片轮转法

1) 基本原理

在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列， 每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到 几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号 来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中 新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一 给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应 所有用户的请求。

2) 时间片大小的确定

在时间片轮转算法中，时间片的大小对系统性能有很大的影响，如选择很小的时间片 将有利于短作业，因为它能较快地完成，但会频繁地发生中断、进程上下文的切换，从而 增加系统的开销；反之，如选择太长的时间片，使得每个进程都能在一个时间片内完成， 时间片轮转算法便退化为 FCFS 算法，无法满足交互式用户的需求。一个较为可取的大小是， 时间片略大于一次典型的交互所需要的时间。这样可使大多数进程在一个时间片内完成。

##### 2. 多级反馈队列调度

**多级反馈 = FCFS + 多级就绪队列（每个队列的时间片时间不一样，依次递增；优先级依次降低）**

应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高， 第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片 的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例 如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第 i+1 个队列的时间片要 比第 i 个队列的时间片长一倍。

![image-20201020104833949](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvlvrwz0wj30f007z0tb.jpg)

当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待 调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一 个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第 三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第 n 队列后，在第 n 队列中便采取按时间片轮转的方式运行。

仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1)队 列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时， 又有新进程进入优先权较高的队列(第 1～(i-1)中的任何一个队列)，则此时新进程将抢占正 在运行进程的处理机，即由调度程序把正在运行的进程放回到第 i 队列的末尾，把处理机分 配给新到的高优先权进程。

### 2.8.6  实时调度

可以按不同方式对实时调度算法加以分类

- 根据实时任务（截止时间）性质的不同，
  - 硬实时调度算法：必须满足；
  - 软实时调度算法：尽最大努力；
- 周期性
  - 周期和非周期（非周期连着一个deadline）
- 按调度方式的不同，又可分为非抢占调度算法和抢占调度算法； 还可因调度程序调度时间的不同而分成静态调度算法和动态调 度算法，前者是指在进程执行前，调度程序便已经决定了各进程间的执行顺序，而后者则 是在进程的执行过程中，由调度程序届时根据情况临时决定将哪一进程投入运行。



## 2.9 死锁

### 2.9.1 相关概念

产生死锁的原因可归纳为：

(1) 竞争资源。当系统中供多个进程共享的资源如打印机、公用队列等，其数目不足以 满足诸进程的需要时，会引起诸进程对资源的竞争而产生死锁。

(2) 进程间推进顺序非法。进程在运行过程中，请求和释放资源的顺序不当，也同样会 导致产生进程死锁。

#### 定义

一组进（线）程中的每一个进（线）程都在等待仅由该组进（线）程中其他进（线）程才能引发的事件，那么该组进（线）程是死锁的Deadlock

#### 必要条件

虽然进程在运行过程中可能发生死锁，但死锁的发生也必须具备一定的条件。综上所 述不难看出，死锁的发生必须具备下列四个必要条件。

(1) 互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由 一个进程占用。如果此时还有其它进程请求该资源，则请求者只能等待，直至占有该资源 的进程用毕释放。

(2) 请求和保持条件：指进程已经保持了至少一个资源，但又提出了新的资源请求，而 该资源又已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。**这句话的对立含义：一次性把所有临界资源都分配该进程**

(3) 不剥夺条件（不可占用）：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完 时由自己释放。

(4) 环路等待条件：资源闭环，指在发生死锁时，必然存在一个进程——资源的环形链，即进程集 合{P0 ，P1 ，P2 ，…，Pn }中的 P 0 正在等待一个 P 1 占用的资源；P 1 正在等待 P 2 占用的资源，……， P n 正在等待已被 P 0 占用的资源。

总结一下：就是两点

- 资源具备不可占用性，且互斥；
- 进程之间占用的资源信号量循环等待；

#### 处理死锁方法

1 预防死锁：预先防止产生死锁。该方法是通过设置某些限制 条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来预防发生死锁。

2 避免死锁：该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施 去破坏产生死锁的四个必要条件，而是在资源的动态分配过程中，用某种方法去防止系统 进入不安全状态，从而避免发生死锁。

3 检测死锁：这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进 入不安全区，而是允许系统在运行过程中发生死锁。但可通过系统所设置的检测机构，及 时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源；

4 解除死锁。这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须 将进程从死锁状态中解脱出来。常用的实施方法是撤消或挂起一些进程，以便回收一些资 源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。

后面就围绕这几方面去讨论，预防、避免、检测、解除四个方面。

### 2.9.2 预防死锁

预防死锁的方法是使四个必要条件中的第 2、3、4 个条件之一不能成立，来避免发生 死锁。至于必要条件 1，因为它是由设备的固有特性所决定的，用户无法改变。

#### 破坏“请求和保持”

一次性把进程所需的所有临界资源都分配给他，或者说把进程运行初期所需的资源分配给他。这两种方式都是破坏 “请求和保持” ，第二种方式所需的代价比较小，因为进程涉及到很多的临界资源时，要想把所有的临界资源都准备好，代价太大，同样也存在资源的浪费，效率不高

#### 破坏“不可抢占”

就是允许某个进程P占用了某个临界资源R时，当有一个更高级的进程P1过来时，允许P1获取R资源的使用权，P进程释放该资源的使用权。这种方式的代价就是假如某个进程P已经完成了大部分工作，这时要求其释放资源，暂停工作，可能下次又要花费较长时间去运行之前已经完成的工作，这对于P进程存在反反复复的做某个进程中的部分工作，但却无法完成整个工作。

#### 破坏“循环等待”

这种方法中规定，系统将所有资源按类型进行线性排队，并赋予不同的序号。例如， 令输入机的序号为 1，打印机的序号为 2，磁带机为 3，磁盘为 4。**所有进程对资源的请求 必须严格按照资源序号递增的次序提出，这样，在所形成的资源分配图中，不可能再出现 环路**，因而摒弃了“环路等待”条件。事实上，在采用这种策略时，总有一个进程占据了 较高序号的资源，此后它继续申请的资源必然是空闲的，因而进程可以一直向前推进。

但也存在下述严重问题：某进程先用磁带机，后用打印机，但按系统规定，该进 程应先申请打印机而后申请磁带机，致使先获得的打印机被长时间闲置

### 2.9.3 避免死锁

在预防死锁的几种方法中，都施加了较强的限制条件；避免死锁也是预先预防的策略，并不是实现采取某种限制错死，而是在资源动态分配中，防止系统进入不安全状态来避免死锁。

#### 系统安全状态

在避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给 进程；否则，令进程等待。

虽然并非所有的不安全状态都必然会转为死锁状态，但当系统进入不安全状态后，便 有可能进而进入死锁状态；反之，只要系统处于安全状态，系统便可避免进入死锁状态。 因此，避免死锁的实质在于：系统在进行资源分配时，如何使系统不进入不安全状态。

> 例子：。假定系统中有三个进程 P1、P 2和 P3，共有 12 台磁带 机。进程 P 1 总共要求 10 台磁带机，P 2 和 P 3 分别要求 4 台和 9 台。假设在 T 0 时刻，进程 P1 、 P 2 和 P 3 已分别获得 5 台、2 台和 2 台磁带机，尚有 3 台空闲未分配，如下表所示：
>
> | 进程 | 最大需求 | 已 分 配 | 可用 |
> | ---- | -------- | -------- | ---- |
> | P1   | 10       | 5        | 3    |
> | P2   | 4        | 2        |      |
> | P3   | 9        | 2        |      |
>
> 分析发现，在 T 0时刻系统是安全的，因为这时存在一个安全序列〈P2，P1，P3〉，即 只要系统按此进程序列分配资源，就能使每个进程都顺利完成。例如，将剩余的磁带机取 2 台分配给 P2 ，使之继续运行，待 P 2 完成，便可释放出 4 台磁带机，于是可用资源增至 5 台； 以后再将这些全部分配给进程 P1 ，使之运行，待 P 1 完成后，将释放出 10 台磁带机，P 3 便 能获得足够的资源，从而使 P1 、P2 、P 3 每个进程都能顺利完成。

#### 系统不安全状态

如果不按照安全序列分配资源，则系统可能会由安全状态进入不安全状态。例如，在 T 0 时刻以后，P 3 又请求 1 台磁带机，若此时系统把剩余 3 台中的 1 台分配给 P3 ，则系统便 进入不安全状态。因为此时也无法再找到一个安全序列，例如，把其余的 2 台分配给 P2 ， 这样，在 P 2 完成后只能释放出 4 台，既不能满足 P 1 尚需 5 台的要求，也不能满足 P 3 尚需 6 台的要求，致使它们都无法推进到完成，彼此都在等待对方释放资源，即陷入僵局，结果 导致死锁。

#### 银行家算法

四个矩阵：

当前最大资源可用数目的矩阵Available Matrix ：

当前进程所需最大资源数目Max Matrix ：

当前进程已经分配的资源数目矩阵 Allocation Matrix

当前进程还需资源的数目矩阵Need Matrix

其中：Need = Max - Allocation，然后把当前进程申请的资源数目reqeust 和need 、available 相比，要小于他们才行。然后尝试着进行资源分配，再次计算上面四个矩阵值，然后看是否满足安全算法不。这个算法就是当把某个进程分配某个临界资源后，便计算其他进程所需的资源request 是否小于 Available ，当所有进程满足时，就是系统安全状态，然后才真正的分配，否则收回之前的试探分配。



### 2.9.4 解除死锁

#### 死锁检测

资源分配图

死锁定理

死锁检测数据结构



#### 锁锁解除

当发现有进程死锁时，便应立即把它们从死锁状态中解脱出来。常采用解除死锁的两 种方法是：

(1) 剥夺资源。从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态。

(2) 撤消进程。最简单的撤消进程的方法是使全部死锁进程都夭折掉；稍微温和一点的 方法是按照某种顺序逐个地撤消进程，直至有足够的资源可用，使死锁状态消除为止。



# 第三章 存储管理

这一章节讲的是计算机存储。主要有三部分内容，计算机存储相关概念，简单存储、虚拟存储。

## 3.1 存储相关概念

学校目标：

- 明白相关概念：重定位、逻辑/物理地址

现代计算机系统中，存储部件 通常是采用层次结构来组织的。存储层次至少应具有三级：最高层为 CPU 寄存器，中间为主存， 最底层是辅存。还可以根据具体的功能分工细划为

- 寄存器——cpu寄存器
- 高速缓 存、主存储器、磁盘缓存——主存
- 固定磁盘、可移动存储 —— 辅存

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1qc7yf6pj30q80dwmys.jpg" alt="image-20201025175606974" style="zoom:80%;" />

对于不同层次的存储介质，由操作系统进行统一管理。操作系统的存储管理，负责对可执行存储器（寄存器和主存储器被称为可执行存储器）的分配、回收以及提供在存储层次间数据移动的管理机制，例如主存与磁盘 缓存、高速缓存与主存间的数据移动等。在设备和文件管理中，根据用户的需求提供对辅 存的管理机制。

### 3.1.1 主存储器与寄存器

#### 1. 主存储器

也称可执行存储器，为数十 MB 到数 GB。

作用：

cpu从主存储器读取数据，在把数据放入寄存存储器；或者从寄存器存入到主存储器

#### 2 寄存器

寄存器的长度一般以字(word)为单位，寄存器访问速度最快，完全能与 CPU 协调工作。寄存器 用于加速存储器的访问速度，如用寄存器存放操作数，或用作地址寄存器加快地址转换速 度等。

> 一个文件的数据可能出现在存储器层次的不同级别中，例如，一个文件数据通常被存 储在辅存中(如硬盘)，当其需要运行或被访问时，就必须调入主存，也可以暂时存放在主存 的磁盘高速缓存中。大容量的辅存常常使用磁盘，磁盘数据经常备份到磁带或可移动磁盘 组上，以防止硬盘故障时丢失数据。

注意：断电后，只有辅存中的数据还在，主存和寄存器中的数据都会丢失掉。

### 3.1.2 高速缓存和磁盘缓存

#### 高速缓存

其容量大于或远大于寄存器，而比内 存约小两到三个数量级左右，从几十 KB 到几 MB，访问速度快于主存储器。

作用：将主存中一些经常访问的信息存放在高速缓存中，减少访 问主存储器的次数，可大幅度提高程序执行速度。

> 通常，进程的程序和数据是存放在主存 储器中，每当使用时，被临时复制到一个速度较快的高速缓存中。当 CPU 访问一组特定信 息时，首先检查它是否在高速缓存中，如果已存在，可直接从中取出使用，以避免访问主 存，否则，再从主存中读出信息。如大多数计算机有指令高速缓存，用来暂存下一条欲执 行的指令，如果没有指令高速缓存，CPU 将会空等若干个周期，直到下一条指令从主存中 取出。现在也有很多级高速缓存。

#### 磁盘缓存

磁盘的 I/O 速度远低于对主存的访问速度，因此将频繁使用的一部分磁盘数据 和信息，暂时存放在磁盘缓存中，可减少访问磁盘的次数。其设计目的和高速缓存一样，加速对硬盘的访问速度。

## 3.2 程序链接

要程序运行，必须先为之创建进程。而创建进程的第一件事， 便是将程序和数据装入内存。如何将一个用户源程序变为一个可在内存中执行的程序，通 常都要经过以下几个步骤：首先是要编译，由编译程序(Compiler)将用户源代码编译成若干个目标模块(Object Module)；其次是链接，由链接程序(Linker)将编译后形成的一组目标模块(Load Module)；最后 是装入，由装入程序(Loader)将模块装入内存。

现在讨论一下链接：通常有下面链接方式 静态链接、装入时链接、运行时动态链接；

### 静态链接

在编译时，如果知道程序将驻留在内存的什么位置，那么，编译程序将产生绝对地址 的目标代码。例如，事先已知用户程序(进程)驻留在从 R 处开始的位置，则编译程序所产生 的目标模块(即装入模块)便从 R 处开始向上扩展。绝对装入程序按照装入模块中的地址，将 程序和数据装入内存。装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址完 全相同，故不须对程序和数据的地址进行修改。

程序中所使用的绝对地址，既可在编译或汇编时给出，也可由程序员直接赋予。但在 由程序员直接给出绝对地址时，不仅要求程序员熟悉内存的使用情况，而且一旦程序或数 据被修改后，可能要改变程序中的所有地址。因此，通常是宁可在程序中采用符号地址， 然后在编译或汇编时，再将这些符号地址转换为绝对地址。方式只适用于单道程序环境，多道程序运行时，可能会出现程序交换或者并发等情况，不能采用此方式。

### 装入时链接

在多道程序环境下，所得到的目标模块的起始地址通常是从 0 开始的，程序 中的其它地址也都是相对于起始地址计算的。此时应采用可重定位装入方式，根据内存的 当前情况，将装入模块装入到内存的适当位置。通常是把在装入时对目标 程序中指令和数据的修改过程称为重定位。又因为地址变换通常是在装入时一次完成的， 以后不再改变，故称为静态重定位。

### 运行时动态链接

这是指对某些目标模块的链接，是在程序执行中需要该(目标)模 块时，才对它进行的链接。

在许多情况下，应用程序在运行时，每次要运行的模块可能是不相同的。但由于事先 无法知道本次要运行哪些模块，故只能是将所有可能要运行到的模块都全部装入内存，并 在装入时全部链接在一起。显然这是低效的，因为往往会有些目标模块根本就不运行。比 较典型的例子是作为错误处理用的目标模块，如果程序在整个运行过程中都不出现错误， 则显然就不会用到该模块。 

近几年流行起来的运行时动态链接方式，是对上述在装入时链接方式的一种改进。这 种链接方式是将对某些模块的链接推迟到程序执行时才进行链接，亦即，在执行过程中， 当发现一个被调用模块尚未装入内存时，立即由 OS 去找到该模块并将之装入内存，把它链 接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到 装入模块上，这样不仅可加快程序的装入过程，而且可节省大量的内存空间。

## 3.3 连续分配存储

### 3.1.1 连续分区

把内存分为系统区和用户区两部分，系统区仅提供给 OS 使用，通常 是放在内存的低址部分；用户区是指除系统区以外的全部内存空间，提供给用户使用。

适用：一种存储管理方式，但只能用于单用户、单任务的操作系统中。

### 3.1.2 固定分区

此种分配方式把内存空间分为固定大小的区域，每个分区允许一个作业被装入。分区大小可以不相同。通常会建立一张分区使用表来记录每个分区的起始地址、分区大小、状态。没有足够大的分区则拒绝分配内存。此种分配方式是最早的多道程序的存储管理方式。

缺点：限制了进程的数目，内存空间利用率比较低。比如说只有4个分区，则只能允许最多四个程序运行。其他的程序必须等待其中的一个运行完后才能运行。

### 3.1.3 动态分区

动态分区分配是根据进程的实际需要，动态地为之分配内存空间。在实现可变分区分 配时，将涉及到分区分配中所用的数据结构、分区分配算法和分区的分配与回收操作这样 三个问题。因为是动态的，必须要有相关的数据结构描述对象，相应的算法，已经涉及到的相关问题。这个动态可类比固定分区，解决了进程最大运行数目问题。

#### 数据结构

#### 分配算法

##### 基于顺序搜索的动态分区分配算法

**首次适应**

要求空闲分区链以 地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要 求的空闲分区为止；然后再按照作业的大小，从该分区中划出一块内存空间分配给请求者， 余下的空闲分区仍留在空闲链中。若从链首直至链尾都不能找到一个能满足要求的分区， 则此次内存分配失败，返回

**循环首次适应算法**

在首次适应算法上，不在从开始查找。从上次找到的空闲分区下一个分区开始查找。

**最佳适应算法**

指每次为作业分配内存时，总是把能满足要求的最小的内存分区分配给作业，避免“大材小用”。

**最坏适应算法**

 选择最大的空闲分区，然后进行分配 

##### 基于索引搜索的动态分区分配算法

**快速适应算法**

也叫分类搜索算法，采取分区表加上相同类别管理的链表进行记录，仅需根据进程的长度，即可分配相应的内存空间。就是把内存剩余空间的大小进行分类，再去匹配进程需求。

**伙伴系统**

**哈希算法**

#### 内存回收

### 3.1.4 动态可重定位分区

此种算法考虑到的情况是：有很多内存碎片。对于一个进程来说，没有任何一个碎片能够满足进程所需的容量要求，但是碎片的容量总和能够满足一个或者多个进程的容量要求。

解决方案：①把内存中的所有作业全部移动，让他们紧凑在一起，这样内存碎片便集中在一起了。（需要对移动的程序地址进行修改才行）

分区分配算法：与动态分区分配算法类似，不过多了“紧凑”的操作。

### 3.1.5 对换swapping

将占用内存却没有干什么事情的进程给放到外存。这样来提升内存的使用效率。

#### 引入背景

在多道程序环境下，一方面，在内存中的某些进程由于某事件尚未发生而被阻塞运行， 但它却占用了大量的内存空间，甚至有时可能出现在内存中所有进程都被阻塞而迫使 CPU 停止下来等待的情况；另一方面，却又有着许多作业在外存上等待，因无内存而不能进入 内存运行的情况。显然这对系统资源是一种严重的浪费，且使系统吞吐量下降。为了解决 这一问题，在系统中又增设了对换(也称交换)设施。

在具有对换功能的 OS 中，通常把外存分为文件区和对换区。前者用于存放文件，后者 用于存放从内存换出的进程。

换入：每当一进程由于创建子进程而需要更多的内存空间，但又无足够的内 存空间等情况发生时，系统应将某进程换出。其过程是：系统首先选择处于阻塞状态且优 先级最低的进程作为换出进程，然后启动磁盘，将该进程的程序和数据传送到磁盘的对换 区上。若传送过程未出现错误，便可回收该进程所占用的内存空间，并对该进程的进程控 制块做相应的修改。

换出：系统应定时地查看所有进程的状态，从中找出“就绪”状态但已换出 的进程，将其中换出时间最久(换出到磁盘上)的进程作为换入进程

## 3.4 分页、分段离散存储管理内存

分区是连续分配内存管理方法，分页和分段都是离散方式来管理内存的，根据离散分配的基本单位是不同，可以有以下几种方式：

- 分页存储管理方式：用户程序地址分为若干大小固定的区域，称为“页”
- 分段存储管理：把用户程序的地址空间分为若干个大小不同的段，每段可定义一组相对完整的信息。
- 页段式存储管理：把上述两种方式结合一起。

> 内存的分段和分页管理方式和由此衍生的一堆段页式等都属于内存的**不连续分配**。什么叫不连续分配？就是把程序分割成一块一块的装入内存，在物理上不用彼此相连，在逻辑上使用段表或者页表将离散分布的这些小块串起来形成逻辑上连续的程序。

比如说分段就是将一个程序分成代码段，数据段，堆栈段什么的。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk59qw73ddj30iw0fbq5s.jpg" alt="image-20201028192417262" style="zoom:67%;" />

分页就是将这些段，例如代码段分成均匀的小块，然后这些给这些小块编号，然后就可以放到内存中去，由于编号了的，所以也不怕顺序乱

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk59rl3x7nj30k00eu0t1.jpg" alt="img" style="zoom:67%;" />

然后我们就能通过段号，页号，页内偏移找到程序的地址

![img](https://tva1.sinaimg.cn/large/0081Kckwgy1gk59se15qej30k006kt8q.jpg)

分页、分段、加上对换swapping、以及程序的局部运行的想象奠定了虚拟内存技术。

### 分页的基本概念

1．页面

1) 页面和物理块

分页存储管理是将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页， 并为各页加以编号，从 0 开始，如第 0 页、第 1 页等。相应地，也把内存空间分成与页面 相同大小的若干个存储块，称为(物理)块或页框(frame)，也同样为它们加以编号，如 0# 块、 1# 块等等。在为进程分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相 邻接的物理块中。由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为 “页内碎片”。

2) 页面大小

在分页系统中的页面其大小应适中。页面若太小，一方面虽然可使内存碎片减小，从 而减少了内存碎片的总空间，有利于提高内存利用率，但另一方面也会使每个进程占用较 多的页面，从而导致进程的页表过长，占用大量内存；此外，还会降低页面换进换出的效 率。然而，如果选择的页面较大，虽然可以减少页表的长度，提高页面换进换出的速度， 但却又会使页内碎片增大。因此，页面的大小应选择适中，且页面大小应是 2 的幂，通常 为 512 B～8 KB。

2 页表

在分页系统中，允许将进程的各个页离散地存储在内存不同的物理块中，但系统应能 保证进程的正确运行，即能在内存中找到每个页面所对应的物理块。为此，系统又为每个 进程建立了一张页面映像表，简称页表。在进程地址空间内的所有页(0～n)，依次在页表中 有一页表项，其中记录了相应页在内存中对应的物理块号，在配置 了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表 的作用是实现从页号到物理块号的地址映射。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk5a0m7f7wj30c508emxl.jpg" alt="image-20201028193340684" style="zoom:80%;" />

3 抵制转换机构

为了能将用户地址空间中的逻辑地址变换为内存空间中的物理地址，在系统中必须设 置地址变换机构——页表寄存器。

### 分段存储

#### 分段的引入

1) 方便编程

通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从 0 开始编址， 并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名(段号)和段内偏移量(段内 地址)决定的。

2) 信息共享

在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，共享某个例程 和函数。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的意义，不便于实现 共享；然而段却是信息的逻辑单位。由此可知，为了实现段的共享，希望存储管理能与用 户程序分段的组织方式相适应。

3) 信息保护

信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地 实现信息保护功能。

4) 动态增长

在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又 无法确切地知道数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动 态增长的情况，而分段存储管理方式却能较好地解决这一问题。

5) 动态链接

动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主 程序所对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段(目 标程序)调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。

#### 基本原理

##### 1 分段

在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑 信息。例如，有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等，如图 4-17 所示。每 个段都有自己的名字。为了实现简单起见，通常可用一个段号来代替段名，每个段都从 0 开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因而 各段长度不等。整个作业的地址空间由于是分成多个段，因而是二维的，亦即，其逻辑地 址由段号(段名)和段内地址所组成。 分段地址中的地址具有如下结构：

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk5abiwx02j30di035jrc.jpg" alt="image-20201028194410013" style="zoom:80%;" />

##### 2 段表

同页表的作用一样。实现从逻辑段到物理内存区的映射

##### 3 地址变换机构

为了实现从进程的逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用 于存放段表始址和段表长度 TL。

### 分段和分页区别

分页和分段系统有许多相似之处。比如，两者都采用离散分配方 式，且都要通过地址映射机构来实现地址变换。但在概念上两者完全不同，主要表现在下 述三个方面。

(1) 页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内 存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的 逻辑单位， 它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的 需要。

(2) 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是 由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度却不固定，决定于 用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。

(3) 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆 符，即可表示一个地址；而分段的作业地址空间则是二维的，程序员在标识一个地址时， 既需给出段名，又需给出段内地址。

## 3.5 虚拟存储器

前面所介绍的各种存储器管理方式有一个共同的特点，即它们都要求将一个作业全部 装入内存后方能运行，于是，出现了下面这样两种情况：

(1) 有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部被装入内存， 致使该作业无法运行。

(2) 有大量作业要求运行，但由于内存容量不足以容纳所有这些作业，只能将少数作业 装入内存让它们先运行，而将其它大量的作业留在外存上等待。 出现上述两种情况的原因，都是由于内存容量不够大。一个显而易见的解决方法，是 从物理上增加内存容量，但这往往会受到机器自身的限制，而且无疑要增加系统成本，因 此这种方法是受到一定限制的。另一种方法是从逻辑上扩充内存容量，这正是虚拟存储技 术所要解决的主要问题。

因为上面虽然采取了离散存储方式，但不能解决有的作业大要求的内存多（超出了物理内存大小），无法去运行这样的作业。这样就引入了虚拟存储，增加逻辑内存大小。如何做到呢？

### 虚拟存储器引入

1．**常规存储器管理方式的特征**

(1) 一次性。在前面所介绍的几种存储管理方式中，都要求将作业全部装入内存后方能 运行，即作业在运行前需一次性地全部装入内存，而正是这一特征导致了上述两种情况的 发生。

(2) 驻留性。作业装入内存后，便一直驻留在内存中，直至作业运行结束。尽管运行中 的进程会因 I/O 而长期等待，或有的程序模块在运行过一次后就不再需要(运行)了，但它们 都仍将继续占用宝贵的内存资源。 由此可以看出，上述的一次性及驻留性，使许多在程序运行中不用或暂不用的程序(数 据)占据了大量的内存空间，使得一些需要运行的作业无法装入运行。现在要研究的问题是： 一次性及驻留性在程序运行时是否是必需的。

2．**程序运行局部性原理**

程序在执行时将呈现出局部性规律，即在一较短 的时间内，程序的执行仅局限于某个部分；相应地，它所访问的存储空间也局限于某个区 域。关于这个可以去了解更多，知道有这个特性就行了。

3．**虚拟存储器的定义** 

基于局部性原理，应用程序在运行之前，没有必要全部装入内存，仅须将那些当前要 运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。程序在运行时，如果它 所要访问的页(段)已调入内存，便可继续执行下去；但如果程序所要访问的页(段)尚未调入 内存(称为缺页或缺段)，此时程序应利用 OS 所提供的请求调页(段)功能，将它们调入内存， 以使进程能继续执行下去。如果此时内存已满，无法再装入新的页(段)，则还须再利用页(段)的置换功能，将内存中暂时不用的页(段)调至盘上，腾出足够的内存空间后，再将要访问的 页(段)调入内存，使程序继续执行下去。这样，便可使一个大的用户程序能在较小的内存空 间中运行；也可在内存中同时装入更多的进程使它们并发执行。从用户角度看，该系统所 具有的内存容量，将比实际内存容量大得多。但须说明，用户所看到的大容量只是一种感 觉，是虚的，故人们把这样的存储器称为虚拟存储器。

**所谓虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑 上对内存容量加以扩充的一种存储器系统。其逻辑容量由内存容量和外存容量之和所决定， 其运行速度接近于内存速度，而每位的成本却又接近于外存。**

### 虚拟存储器的特征

1．多次性 多次性是指一个作业被分成多次调入内存运行，亦即在作业运行时没有必要将其全部装 入，只需将当前要运行的那部分程序和数据装入内存即可；以后每当要运行到尚未调入的那 部分程序时，再将它调入。多次性是虚拟存储器最重要的特征，任何其它的存储管理方式都 不具有这一特征。因此，我们也可以认为虚拟存储器是具有多次性特征的存储器系统。

2．对换性

对换性是指允许在作业的运行过程中进行换进、换出，亦即，在进程运行期间，允许 将那些暂不使用的程序和数据，从内存调至外存的对换区(换出)，待以后需要时再将它们从 外存调至内存(换进)；甚至还允许将暂时不运行的进程调至外存，待它们重又具备运行条件 时再调入内存。换进和换出能有效地提高内存利用率。可见，虚拟存储器具有对换性特征。

3．虚拟性

虚拟性是指能够从逻辑上扩充内存容量，使用户所看到的内存容量远大于实际内存容 量。这是虚拟存储器所表现出来的最重要的特征，也是实现虚拟存储器的最重要的目标。

**虚拟性是以多次性和对换性为基础的，而多次性和对换性又是以离散存储为基础。**

## 3.6 请求分页存储管理

请求分页系统是建立在基本分页基础（这就是3.4中讲的分页离散存储）上的，为了能支持虚拟存储器功能而增加了请求 调页功能和页面置换功能。相应地，每次调入和换出的基本单位都是长度固定的页面，这 使得请求分页系统在实现上要比请求分段系统简单(后者在换进和换出时是可变长度的段)。 因此，请求分页便成为目前最常用的一种实现虚拟存储器的方式。

### 3.6.1 硬件支持

为了实现请求分页，系统必须提供一定的硬件支持。除了需要一台具有一定容量的内 存及外存的计算机系统外，还需要有页表机制、缺页中断机构以及地址变换机构。

#### 1．页表机制 

在请求分页系统中所需要的主要数据结构是页表。其基本作用仍然是将用户地址空间中的逻辑地址变换为内存空间中的物理地址。由于只将应用程序的一部分调入内存，还有 一部分仍在盘上，故须在页表中再增加若干项，供程序(数据)在换进、换出时参考。

#### 2．缺页中断机构

在请求分页系统中，每当所要访问的页面不在内存时，便产生一缺页中断，请求 OS 将 所缺之页调入内存。缺页中断作为中断，它们同样需要经历诸如保护 CPU 环境、分析中断 原因、转入缺页中断处理程序进行处理、恢复 CPU 环境等几个步骤。

#### 3．地址变换机构

 请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，再为实现虚 拟存储器而增加了某些功能而形成的，如产生和处理缺页中断，以及从内存中换出一页的 功能等等。

### 3.6.2 内存分配策略和分配算法**

在为进程分配内存时，将涉及到三个问题：第一，最小物理块数的确定；第二，物理块的分配策略(固定的，还是可变的)；第三，物理块的分配算法。

#### 1．最小物理块数的确定

这里所说的最小物理块数，是指能保证进程正常运行所需的最小物理块数。当系统为 进程分配的物理块数少于此值时，进程将无法运行。进程应获得的最少物理块数与计算机 的硬件结构有关，取决于指令的格式、功能和寻址方式。对于某些简单的机器，若是单地 址指令且采用直接寻址方式，则所需的最少物理块数为 2。其中，一块是用于存放指令的页 面，另一块则是用于存放数据的页面。如果该机器允许间接寻址时，则至少要求有三个物 理块。

#### 2．物理块的分配策略

在请求分页系统中，可采取两种内存分配策略，即固定和可变分配策略。在进行置换 时，也可采取两种策略，即全局置换和局部置换。于是可组合出以下三种适用的策略。

**1) 固定分配局部置换(Fixed Allocation，Local Replacement)**

这是指基于进程的类型(交互型或批处理型等)，或根据程序员、程序管理员的建议，为 每个进程分配一定数目的物理块，在整个运行期间都不再改变。采用该策略时，如果进程 在运行中发现缺页，则只能从该进程在内存的 n 个页面中选出一个页换出，然后再调入一 页，以保证分配给该进程的内存空间不变。实现这种策略的困难在于：应为每个进程分配 多少个物理块难以确定。若太少，会频繁地出现缺页中断，降低了系统的吞吐量；若太多， 又必然使内存中驻留的进程数目减少，进而可能造成 CPU 空闲或其它资源空闲的情况，而 且在实现进程对换时，会花费更多的时间。

**2) 可变分配全局置换(Variable Allocation，Global Replacement)**

**3) 可变分配局部置换(Variable Allocation，Local Replacement)**

#### 3 物理块分配算法

- 平均分配算法
- 按比例分配算法
- 按优先权分配

### 3.6.3 调页策略

使进程正常执行，事先将要执行的<u>**部分**</u>程序和数据调入内存，至此，要考虑的问题：

1. 系统应在何时考虑调入这些页面？
2. 系统从何处调入这些页面？
3. 如何进行调入？

#### 何时调入页面？

为了确定系统将进程运行时所缺的页面调入内存的时机，可采取预调页策略或请求调 页策略。预先调页由于无法确定要调用哪一页，故发生缺页时再去调用。调入过程如下：

每当程序所要访问的页面未在内存时，便向 CPU 发出一缺页中断，中断处理程序首先 保留 CPU 环境，分析中断原因后转入缺页中断处理程序。该程序通过查找页表，得到该页 在外存的物理块后，如果此时内存能容纳新页，则启动磁盘 I/O 将所缺之页调入内存，然后 修改页表。如果内存已满，则须先按照某种置换算法从内存中选出一页准备换出；如果该 页未被修改过，可不必将该页写回磁盘；但如果此页已被修改，则必须将它写回磁盘，然 后再把所缺的页调入内存，并修改页表中的相应表项，置其存在位为“1”，并将此页表项 写入快表中。在缺页调入内存后，利用修改后的页表，去形成所要访问数据的物理地址， 再去访问内存数据。整个页面的调入过程对用户是透明的。

#### 从何处调入这些页面？

请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘I/O速度比文件区的更快。这样从何处调入页面有三种情况：

1. 1. 系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。
   2. 系统缺少足够的对换区空间：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。
   3. UNIX方式：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。

#### 页面调入过程

每当程序所要访问的页面未在内存时，便向cpu发出 缺页中断 请求，中断程序保护cou环境，分析原因后转入缺页中断程序。

程序查找页表得到该页在外存的物理块，若内存此时能够容纳新页，则调入；若内存已满，则选用某种置换算法，从内存中选中一页并替换。（同时还要注意该页有没有被修改过，修改过处理方式不一样）

#### 缺页率

假设一个进程逻辑分页n，系统为其分配的物理内存块数为m （m <= n）运行中，访问页面成功次数为S， 失败的次数为F，则缺页率为

f = F /（S + F）；

通常，缺页率由以下因素影响：

- 页面大小 ——页越大，缺页率越低；反之，越高；
- 进程所分配的物理块数目 —— 越多缺页率越低；
- 页面置换算法——取决算法的好坏
- 程序编写对缺页中断的影响。（这个可以类比android 系统中的内存抖动的因素）

## 3.7 请求分段存储管理

在请求分段系统中，程序运行之前，只需先调入若干个分段(不必调入所有的分段)，便 可启动运行。当所访问的段不在内存中时，可请求 OS 将所缺的段调入内存。像请求分页系 统一样，为实现请求分段存储管理方式，同样需要一定的硬件支持和相应的软件。

### 3.7.1 请求分段中的硬件支持

请求分段管理所需的硬件支持有段表机制、缺段中断机构，以及地址变换机构。和请求分页系统和类似。

#### 1．段表机制

在请求分段式管理中所需的主要数据结构是段表。由于在应用程序的许多段中，只有 一部分段装入内存，其余的一些段仍留在外存上，故须在段表中增加若干项，以供程序在 调进、调出时参考。

|      |      |        |          |          |        |        |        |          |
| ---- | ---- | ------ | -------- | -------- | ------ | ------ | ------ | -------- |
| 段名 | 段长 | 段地址 | 存取方式 | 访问字段 | 修改位 | 存在位 | 增补位 | 外存始址 |

在段表项中，除了段名(号)、段长、段在内存中的起始地址外，还增加了以下诸项。

(1) 存取方式：用于标识本分段的存取属性是只执行、只读，还是允许读/写。

(2) 访问字段 A：其含义与请求分页的相应字段相同，用于记录该段被访问的频繁程度。

(3) 修改位 M：用于表示该页在进入内存后是否已被修改过，供置换页面时参考。

(4) 存在位 P：指示本段是否已调入内存，供程序访问时参考。

(5) 增补位：这是请求分段式管理中所特有的字段，用于表示本段在运行过程中是否做 过动态增长。

(6) 外存始址：指示本段在外存中的起始地址，即起始盘块号。

#### 2．缺段中断机构 

每当发现运行进程所要访问的段尚未调入内存时，便由缺段中断机 构产生一缺段中断信号，进入 OS 后由缺段中断处理程序将所需的段调入内存。

![image-20201029112239470](https://tva1.sinaimg.cn/large/0081Kckwgy1gk61g0tbzfj30g60bvdh1.jpg)

#### 3．地址变换机构 

请求分段系统中的地址变换机构是在分段系统地址变换机构的基础上形成的。因为被 访问的段并非全在内存，所以在地址变换时，若发现所要访问的段不在内存，必须先将所 缺的段调入内存，并修改段表，然后才能再利用段表进行地址变换。

![image-20201029112343052](https://tva1.sinaimg.cn/large/0081Kckwgy1gk61h4ovacj30do0c90tw.jpg)

### 3.7.2 分段的共享和保护

#### 共享分段

分段存储管理方式便于实现分段的共享与保护，也扼要地介绍了 实现分段共享的方法。下面进一步讲解分段共享实现。

1．**共享段表**

为了实现分段共享，可在系统中配置一张共享段表，所有各共享段都在共享段表中占 有一表项。表项中记录了共享段的段号、段长、内存始址、存在位等信息，并记录了共享 此分段的每个进程的情况。

![image-20201029155243030](https://tva1.sinaimg.cn/large/0081Kckwgy1gk6991q32zj30iy062jrv.jpg)

(1) 共享进程计数 count。非共享段仅为一个进程所需要。当进程不再需要该段时，可 立即释放该段，并由系统回收该段所占用的空间。而共享段是为多个进程所需要的，当某 进程不再需要而释放它时，系统并不回收该段所占内存区，仅当所有共享该段的进程全都 不再需要它时，才由系统回收该段所占内存区。为了记录有多少个进程需要共享该分段， 特设置了一个整型变量 count。

(2) 存取控制字段。对于一个共享段，应给不同的进程以不同的存取权限。例如，对于 文件主，通常允许他读和写；而对其它进程，则可能只允许读，甚至只允许执行。

(3) 段号。对于一个共享段，不同的进程可以各用不同的段号去共享该段。

2 **分配和回收**

由于共享段是供多个进程所共享的，每增加一个进程其count 应加1，回收时则应减1，当count= 0 才能回收。

#### 分段保护

在分段系统中，由于每个分段在逻辑上是独立的，因而比较容易实现信息保护。

1) 越界检查

在段表寄存器中放有段表长度信息；同样，在段表中也为每个段设置有段长字段。在 进行存储访问时，首先将逻辑地址空间的段号与段表长度进行比较，如果段号等于或大于 段表长度，将发出地址越界中断信号；其次，还要检查段内地址是否等于或大于段长，若 大于段长，将产生地址越界中断信号，从而保证了每个进程只能在自己的地址空间内运行。

2） 存取控制检查

(1) 只读，即只允许进程对该段中的程序或数据进行读访问。

(2) 只执行，即只允许进程调用该段去执行，但不准读该段的内容，也不允许对该段执 行写操作。

(3) 读/写，即允许进程对该段进行读/写访问。

对于共享段而言，存取控制就显得尤为重要，因而对不同的进程，应赋予不同的读写 权限。这时，既要保证信息的安全性，又要满足运行需要。

3) 环保护机构

这是一种功能较完善的保护机制。在该机制中规定：低编号的环具有高优先权。OS 核 心处于 0 环内；某些重要的实用程序和操作系统服务占居中间环；而一般的应用程序则被 安排在外环上。在环系统中，程序的访问和调用应遵循以下规则：

(1) 一个程序可以访问驻留在相同环或较低特权环中的数据。

(2) 一个程序可以调用驻留在相同环或较高特权环中的服务。

![image-20201029155744625](https://tva1.sinaimg.cn/large/0081Kckwgy1gk69e95jq5j30gn06idgm.jpg)

## 3.8 页面置换与 “抖动”

在进程运行过程中，若其所要访问的页面不在内存而需把它们调入内存，但内存已无 空闲空间时，为了保证该进程能正常运行，系统必须从内存中调出一页程序或数据送磁盘 的对换区中。但应将哪个页面调出，须根据一定的算法来确定。通常，把选择换出页面的 算法称为页面置换算法(Page-Replacement Algorithms)。置换算法的好坏，将直接影响到系统 的性能。这就是页面置换的背景。

### 置换算法

#### 1 最佳置换算法

**最佳置换算法是一种理论上的算法。其所选择的被淘汰页面， 将是以后永不使用的，或许是在最长(未来)时间内不再被访问的页面**。采用最佳置换算法， 通常可保证获得最低的缺页率。但由于人们目前还无法预知一个进程在内存的若干个页面 中，哪一个页面是未来最长时间内不再被访问的，**因而该算法是无法实现的，但可以利用 该算法去评价其它算法**。

#### 2 先进先出(FIFO)页面置换算法

该算法总是淘汰最先进入内存的页面，即选择在内存中驻 留时间最久的页面予以淘汰。类似于队列的实现原理。但其缺点是：最先进入的页面假如是全局变量这种经常使用的，该算法不合适。

#### 3 最近最久未使用(LRU)置换算法

LRU 算法算是比较常用和熟悉的一点了。选择最近最久未 使用的页面予以淘汰。在系统采取这种方法，必须要有硬件支持才行的。下面分析一下硬件特征：移位寄存器和栈

#### 4 CLock 置换算法

是LRU的近似算法。思想：

> 为每页设置一位访问位，再将内存中的所有页面都通过 链接指针链接成一个循环队列。当某页被访问时，其访问位被置 1。置换算法在选择一页淘 汰时，只需检查页的访问位。如果是 0，就选择该页换出；若为 1，则重新将它置 0，暂不 换出，而给该页第二次驻留内存的机会，再按照 FIFO 算法检查下一个页面。

### 进程抖动

虚拟分页请求内存管理系统以离散内存分配为基础，通过多道性、对换性技术，加上程序运行的局部性原理，使得逻辑内存大于物理内存，极大的提高了系统吞吐，程序的并发执行。明白万事有一个度，不可能极大的增加进程数，如果实际内存较小，为每个进程分配的物理块不多，但同时运行的进程很多，这个时候会发生什么呢？进程频繁的出现缺页，请求系统将所缺的页调人内存；当大多进程都出现内存缺页时，每个进程向cpu发出的指令都是请求/置换页（A进程把a页面调入，B进程又把A进程的a页拿走了执行B，这时候cpu先把A进程换出，再把a给B；之后A进程又获取了cpu 又把a页拿回去，导致反反复复的抢夺内存物理块），致使进程不能执行真正有意义的工作，都浪费在页面的置换上了，而且是反复执行这个过程，每个迟迟不能执行完退出。这时候就称之为 进程抖动。

> 刚被置换出去的页，很快又要访问，因而要把它重新调入；可是调入不 久又再次被置换出去，这样再访问、再调入，如此反复，使得整个系统的页面替换非常频繁，以致大部分的机器时间都花在来回进行的页面调度上，只有一小部分时 间用于进程的实际运算。这种局面就称为**系统“抖动”**

![image-20201029171119833](https://tva1.sinaimg.cn/large/0081Kckwgy1gk6bit3mfwj30ye0fo400.jpg)

#### **工作集**

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk9qlvue30j31c50u0npg.jpg" alt="image-20201029173601662" style="zoom:67%;" />

工作集（或驻留集）是指在某段时间间隔内，进程要访问的页面集合。经常被使用的页面需要在工作集中，而长期不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小。

工作集模型的原理是：让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。如果还有空闲物理块，则可以再调一个进程到内存以增加多道程序数。如果所有工作集之和增加以至于超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。

由于事先并不知道进程会使用到哪些内存，所以这个工作集的确定是在进程执行后，根据一定的策略确定的，比如对刚刚运行的进程所使用的内存作为参考看为当前工作集，这样每次对过去一段时间进程的运行情况分析得到相应的工作集，所以工作集是动态改变的，不固定的。

#### 预防抖动方法

**a) 采取局部置换策略**

仅允许进程在自身范围内进行置换。即使发生抖动，也可以把影响限制在较小范围内。不能采取全局替换，这样可能替换到其他进程正在使用的页，这样会打断其他进程的运行；

**b) 在处理机调度中引入工作集策略**

- 操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。
- 如果所有工作集之和增加到超过了可用物理块的总数，操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。

**c) 用 L=S 准则调节缺页率**

L：缺页之间的平均时间（两次缺页之间的时间差）。S：平均缺页服务时间（用于置换一个页面所需时间）

- L 大于 S，很少缺页，磁盘能力没有被充分利用。
- L 小于 S，频繁缺页，超过磁盘的处理能力。

调整并发程序度，使得 L 与 S 接近。这种情况下，磁盘和处理机到可以达到最佳利用率。

**d) 挂起若干进程**

当多道程序度偏高，已影响到处理机的利用率时，为了防止发生抖动，系统必须减少多道程序的数目。把某些低优先级的进程挂起，从而腾出内存空间。



# 第四章 设备管理

## 4.1 I/O系统设计

### 4.1.1 I/O 系统基本功能

#### **设备无关性**

隐藏物理设备的细节，用逻辑设备替代物理设备，提供统一的逻辑命令，然后硬件控制层把逻辑命令转化为对应的物理设备命令。

#### 效率

I/O设备的读写速度远远低于内存和cpu速度，必须采用一些方式提升效率。

### 4.1.2 I/O层次结构

I/O软件向下与硬件相关，向上和文件系统、存储系统、用户的应用程序关联。必须设计好I/O的实现，方能使其协调工作。

#### 软件层次结构

![文件分层结构](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm5nmmehnj30b108t404.jpg)



用户进程：指的是用户层面软件，与用户交互的接口，用户可调用改层提供的I/O相关的库函数对设备进行操作；

设备硬件无关层：也叫设备独立性软件。 实现设备映射功能，把逻辑I/O设备映射到物理I/O设备；（实现用户程序和设备驱动程序的统一接口、设备命令、保护、分配等操作，还提供数据传输的内存空间）

设备硬件相关层：实现设备驱动功能，控制物理I/O设备以便完成实际的I/O操作；这一层一般包含两层 设备驱动、中断程序

- 设备驱动程序：对设备发出设备独立性软件转化的设备命令
- 中断处理程序：保存被中断的进程cpu环境，转向中断处理程序，执行I/O操作；执行完后返回到被中断的程序；

设备硬件：真正的物理设备；



![image-20201112101249356](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm63q2f3uj31ng0ockjl.jpg)



#### 各模块之间的层次结构图

![image-20201112102423215](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm6fsvzpfj314t0u01kz.jpg)



中断信号是由设备控制器发出来的。I/O系统由：设备无关软件、驱动程序、设备管理器（从上到下）

### 4.1.3 I/O 系统接口

I/O系统与高层之间的接口中，根据设备类型不同，进一步分为若干个借口，分为块设备借口、流设备接口、网络接口；

**块设备接口**

块设备管理程序和高层之间的接口，块设备指的数据存取、传输都是以数据块为单位的设备，比如大部分的磁盘、光盘存储器设备，他们存储容量大、传输效率高。

**流设备接口**

流设备接口是流设备管理程序与高层之间的接口。反映了流设备的本质特征。流设备指的是传输、存取以字符为单位的设备，比如打印机、键盘、鼠标等。其特征传输效率低，一般几个字节到数千字节每秒。

**网络通信接口**

操作系统一般提供网络软件和通信接口。具体见后面。

### 4.1.4 I/O 设备分类

I/O 设备的类型繁多，从 OS 观点看，其重要的性能指标有: 设备使用特性、数据传输 速率、数据的传输单位、设备共享属性等。因而可从不同角度对它们进行分类。

1) **按设备的使用特性分类**

第一类是存储设备、第二类就是输入/输出设备

2) **按传输速率分类**

- 低速设备，这是指其传输速率仅 为每秒钟几个字节至数百个字节的一类设备；有键盘、鼠标器
- 中速设备，这是指其传输速率在每秒钟数千个字节至 数十万个字节的一类设备。典型的中速设备有行式打印机、 激光打印机等
- 高速 设备，这是指其传输速率在数百个千字节至千兆字节的一类设备。典型的高速设备有磁带 机、磁盘机、光盘机等。

**3) 信息交换的单位分类**

按信息交换的单位，可将 I/O 设备分成两类。第一类是块设备(Block Device)，第二类是字符设备(Character Device)；

- 块设备：信息的存取总是以数据块为单位
- 字符设备：用于数据的输入和 输出，基本单位是字符；另一特征是不可寻址，即输入/输出时不能指定数据的输入源地址及输出的目标地 址；此外，字符设备在输入/输出时，常采用中断驱动方式。

4) **按设备的共享属性分类**

(1) 独占设备。这是指在一段时间内只允许一个用户(进程)访问的设备，即临界资源。 因而， 对多个并发进程而言，应互斥地访问这类设备。系统一旦把这类设备分配给了某 进程后，便由该进程独占， 直至用完释放。 应当注意，独占设备的分配有可能引起进程 死锁。

(2) 共享设备。这是指在一段时间内允许多个进程同时访问的设备。当然，对于每一时 刻而言，该类设备仍然只允许一个进程访问。显然，共享设备必须是可寻址的和可随机访 问的设备。典型的共享设备是磁盘。对共享设备不仅可获得良好的设备利用率，而且它也 是实现文件系统和数据库系统的物质基础。

(3) 虚拟设备。这是指通过虚拟技术将一台独占设备变换为若干台逻辑设备，供若干个 用户(进程)同时使用。



### 4.1.5 设备控制器

#### 信号线

设备并不是直接与 CPU 进行通信，而是与设备控制器通信，因此，在 I/O 设备 中应含有与设备控制器间的接口，在该接口中有三种类型的信号，对应着三条信号线：

![image-20201112105434033](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm7b3oangj30da0490t0.jpg)

**1) 数据信号线**

这类信号线用于在设备和设备控制器之间传送数据信号。对输入设备而言，由外界输 入的信号经转换器转换后所形成的数据，通常先送入缓冲器中，当数据量达到一定的比特(字 符)数后，再从缓冲器通过一组数据信号线传送给设备控制器，如图所示。对输出设备 而言，则是将从设备控制器经过数据信号线传送来的一批数据先暂存于缓冲器中，经转换 器作适当转换后，再逐个字符地输出。

> 一句话：传输数据用的

**2) 控制信号线**

这是作为由设备控制器向 I/O 设备发送控制信号时的通路。该信号规定了设备将要执行 的操作，如读操作(指由设备向控制器传送数据)或写操作(从控制器接收数据)，或执行磁头 移动等操作。

> 传输命令用的

**3) 状态信号线**

这类信号线用于传送指示设备当前状态的信号。设备的当前状态有正在读(或写)；设备 已读(写)完成，并准备好新的数据传送。

#### 设备控制器组成

![image-20201112110209502](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm7j15c09j30in07jdgo.jpg)

设备控制器是计算机中的一个实体，其主要职责是控制一个或多个 I/O 设备，以实现 I/O 设备和计算机之间的数据交换。它是 CPU 与 I/O 设备之间的接口，它接收从 CPU 发来的命 令，并去控制 I/O 设备工作，以使处理机从繁杂的设备控制事务中解脱出来。

由于设备控制器位于 CPU 与设备之间，它既要与 CPU 通信，又要与设备通信，还应具 有按照 CPU 所发来的命令去控制设备工作的功能，因此，现有的大多数控制器都是由以下 三部分组成的。

**1) 设备控制器与处理机的接口**

该接口用于实现 CPU 与设备控制器之间的通信。共有三类信号线: 数据线、地址线和 控制线。数据线通常与两类寄存器相连接，第一类是数据寄存器(在控制器中可以有一个或 多个数据寄存器，用于存放从设备送来的数据(输入)或从 CPU 送来的数据(输出))；第二类 是控制/状态寄存器(在控制器中可以有一个或多个这类寄存器，用于存放从 CPU 送来的控 制信息或设备的状态信息)。

**2) 设备控制器与设备的接口**

在一个设备控制器上，可以连接一个或多个设备。相应地，在控制器中便有一个或多 个设备接口，一个接口连接一台设备。在每个接口中都存在数据、控制和状态三种类型的 信号。控制器中的 I/O 逻辑根据处理机发来的地址信号去选择一个设备接口。

**3) I/O 逻辑**

在设备控制器中的 I/O 逻辑用于实现对设备的控制。它通过一组控制线与处理机交互， 处理机利用该逻辑向控制器发送 I/O 命令；I/O 逻辑对收到的命令进行译码。每当 CPU 要启 动一个设备时，一方面将启动命令发送给控制器；另一方面又同时通过地址线把地址发送 给控制器，由控制器的 I/O 逻辑对收到的地址进行译码，再根据所译出的命令对所选设备进 行控制。

### 4.1.6 I/O通道

##### 通道引入

虽然在 CPU 与 I/O 设备之间增加了设备控制器后，已能大大减少 CPU 对 I/O 的干预， 但当主机所配置的外设很多时，CPU 的负担仍然很重。为此，在 CPU 和设备控制器之间又 增设了通道。其主要目的是为了建立独立的 I/O 操作，不仅使数据的传送能独立于 CPU， 而且也希望有关对 I/O 操作的组织、 管理及其结束处理尽量独立，以保证 CPU 有更多的时 间去进行数据处理；或者说，其目的是使一些原来由 CPU 处理的 I/O 任务转由通道来承担， 从而把 CPU 从繁杂的 I/O 任务中解脱出来。

实际上，**I/O 通道是一种特殊的处理机**，它具有执行 I/O 指令的能力，并通过执行通道 (I/O)程序来控制 I/O 操作。但 I/O 通道又与一般的处理机不同，主要表现在以下两个方面: 一 是其指令类型单一，这是由于通道硬件比较简单，其所能执行的命令主要局限于与 I/O 操作 有关的指令；二是通道没有自己的内存，通道所执行的通道程序是放在主机的内存中的， 换言之，是通道与 CPU 共享内存。

##### 通道类型

**1) 字节多路通道(Byte Multiplexor Channel)**

![image-20201112112437519](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm86dvwaxj30fd05r0tc.jpg)

这是一种按字节交叉方式工作的通道。它通常都含有许多非分配型子通道，其数量可 从几十到数百个，每一个子通道连接一台 I/O 设备，并控制该设备的 I/O 操作。这些子通道 按时间片轮转方式共享主通道。当第一个子通道控制其 I/O 设备完成一个字节的交换后，便 立即腾出主通道，让给第二个子通道使用；当第二个子通道也完成一个字节的交换后，同 样也把主通道让给第三个子通道；依此类推。当所有子通道轮转一周后，重又返回来由第 一个子通道去使用字节多路主通道。这样，只要字节多路通道扫描每个子通道的速率足够 快，而连接到子通道上的设备的速率不是太高时，便不致丢失信息。

**2) 数组选择通道(Block Selector Channel)**

图 5-3 示出了字节多路通道的工作原理。它所含有的多个子通道 A，B，C，D，E，…， N，…分别通过控制器各与一台设备相连。假定这些设备的速率相近，且都同时向主机传送 数据。设备 A 所传送的数据流为 A1 A2 A3 …；设备 B 所传送的数据流为 B1 B2 B3 …把这些数 据流合成后(通过主通道)送往主机的数据流为 A1 B1 C1 D 1 …A2 B2 C2 D 2 … A3 B3 C3 D 3 …。

字节多路通道不适于连接高速设备，这推动了按数组方式进行数据传送的数组选择通 道的形成。这种通道虽然可以连接多台高速设备，但由于它只含有一个分配型子通道，在 一段时间内只能执行一道通道程序，控制一台设备进行数据传送，致使当某台设备占用了 该通道后，便一直由它独占，即使是它无数据传送，通道被闲置，也不允许其它设备使用 该通道，直至该设备传送完毕释放该通道。可见，这种通道的利用率很低。

**3) 数组多路通道(Block Multiplexor Channel)**

数组选择通道虽有很高的传输速率，但它却每次只允许一个设备传输数据。数组多路 通道是将数组选择通道传输速率高和字节多路通道能使各子通道(设备)分时并行操作的优 点相结合而形成的一种新通道。它含有多个非分配型子通道，因而这种通道既具有很高的 数据传输速率，又能获得令人满意的通道利用率。也正因此，才使该通道能被广泛地用于 连接多台高、中速的外围设备，其数据传送是按数组方式进行的。

![image-20201112112651466](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm88p3lcrj30ed06m0t6.jpg)

![image-20201112112701919](https://tva1.sinaimg.cn/large/0081Kckwgy1gkm88vl3psj30g906dq3c.jpg)

### 4.1.7 总线系统

在计算机系统中的各部件，如 CPU、存储器以及各种 I/O 设备之 间的联系，都是通过总线来实现的。总线的性能是用总线的时钟频率、带宽和相应的总线 传输速率等指标来衡量的。

**局部总线(Local Bus)** 在某个需要高效率传输数据地方，新增一条总线连接到cpu总线上。



## 4.2 I/O设备控制方式

随着计算机技术的发展，I/O 控制方式也在不断地发展。在早期的计算机系统中，是采 用程序 I/O 方式；当在系统中引入中断机制后，I/O 方式便发展为中断驱动方式；此后，随 着 DMA 控制器的出现，又使 I/O 方式在传输单位上发生了变化，即从以字节为单位的传输 扩大到以数据块为单位进行转输，从而大大地改善了块设备的 I/O 性能；而通道的引入，又 使对 I/O 操作的组织和数据的传送都能独立地进行而无需 CPU 干预。

**==应当指出，在 I/O 控 制方式的整个发展过程中，始终贯穿着这样一条宗旨，即尽量减少主机对 I/O 控制的干预， 把主机从繁杂的 I/O 控制事务中解脱出来，以便更多地去完成数据处理任务。==**

### 程序I/O

早期的计算机系统中， 由于无中断机构， 处理机对 I/O 设备的控制采取程序 I/O(Programmed I/O)方式，或称为忙—等待方式。处理机向控制器发出一条 I/O 指令启动外围输入设备输入数据时，要同时把状态寄存器中的忙/闲标志 busy 置为 1，然后便不断地循 环测试 busy。当 busy=1 时，表示输入机尚未输完一个字(符)，处理机应继续对该标志进行 测试，直至 busy=0，表明输入机已将输入数据送入控制器的数据寄存器中。于是处理机将 数据寄存器中的数据取出，送入内存指定单元中，这样便完成了一个字(符)的 I/O。接着再 去启动读下一个数据，并置 busy=1。下图a示出了程序 I/O 方式的流程。

![image-20201111172504143](https://tva1.sinaimg.cn/large/0081Kckwgy1gklcz5t6ppj30l80dngnp.jpg)

在程序 I/O 方式中，由于 CPU 的高速性和 I/O 设备的低速性，致使 CPU 的绝大部分时 间都处于等待 I/O 设备完成数据 I/O 的循环测试中，造成对 CPU 的极大浪费。

在该方式中， CPU 之所以要不断地测试 I/O 设备的状态，就是因为在 CPU 中无中断机构，使 I/O 设备无 法向 CPU 报告它已完成了一个字符的输入操作。**所以说忙等导致cpu浪费了很多时间，还有cpu频繁获取以字节为单位的信息**。这两个缺点会是以后的改进方向。

### 中断驱动 I/O 控制方式

前面说了忙等导致cpu 浪费了很多时间，如何解决这个问题？

**引入中断策略，即当cpu下达I/O命令后，去执行别的任务，然后设备控制器获取到外围设备的信息后向cpu发出中断请求，告知cpu去获取当前输入信息。这就是中断I/O控制的核心思想。**

下面详细描述：

即当某进程要启动某个 I/O 设备工作时，便==「1」==由 CPU 向相应 的设备控制器发出一条 I/O 命令，然后立即返回继续执行原来的任务。==「2」==设备控制器于是按照 该命令的要求去控制指定 I/O 设备。此时，CPU 与 I/O 设备并行操作。例如，在输入时，当 设备控制器收到 CPU 发来的读命令后，便去控制相应的输入设备读数据。==「3」==一旦数据进入数 据寄存器，控制器便通过控制线向 CPU 发送一中断信号，==「4」==由 CPU 检查输入过程中是否出错， 若无错，便向控制器发送取走数据的信号，然后再通过控制器及数据线将数据写入内存指 定单元中。

**过程就是上面大致的四步骤。利用中断告知cpu我的信息获取到了，你可以来取了，省去了cpu不断轮询查找。**

> 例如， 从终端输入一个字符的时间约为 100 ms，而将字符送入终端缓冲区的时间小于 0.1 ms。若 采用程序 I/O 方式，CPU 约有 99.9 ms 的时间处于忙—等待的过程中。但采用中断驱动方式后，CPU 可利用这 99.9 ms 的时间去做其它的事情，而仅用 0.1 ms 的时间来处理由控制器 发来的中断请求。可见，中断驱动方式可以成百倍地提高 CPU 的利用率。



### 直接存储DMA （Direct Memory Access）

#### 1．DMA(Direct Memory Access)控制方式的引入

虽然中断驱动 I/O 比程序 I/O 方式更有效，但须注意，==它仍是以字(节)为单位进行 I/O 的==，每当完成一个字(节)的 I/O 时，控制器便要向 CPU 请求一次中断。换言之，采用中断 驱动 I/O 方式时的 CPU 是以字(节)为单位进行干预的。如果将这种方式用于块设备的 I/O， 显然是极其低效的。例如，为了从磁盘中读出 1 KB 的数据块，需要中断 CPU 1K 次。为了 进一步减少 CPU 对 I/O 的干预而引入了直接存储器访问方式，见图 (c)所示。该方式的 特点是：

(1) 数据传输的基本单位是数据块，即在 CPU 与 I/O 设备之间，每次传送至少一个数 据块；

(2) 所传送的数据是从设备直接送入内存的，或者相反；

(3) 仅在传送一个或多个数据块的开始和结束时，才需 CPU 干预，整块数据的传送是 在控制器的控制下完成的。 可见，DMA 方式较之中断驱动方式，又是成百倍地减少了 CPU 对 I/O 的干预，进一步 提高了 CPU 与 I/O 设备的并行操作程度。

#### 2．DMA 控制器的组成

DMA 控制器由三部分组成：主机与 DMA 控制器的接口；DMA 控制器与块设备的接 口；I/O 控制逻辑。下图 示出了 DMA 控制器的组成。这里主要介绍主机与控制器之间的 接口。

![image-20201111173840631](https://tva1.sinaimg.cn/large/0081Kckwgy1gkldd9nixrj30i2075q3i.jpg)

为了实现在主机与控制器之间成块数据的直接交换，必须在 DMA 控制器中设置如下四类寄存器：

(1) 命令/状态寄存器(CR Control Regisgter)。用于接收从 CPU 发来的 I/O 命令，或有关控制信息，或设 备的状态。

(2) 内存地址寄存器(MAR Memory Address Register)。在输入时，它存放把数据从设备传送到内存的起始目标地 址；在输出时，它存放由内存到设备的内存源地址。

(3) 数据寄存器(DR Data Register)。用于暂存从设备到内存，或从内存到设备的数据。

(4) 数据计数器(DC Data Count)。存放本次 CPU 要读或写的字(节)数。

#### 3．DMA 工作过程

以从磁盘读入数据为例，来说明 DMA 方式的工作流程。

==「1」==当 CPU 要从磁盘读入一 数据块时，便向磁盘控制器发送一条读命令。该命令被送到其中的命令寄存器(CR)中。同 时，还须发送本次要将数据读入的内存起始目标地址，==「2」==该地址被送入内存地址寄存器（MAR） 中；==「3」==本次要读数据的字(节)数则送入数据计数器(DC)中，还须将磁盘中的源地址直接送至 DMA 控制器的 I/O 控制逻辑上。然后，==「4」==启动 DMA 控制器进行数据传送，以后，CPU 便可去处理其它任务。此后，整个数据传送过程便由 DMA 控制器进行控制。当DMA 控制器已从磁盘中读入一个字(节)的数据并送入数据寄存器(DR)后，再挪用一个存储器周期，将该字 (节)传送到 MAR 所指示的内存单元中。接着便对 MAR 内容加 1，将 DC 内容减 1。若减 1 后 DC 内容不为 0，表示传送未完，便继续传送下一个字(节)；==「5」==否则(数据传输完成)，由 DMA 控制器发出 中断请求。下图是 DMA 方式的工作流程。

![image-20201111175818639](https://tva1.sinaimg.cn/large/0081Kckwgy1gkldxp8c5cj30d60bmmy0.jpg)

DMA 使用于小型PC系统，

### I/O通道控制方式

#### 1．I/O 通道控制方式的引入

当我们需要一次去读多个数据块且将它们分别传送到不同的内存区 域，或者相反时，则须由 CPU 分别发出多条 I/O 指令及进行多次中断处理才能完成。为了解决这种情况，提出了I/O通道控制方式。

I/O 通道方式是 DMA 方式的发展，它可进一步减少 CPU 的干预，即把对一个数据块的 读(或写)为单位的干预减少为对一组数据块的读(或写)及有关的控制和管理为单位的干预。 同时，又可实现 CPU、通道和 I/O 设备三者的并行操作，从而更有效地提高整个系统的资源利用率。例如，当 CPU 要完成一组相关的读(或写)操作及有关控制时，只需向 I/O 通道 发送一条 I/O 指令，以给出其所要执行的通道程序的首址和要访问的 I/O 设备，通道接到该 指令后，通过执行通道程序便可完成 CPU 指定的 I/O 任务。

#### 2．通道程序

通道是通过执行通道程序，并与设备控制器共同实现对 I/O 设备的控制的。通道程序是 由一系列通道指令(或称为通道命令)所构成的。通道指令与一般的机器指令不同，在它的每 条指令中都包含下列诸信息：

(1) 操作码。操作码规定了指令所执行的操作，如读、写、控制等操作。

(2) 内存地址。内存地址标明字符送入内存(读操作)和从内存取出(写操作)时的内存 首址。

(3) 计数。该信息表示本条指令所要读(或写)数据的字节数。

(4) 通道程序结束位 P。该位用于表示通道程序是否结束。P=1 表示本条指令是通道程 序的最后一条指令。

(5) 记录结束标志 R。R=0 表示本通道指令与下一条指令所处理的数据是同属于一个记 录；R=1 表示这是处理某记录的最后一条指令。



总结：I/O通道其实增加了一个处理器（有自己的专门I/O指令集），专门去处理I/O事物，最大程度上减轻cpu工作量。I/O通道控制适用于大型系统，DMA 一般用于小型PC系统，I/O通道成本还是比较昂贵的。



## 4.3 中断处理程序

对于操作系统的I/O，采用从底层向上介绍。从硬件的第一层中断开始说起，中断是I/O系统的最底层，是整个I/O的基础。

当一个进程请求 I/O 操作时，该进程将被挂起，直到 I/O 设备完成 I/O 操 作后，设备控制器便向 CPU 发送一中断请求，CPU 响应后便转向中断处理程序，中断处理 程序执行相应的处理，处理完后解除相应进程的阻塞状态。

### 中断简介

#### 中断和陷入

**（1）中断**

CPU对I/O设备发来的中断信号的一种响应。cpu 暂停正在执行的程序，保存当前程序cpu环境后，去处理I/O设备的中断处理程序。由于中断是由外部设备引起的，又称外中断；

**（2）陷入**

由CPU内部事件所引起的中断，例如进程在运算中发生了错误，或者程序出错，非法指令、地址越界等等，通常把这类中断称为内中断或陷入（trap）。

**中断和陷入的主要区别**：是信号的来源，一个来源于CPU外部，一个来自CPU内部。

#### 中断向量表

为每种设备配以相应的中断处理程序，并把该程序的入口地址，放在中断向量表的一个表项中，并为每一个设备的中断请求规定一个中断号，它直接对应于中断向量表的一个表项中。当I/O设备发来中断请求信号时，由中断控制器确定改请求的中断号，根据改设备的中断号去查找中断向量表，从中取得该设备中断处理程序的入口地址，这样便可以转入中断处理程序。

**中断优先级**：实际中可能有多个中断信号源，他们的优先级不一样。

#### 对多中断源的处理方式

当有多个中断信号时，处理机可以有以下处理方式应对：

- 屏蔽（禁止）中断

  a.所有中断都将按顺序依次处理。
  b.优点是简单，但不能用于对实时性要求较高的中断请求。

- 嵌套中断

  a.中断优先级：系统根据不同中断信号源，对服务要求的紧急程度的不同，它们分别规定不同的优先级。
  b.当同时有多个不同优先级的中断请求时，CPU优先响应最高优先级的中断请求；
  c.高优先级的中断请求，可以抢占正在运行低优先级中断的处理机，该方式类似于基于优先级的抢占式进程调度。

### 中断处理程序

当一个进程请求 I/O 操作时，该进程将被挂起，直到 I/O 设备完成 I/O 操 作后，设备控制器便向 CPU 发送一中断请求，CPU 响应后便转向中断处理程序，中断处理 程序执行相应的处理，处理完后解除相应进程的阻塞状态。

这里主要讲解中断程序如何工作的？其流程和上面的叙述大致一样：

1. 测定是否有未响应的中断信号

   每次设备处理一个流（块）读取或输入，设备控制器会向cpu发送一个中断信号，请求cpu把数据读入内存缓冲区。

2. 保护被中断进程的CPU环境

   把cpu控制权交给中断程序后，需要保护当前正在执行的进程，以后后续可以恢复运行。

3. 转入相应的设备处理程序

   cpu找到发出中断信号的I/O设备及设备控制器。将该设备的中断处理程序入口地址放入到程序计数器中，当cpu执行时可自动执行中断程序。

4. 中断处理——说白了就是干中断程序想要做的事，比如传输数据。

5. 恢复CPU的现场——当中断处理完后，恢复之前的保护的环境，cpu就去执行之前的进程。

![image-20201112164740925](https://tva1.sinaimg.cn/large/0081Kckwgy1gkmhikau5dj30dd0cvdgv.jpg)

## 4.4 设备驱动程序

设备驱动程序通常又称为设备处理程序，它是 I/O 进程与设备控制器之间的通信程序， 又由于它常以进程的形式存在，故以后就简称之为设备驱动进程。其主要任务是接收上层 软件发来的抽象 I/O 要求，如 read 或 write 命令，在把它转换为具体要求后，发送给设备控 制器，启动设备去执行；此外，它也将由设备控制器发来的信号传送给上层软件。

> 连接上层无关软件，下层设备控制器。

### 设备驱动程序功能

(1) 接收由设备独立性软件发来的命令和参数，并将命令中的抽象要求转换为具体要 求，例如，将磁盘块号转换为磁盘的盘面、磁道号及扇区号。

(2) 检查用户 I/O 请求的合法性，了解 I/O 设备的状态，传递有关参数，设置设备的工 作方式。

(3) 发出 I/O 命令。如果设备空闲，便立即启动 I/O 设备去完成指定的 I/O 操作；如果 设备处于忙碌状态，则将请求者的请求块挂在设备队列上等待。

(4) 及时响应由控制器或通道发来的中断请求，并根据其中断类型调用相应的中断处理 程序进行处理。

(5) 对于设置有通道的计算机系统，驱动程序还应能够根据用户的 I/O 请求，自动地构 成通道程序。

### 设备处理方式

在不同的操作系统中所采用的设备处理方式并不完全相同。根据在设备处理时是否设 置进程，以及设置什么样的进程而把设备处理方式分成以下三类：

(1) 为每一类设备设置一个进程，专门用于执行这类设备的 I/O 操作。比如，为所有的 交互式终端设置一个交互式终端进程；又如，为同一类型的打印机设置一个打印进程。

(2) 在整个系统中设置一个 I/O 进程，专门用于执行系统中所有各类设备的 I/O 操作。 也可以设置一个输入进程和一个输出进程， 分别处理系统中所有各类设备的输入或输出 操作。

(3) 不设置专门的设备处理进程，而只为各类设备设置相应的设备处理程序(模块)，供 用户进程或系统进程调用。

### 设备驱动程序特点

(1) 驱动程序事连接设备无关软件和设备控制器的桥梁。

(2) 驱动程序与 I/O 设备所采用的 I/O 控制方式紧密相关。常用的 I/O 控制方式是中断 驱动和 DMA 方式，这两种方式的驱动程序明显不同，因为后者应按数组方式启动设备及进 行中断处理。

(3) 由于驱动程序与硬件紧密相关，因而其中的一部分必须用汇编语言书写；同时不同的设备其驱动程序不一样。

(4) 驱动程序应允许可重入。一个正在运行的驱动程序常会在一次调用完成前被再次调用；

### 设备处理器工作过程

设备驱动程序的主要任务是启动指定设备。但在启动之前，还必须完成必要的准备工 作，如检测设备状态是否为“忙”等。在完成所有的准备工作后，才最后向设备控制器发 送一条启动命令。 以下是设备驱动程序的处理过程。

**1) 将抽象要求转换为具体要求**

由于用户及上层软件对设备控制器的具体情况毫无了解，因而只能向它发出抽象的要求(命 令)，但这些命令无法传送给设备控制器。因此，就需要将这些抽象要求转换为具体要求。 例如，将抽象要求中的盘块号转换为磁盘的盘面、 磁道号及扇区。这一转换工作只能由驱 动程序来完成，因为在 OS 中只有驱动程序才同时了解抽象要求和设备控制器中的寄存器情 况；也只有它才知道命令、 数据和参数应分别送往哪个寄存器。

**2) 检查 I/O 请求的合法性**

对于任何输入设备，都是只能完成一组特定的功能，若该设备不支持这次的 I/O 请求， 则认为这次 I/O 请求非法。比如像键盘设备发出打印请求，显然被拒绝。

**3) 读出和检查设备的状态**

在启动某个设备进行 I/O 操作时，其前提条件应是该设备正处于空闲状态。因此在启动 设备之前，要从设备控制器的状态寄存器中，读出设备的状态。例如，为了向某设备写入 数据，此前应先检查该设备是否处于接收就绪状态，仅当它处于接收就绪状态时，才能启 动其设备控制器，否则只能等待。

**4) 传送必要的参数**

对于许多设备，特别是块设备，除必须向其控制器发出启动命令外，还需传送必要的 参数。例如在启动磁盘进行读/写之前，应先将本次要传送的字节数和数据应到达的主存始 址，送入控制器的相应寄存器中。

**5) 启动 I/O 设备**

完成上述各项准备工作之后，驱动程序可以向控制器中的命令寄存器传送相应的控 制命令。对于字符设备，若发出的是写命令，驱动程序将把一个数据传送给控制器；若发 出的是读命令，则驱动程序等待接收数据，并通过从控制器中的状态寄存器读入状态字的 方法，来确定数据是否到达。

驱动程序发出 I/O 命令后，基本的 I/O 操作是在设备控制器的控制下进行的。通常，I/O 操作所要完成的工作较多，需要一定的时间，如读/写一个盘块中的数据，此时驱动(程序) 进程把自己阻塞起来，直到中断到来时才将它唤醒。

这里看到，其实驱动程序实际上充当了一个 映射 表（逻辑命令 —— 物理命令）而已，把逻辑命令转化为物理命令后，并传给设备控制器后，自己的使命就完成了。



## 4.5 设备独立（无关）软件

驱动程序是一个与硬件(或设备)紧密相关的软件。为了实现设备独立性，必须再在驱动 程序之上设置一层软件，称为设备独立性（无关）软件。至于设备独立性软件和设备驱动程序之间 的界限，根据不同的操作系统和设备有所差异，主要取决于操作系统、设备独立性和设备 驱动程序的运行效率等多方面因素的权衡，因为对于一些本应由设备独立性软件实现的功 能，可能由于效率等诸多因素，实际上设计在设备驱动程序中。

设备独立性软 件的主要功能可分为以下两个方面：执行所有设备的公有操作、向用户层(或文件层)软件提供统一接口

### 主要功能

（1）公有操作

①对独立设备的分配与回收

② 将逻辑设备名映射为物理设备名，进一步可以找到相应物理设备的驱动程序；

③ 对设备进行保护，禁止用户直接访问设备；

④ 缓冲管理，即对字符设备和块设备的缓冲区进行有效的管理，以提高I/O的效率； 

⑤ 差错控制，由于在I/O操作中的绝大多数错误都与设备无关，故主要由设备驱动程序 处理，而设备独立性软件只处理那些设备驱动程序无法处理的错误；

(2) 向用户层(或文件层)软件提供统一接口。无论何种设备，它们向用户所提供的接口 应该是相同的。例如，对各种设备的读操作，在应用程序中都使用 read；而对各种设备的 写操作，也都使用 write。

### 逻辑设备名到物理设备名映射的实现

1) 逻辑设备表

为了实现设备的独立性，系统必须设置一张逻辑设备表(LUT，Logical Unit Table)，用 于将应用程序中所使用的逻辑设备名映射为物理设备名。在该表的每个表目中包含了三项： 逻辑设备名、物理设备名和设备驱动程序的入口地址，如下图所示。当进程用逻辑设 备名请求分配 I/O 设备时，系统为它分配相应的物理设备，并在 LUT 上建立一个表目，填 上应用程序中使用的逻辑设备名和系统分配的物理设备名，以及该设备驱动程序的入口地 址。当以后进程再利用该逻辑设备名请求 I/O 操作时，系统通过查找 LUT，便可找到物理 设备和驱动程序。

![image-20201112181636778](https://tva1.sinaimg.cn/large/0081Kckwgy1gkmk31u0wjj30if059dgb.jpg)

2) LUT 的设置问题 LUT 的设置可采取两种方式：第一种方式是在整个系统中只设置一张 LUT。由于系统 中所有进程的设备分配情况都记录在同一张 LUT 中，因而不允许在 LUT 中具有相同的逻辑 设备名，这就要求所有用户都不使用相同的逻辑设备名。在多用户环境下这通常是难以做 到的，因而这种方式主要用于单用户系统中。第二种方式是为每个用户设置一张 LUT。每 当用户登录时，便为该用户建立一个进程，同时也为之建立一张 LUT，并将该表放入进程 的 PCB 中。由于通常在多用户系统中，都配置了系统设备表，故此时的逻辑设备表可以采 用图(b)中的格式。

## 4.6 用户层I/O软件

一般而言，大部分的 I/O 软件都在操作系统内部，但仍有一小部分在用户层，包括与用 户程序链接在一起的库函数，以及完全运行于内核之外的一些程序。

用户层软件必须通过一组系统调用来取得操作系统服务。在现代的高级语言以及 C 语 言中，通常提供了与各系统调用一一对应的库函数，用户程序通过调用对应的库函数使用 系统调用。这些库函数与调用程序连接在一起，包含在运行时装入在内存的二进制程序中， 如 C 语言中的库函数 write 等，显然这些库函数的集合也是 I/O 系统的组成部分。但在许多 现代操作系统中，系统调用本身已经采用 C 语言编写，并以函数形式提供，所以在使用 C 语言编写的用户程序中，可以直接使用这些系统调用。

另外，在操作系统中还有一些程序，如下面章节我们将要论述的 Spooling 系统以及在 网络传输文件时常使用的守护进程等，就是完全运行在内核之外的程序，但它们仍归属于 I/O 系统。

### 假脱机系统Spooling



## 4.7 缓冲

为了缓和CPU与I/O设备之间速度不匹配的矛盾，提高CPU和I/O设备的并行性，在现代操作系统中，几乎所有的***I/O设备***在与***处理机交换数据***时都用了缓冲区。缓冲管理的主要职责是组织好这些缓冲区，并提供**获得和释放**缓冲区的手段。

### 缓冲引入

引入缓冲区的主要原因可归结为以下几点：

**缓和CPU与I/O设备间速度不匹配的矛盾**

事实上，凡在数据到达速率与其离去速率不同的地方，都可设置缓冲区，以缓和它们之间速率不匹配的矛盾。

CPU的运算速度远远高于I/O设备的速率，如果没有缓冲区，则在输出数据时，必然会由于打印机的速度跟不上CPU的速度而使CPU停下来等待；然而在计算阶段，打印机又空闲无事。如果在打印机或控制器中设置一缓冲区，用于快速暂存程序的输出数据，以后由打印机“慢慢地”从中取出数据打印，这样就可提高CPU的工作效率。类似地，在输入设备与CPU之间也设置缓冲区，也可使CPU的工作效率得以提高。

**解决数据处理单位与传输单位不匹配的问题**

对于块设备来说，它的数据传输单位是固定长度的数据块，比如最少一个扇区的数据。而进程在处理数据的时候往往不是按照块来进行的，比如一个进程在查询某门功课的成绩，只需要几个字节。使用缓冲后，可以从块设备上取出一个扇区的数据，然后进程再从缓冲中取出若干个需要的字节的数据，转存到用户进程的工作区。

**减少对CPU的中断频率**

放宽对CPU中断响应时间的限制。例如：远程通信系统中，设终端发来的数据速率为9.6kb/S, 如果用一位缓冲来接收，则接收一位数据就要中断一次cpu，cpu的中断频率也是9.6kb/S ，即每100us cpu就要中断一次，否则该数据就会被冲掉。，如果是8位缓冲器，则中断频率降为之前的八分之一，时间从100us提高到800，这样提升了cpu的效率。

**提高CPU与I/O设备之间的并行性**

缓冲的引入可显著地提高CPU与I/O设备间的***\*并行操作程度\****，提高***\*系统的吞吐量\****和***\*设备的利用率\****。例如，在CPU和打印机之间设置了缓冲区后，便可使CPU与打印机并行工作。

### 单缓冲

![单缓冲](https://pic3.zhimg.com/80/v2-74532609f6f05f187f4cbec7f5779ace_720w.jpg)

单缓冲就是在用户进程的工作区与设备之间只设置一个缓冲区。

其中 M 与 T之间是一个串行工作过程，C与M之间也是一个串行工作过程。不过当用户进程在处理工作区数据的时候，缓冲区已经空，输入设备可以继续输入第二组数据到缓冲区。所以C和T之间是部分并行的工作状态。所以系统对一块数据的处理时间：Max(C,T)+M



### 双缓冲

![双缓冲](https://tva1.sinaimg.cn/large/0081Kckwly1gks0a9kqvrj30py0cumxu.jpg)



为了加快输入和输出速度，提高设备利用率，人们又引入了双缓冲区机制，也称为***\*缓冲对换\****（Buffer Swapping）。在设备输入时，先将数据送入第一缓冲区，***装满后***便转向第二缓冲区。此时操作系统可以从第一缓冲区中移出数据，并送入用户进程。接着由CPU对数据进行计算。在双缓冲时，系统处理一块数据的时间可以粗略的认为是***Max(C,T)***。***如果C<T，可使块设备连续输入；如果C>T，则可使CPU不必等待设备输入。***对于字符设备，若采用行输入方式，则采用双缓冲通常能消除用户的等待时间，即用户在输入完第一行之后，在CPU执行第一行中的命令时，用户可继续向第二缓冲区输入下一行数据。

在这里M与T之间是一个并行的工作状态，C与M是串行的，C与T之间是并行的。所以系统对一块数据的处理时间：Max(C+M,T) 。

> 例题：某文件占10个磁盘块，现要把该文件磁盘块逐个读入主存缓冲区，并送用户区进行分析。假设一个缓冲区与一个磁盘块大小相同，把一个磁盘块读入缓冲区的时间为100us，将缓冲区的数据传送到用户区的时间是50us，CPU对一块数据进行分析的时间为50us。在单缓冲区和双缓冲区结构下，读入并分析完该文件的时间分别是**1550us**和***\*1100us\****。
>
> 单缓冲：（100+50）×10=1500us，记得最后一个磁盘块的处理时间还有50us，所以总共是1550us。
>
> 双缓冲：100×10=1000us，加上将最后一个缓冲区的数据传输到用户区并由CPU处理完的时间50+50=100us，总共是1100us。

==单缓冲同一时刻只能单向发送数据，而双缓冲可以双向发送数据，因为一个缓冲区只能用来输入或输出；同时我们想到android里的surfurceView采用双缓冲机制，可以更加流畅，其原理在这里就明白了==



### 环形缓冲

对比双缓冲，我们在增加缓冲区的数量，便可以理解为环形缓冲；就是把多个缓冲区组织成一个环形形状，每个缓冲区大小相同，缓冲区分为三种：空缓冲区R、已装满数据的缓冲区G、正在工作的缓冲区C；



### 缓冲池

单缓冲、双缓冲、环形缓冲是为了生产者、消费者设置的。当系统较大时，有较多的这样的循环缓冲，不仅要消耗大量的内存空间，而且利用率不高。为了提高利用率，采用公用的缓冲池，设置多个可供若干个进程共享的缓冲区。

![preview](https://tva1.sinaimg.cn/large/0081Kckwgy1gks4l11q7qj30hq08p0ts.jpg)

### 缓冲Buffer与缓存Cache

Buffer的核心作用是用来缓冲，缓和冲击。比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，日子过得爽了。极大缓和了冲击。

Cache的核心作用是加快取用的速度。比如你一个很复杂的计算做完了，下次还要用结果，就把结果放手边一个好拿的地方存着，下次不用再算了。加快了数据取用的速度。

简单来说就是buffer偏重于写，而cache偏重于读。

 

ps：有时候大家要好好理解这些专有名词字面上的意思，对理解这些概念有好处，缓冲：缓解冲击，缓存：临时存储

## 4.8 磁盘概述及调度

磁盘存储器不仅容量大，存取速度快，而且可以实现随机存取（像其他的低速设备不能随机存取，只能顺序存储，同时如果有了随机存储那就涉及到存储策略及调度策略，可以类比内存是一样的道理）,是当前存放大量程序 和数据的理想设备，故在现代计算机系统中，都配置了磁盘存储器，并以它为主来存放文 件。**磁盘 I/O 速度的高低和磁盘系统的可 靠性，都将直接影响到系统性能。因此，设法改善磁盘系统的性能，已成为现代操作系统 的重要任务之一**。

### 磁盘性能

#### 磁盘物理结构

![image-20201117094508118](https://tva1.sinaimg.cn/large/0081Kckwly1gkrxeg7x4uj30kt09kjt5.jpg)

磁盘设备可包括一或多个物理盘片，每个磁盘片分一个或两个存储面；每个磁盘面被组织成若干个同心环，这种环称为磁道(track)；为使处理简单起见，在每条磁道上可存储相同数目的二进制位。这样，**磁盘密 度即每英寸中所存储的位数，显然是内层磁道的密度较外层磁道的密度高。**每条磁道又被 逻辑上划分成若干个扇区(sectors)，软盘大约为 8～32 个扇区，硬盘则可多达数百个；上图b显示了一个磁道分成 8 个扇区。一个扇区称为一个盘块(或数据块)，常常叫做磁盘扇 区。各扇区之间保留一定的间隙。

一个物理记录存储在一个扇区上，磁盘上存储的物理记录块数目是由扇区数、磁道数 以及磁盘面数所决定的。磁道编号是从磁盘外面开始向里面递增编号，最外面是0道，依次向里推进。

> 为了使每个磁道上存储的内容一样，通过磁盘存储介质密度稀疏来实现。

#### 磁盘类型

1) 固定头磁盘 （大容量磁盘，价格贵，使用在大型系统）

这种磁盘在每条磁道上都有一读/写磁头，所有的磁头都被装在一刚性磁臂中。通过这 些磁头可访问所有各磁道，并进行并行读/写，有效地提高了磁盘的 I/O 速度。这种结构的 磁盘主要用于大容量磁盘上。

2) 移动头磁盘 （小容量磁盘）

每一个盘面仅配有一个磁头，也被装入磁臂中。为能访问该盘面上的所有磁道，该磁 头必须能移动以进行寻道。可见，移动磁头仅能以串行方式读/写，致使其 I/O 速度较慢； 但由于其结构简单，故仍广泛应用于中小型磁盘设备中。在微型机上配置的温盘和软盘都 采用移动磁头结构，故本节主要针对这类磁盘的 I/O 进行讨论。

本节讨论的是移动头磁盘。

#### 磁盘访问时间

磁盘设备在工作时以恒定速率旋转。为了读或写，磁头必须能移动到所要求的磁道上， 并等待所要求的扇区的开始位置旋转到磁头下，然后再开始读或写数据。故可把对磁盘的 访问时间分成以下三部分。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gkryl717ghj30uo0i87bv.jpg" alt="磁盘寻址时间" style="zoom:67%;" />

1) 寻道时间 Ts 

这是指把磁臂(磁头)移动到指定磁道上所经历的时间。该时间是启动磁臂的时间 s 与磁 头移动 n 条磁道所花费的时间之和，即

​                                                                                  Ts =m×n+s

其中，m 是一常数，与磁盘驱动器的速度有关。对于一般磁盘，m = 0.2；对于高速磁盘，m≤0.1，磁臂的启动时间约为 2 ms。这样，对于一般的温盘，其寻道时间将随寻道距离的 增加而增大，大体上是 5～30 ms。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gkrylqt1qnj30t80jo11g.jpg" alt="寻道时间" style="zoom:67%;" />

2) 旋转延迟时间 Tr 

这是指定扇区移动到磁头下面所经历的时间。不同的磁盘类型中，旋转速度至少相差 一个数量级，如软盘为 300 r/min，硬盘一般为 7200～15 000 r/min，甚至更高。对于磁盘旋 转延迟时间而言，如硬盘，旋转速度为 15 000 r/min，每转需时 4 ms，平均旋转延迟时间 Tr  为 2 ms；而软盘，其旋转速度为 300 r/min 或 600 r/min，这样，平均 T r 为 50～100 ms。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gkrym1588ij30ua0man9q.jpg" alt="旋转时间" style="zoom:67%;" />

3) 传输时间 Tt 

这是指把数据从磁盘读出或向磁盘写入数据所经历的时间。T~t~ 的大小与每次所读/写的 字节数 b 和旋转速度有关:

​																					T = b / （rN）

其中，r 为磁盘每秒钟的转数；N 为一条磁道上的字节数，当一次读/写的字节数相当于半条 磁道上的字节数时，T t 与 T r 相同。因此，可将访问时间 T a 表示为

​                                                Ta = Ts + 1/(2r) + b/(rN)

由上式可以看出，在访问时间中，寻道时间和旋转延迟时间基本上都与所读/写数据的 多少无关，而且它通常占据了访问时间中的大头。例如，我们假定寻道时间和旋转延迟时 间平均为 20 ms，而磁盘的传输速率为 10 MB/s，如果要传输 10 KB 的数据，此时总的访问 时间为 21 ms，可见传输时间所占比例是非常小的。当传输 100 KB 数据时，其访问时间也 只是 30 ms，即当传输的数据量增大 10 倍时，访问时间只增加约 50%。目前磁盘的传输速 率已达 80 MB/s 以上，数据传输时间所占的比例更低。

可见，适当地集中数据(不要太零散) 传输，将有利于提高传输效率; 同时寻道时间是花费时间最多的一块，是我们需要改进的。

### 磁盘调度算法

磁盘是可供多个进程共享的设备，当有多个进程都要求访问磁盘时，应采用一种最佳 调度算法，以使各进程对磁盘的平均访问时间最小。由于在访问磁盘的时间中，主要是寻 道时间，因此，磁盘调度的目标是使磁盘的平均寻道时间最少。

![磁盘调度策略](https://tva1.sinaimg.cn/large/0081Kckwly1gkrynzy1k2j30um0oeanm.jpg)

图中，列举了多种算法，大致分为两类，一是随机从请求者层面出发，二是基于位置策略全局考虑的，当然是第二种方式更好；下面来好好分析一下：

![随机-请求者调度策略](https://tva1.sinaimg.cn/large/0081Kckwly1gkryuozn6ej30s40k67gp.jpg)

这些策略在之前的进程、内存调度都有讲到，不在缀述。

![基于位置考虑调度算法](https://tva1.sinaimg.cn/large/0081Kckwly1gkryw8g3rfj30sa0l67b4.jpg)

这些算法是从系统角度出发，使整体的效率达到最高，**以使各进程对磁盘的平均访问时间最小**。重点掌握SSTF、SCAN、CSCAN 三种算法，其实这三种算法是层层递进的，每一种都是前面的算法某方面优化。

#### 最短寻道时间优先 SSTF Shortest Seek Time First

其要求访问的磁道与当前磁头所在的磁道距离最近，以使每 次的寻道时间最短。但这种算法不能保证平均寻道时间最短。

![image-20201117105119264](https://tva1.sinaimg.cn/large/0081Kckwly1gkrzb9hac0j30at0avwf2.jpg)

#### 扫描(SCAN)算法

1) 进程“饥饿”现象 

SSTF 算法虽然能获得较好的寻道性能，但却可能导致某个进程发生“饥饿”(Starvation)现象。因为只要不断有新进程的请求到达，且其所要访问的磁道与磁头当前所在磁道的距 离较近，这种新进程的 I/O 请求必然优先满足。

> 就是不断有新的进程I/O进来访问磁盘，且这些进程所访问的磁盘磁道洽好离刚刚正在运行的磁道很近，导致磁盘一直某个区域工作，不能去到其他地方服务其他进程的I/O请求。

SCAN算法， 也称电梯算法

就是在SSTF 算法的基础上，加入磁头的移动方向。例如，当磁头正在自里向外移动时，SCAN 算法所考虑的下一个访问对象，应是其 欲访问的磁道既在当前磁道之外，又是距离最近的。。这样自里向外地访问，直至再无更外 的磁道需要访问时，才将磁臂换向为自外向里移动。这时，同样也是每次选择这样的进程 来调度，即要访问的磁道在当前位置内距离最近者，这样，磁头又逐步地从外向里移动， 直至再无更里面的磁道要访问，从而避免了出现“饥饿”现象。这种算法和电梯运行很相似，故称电梯算法。

![image-20201117105104076](https://tva1.sinaimg.cn/large/0081Kckwly1gkrzazzooaj30d70apaat.jpg)

#### 循环扫描(CSCAN)算法

SCAN 算法既能获得较好的寻道性能，又能防止“饥饿”现象，故被广泛用于大、中、 小型机器和网络中的磁盘调度。但 SCAN 也存在这样的问题：当磁头刚从里向外移动而越 过了某一磁道时，恰好又有一进程请求访问此磁道，这时，该进程必须等待，待磁头继续 从里向外，然后再从外向里扫描完所有要访问的磁道后，才处理该进程的请求，致使该进 程的请求被大大地推迟。为了减少这种延迟，CSCAN 算法规定磁头单向移动，例如，只是 自里向外移动，当磁头移到最外的磁道并访问后，磁头立即返回到最里的欲访问的磁道， 亦即将最小磁道号紧接着最大磁道号构成循环，进行循环扫描。

> 核心思想就是在SCAN算法上，规定磁头单向移动，解决一些特殊情况（当磁头刚从里向外移动而越 过了某一磁道时，恰好又有一进程请求访问此磁道）

![image-20201117105053289](https://tva1.sinaimg.cn/large/0081Kckwly1gkrzatn41tj30dd0aq0ti.jpg)

# 第五章 文件管理

![os-管理](https://tva1.sinaimg.cn/large/0081Kckwgy1gks5494b7rj30a8067dhm.jpg)

**学习目标**

- 文件管理系统

- 文件逻辑组织
- 文件目录
- 文件共享
- 文件存储空间的管理（主要在磁盘上的管理）



文件管理作为操作系统的子系统，依赖操作系统；文件管理的对象是文件，文件存储是一个持久化存储。

文件系统的目标：

符合系统管理数据需求及用户使用需求

保证系统性能及用户对响应时间的要求

保证数据的合法性

对各种各样的设备提供I/O支持

减少或避免数据丢失或损坏

提供标准的I/O接口

支持多用户环境使用

## 文件和文件系统

在现代 OS 中，几乎毫无例外地是通过文件系统来组织和管理在计算机中所存储的大量 程序和数据的；或者说，文件系统的管理功能，是通过把它所管理的程序和数据组织成一 系列文件的方法来实现的。而文件则是指具有文件名的若干相关元素的集合。元素通常是记录，而记录又是一组有意义的数据项的集合。可见，基于文件系统的概念，可以把数据 组成分为数据项、记录和文件三级。

### 文件、记录和数据项

#### 数据项

数据项是最低级的数据组织形式，把数据项分为基本数据项和组合数据项。理解为数据项是一个对象的属性

(1) 基本数据项。这是用于描述一个对象的某种属性的字符集，是数据组织中可以命名 的最小逻辑数据单位，即原子数据，又称为数据元素或字段。它的命名往往与其属性一致。 例如，用于描述一个学生的基本数据项有学号、姓名、年龄、所在班级等。

(2) 组合数据项。它是由若干个基本数据项组成的，简称组项。例如，经理便是个组项， 它由正经理和副经理两个基本项组成。又如，工资也是个组项，它可由基本工资、工龄工 资和奖励工资等基本项所组成。

基本数据项除了数据名外，还应有数据类型。因为基本项仅是描述某个对象的属性， 根据属性的不同，需要用不同的数据类型来描述。在高级语言和操作系统之间需要有一层转换关系，把高级语言转换为文件时，进行编码。比如有文本文件、二进制文件，这些就是所谓的编码格式，他们只是逻辑上的区别，在物理层面没有区别，因为物理文件上肯定只有一种统一的结构。操作系统从外存中读取这些信息，然后解码还原为对应的逻辑文件，方便人去操作。

这一点理解很重要。

#### 记录

记录是一组相关数据项的集合，用于描述一个对象在某方面的属性。可以理解为记录是一个对象。

#### 文件

具有文件名的一组相关元素的集合，可分为有结构文件 和无结构文件两种。在有结构的文件中，文件由若干个相关记录组成；而无结构文件则被 看成是一个字符流。文件在文件系统中是一个最大的数据单位，它描述了一个对象集。例 如，可以将一个班的学生记录作为一个文件。





![image-20201117162930597](https://tva1.sinaimg.cn/large/0081Kckwgy1gks936zwn4j30bj059q31.jpg)

文件、记录、数据项的关系图

### 文件类型

#### 按用途分类

根据文件的性质和用途的不同，可将文件分为三类:

(1) 系统文件。这是指由系统软件构成的文件。大多数的系统文件只允许用户调用，但 不允许用户去读，更不允许修改；有的系统文件不直接对用户开放。

(2) 用户文件。指由用户的源代码、目标文件、可执行文件或数据等所构成的文件。用 户将这些文件委托给系统保管。

(3) 库文件。这是由标准子例程及常用的例程等所构成的文件。这类文件允许用户调用， 但不允许修改。

#### 按文件中数据的形式分类

按这种方式分类，也可把文件分为三类：

(1) 源文件。这是指由源程序和数据构成的文件。通常由终端或输入设备输入的源程序 和数据所形成的文件都属于源文件。它通常是由 ASCII 码或汉字所组成的。

(2) 目标文件。这是指把源程序经过相应语言的编译程序编译过，但尚未经过链接程序 链接的目标代码所构成的文件。它属于二进制文件。 通常，目标文件所使用的后缀名是 “.obj”。

(3) 可执行文件。这是指把编译后所产生的目标代码再经过链接程序链接后所形成的 文件。

#### 按存取控制属性（权限）分类

根据系统管理员或用户所规定的存取控制属性（读R、写W、执行E三种权限），可将文件分为三类：

(1) 只执行文件。该类文件只允许被核准的用户调用执行，既不允许读，更不允许写。

(2) 只读文件。该类文件只允许文件主及被核准的用户去读，但不允许写。

(3) 读写文件。这是指允许文件主和被核准的用户去读或写的文件。

#### 按组织形式和处理方式分类

根据文件的组织形式和系统对其的处理方式，可将文件分为三类：

(1) 普通文件：由 ASCII 码或二进制码组成的字符文件。一般用户建立的源程序文件、 数据文件、目标代码文件及操作系统自身代码文件、库文件、实用程序文件等都是普通文 件，它们通常存储在外存储设备上。

(2) 目录文件：由文件目录组成的，用来管理和实现文件系统功能的系统文件，通过目 录文件可以对其它文件的信息进行检索。由于目录文件也是由字符序列构成，因此对其可 进行与普通文件一样。

(3) 特殊文件：特指系统中的各类 I/O 设备。 为了便于统一管理， 系统将所有的输入/输出设备都视为文件，按文件方式提供给用户使用，如目录的检索、权限的验证等都 与普通文件相似，只是对这些文件的操作是和设备驱动程序紧密相连的。

### 文件层次模型

![image-20201117165800919](https://tva1.sinaimg.cn/large/0081Kckwgy1gks9wtb66ej30di048mxd.jpg)

​																								文件系统模型

1) 对象及其属性（这个对象指的是文件存放形式）

文件管理系统管理的对象有：① 文件。它作为文件管理的直接对象。② 目录。为了 方便用户对文件的存取和检索，在文件系统中必须配置目录，每个目录项中，必须含有文 件名及该文件所在的物理地址(或指针)。对目录的组织和管理是方便用户和提高对文件存取 速度的关键。③ 磁盘(磁带)存储空间。文件和目录必定占用存储空间，对这部分空间的有 效管理，不仅能提高外存的利用率，而且能提高对文件的存取速度。

2) 对对象操纵和管理的软件集合

这是文件管理系统的核心部分。文件系统的功能大多是在这一层实现的，其中包括: 对 文件存储空间的管理、对文件目录的管理、用于将文件的逻辑地址转换为物理地址的机制、 对文件读和写的管理，以及对文件的共享与保护等功能。

3) 文件系统的接口

为方便用户使用文件系统，文件系统通常向用户提供两种类型的接口:

(1) 命令接口。 这是指作为用户与文件系统交互的接口。 用户可通过键盘终端键入命 令，取得文件系统的服务。

(2) 程序接口。这是指作为用户程序与文件系统的接口。用户程序可通过系统调用来取 得文件系统的服务。

### 文件操作

文件的基本操作有创建、删除、修改等等操作，这里重点讲一下文件打开操作含义：

当前 OS 所提供的大多数对文件的操作，其过程大致都是这样两步: 第一步是通过检索文 件目录来找到指定文件的属性及其在外存上的位置；第二步是对文件实施相应的操作，如读 文件或写文件等。当用户要求对一个文件实施多次读/写或其它操作时，每次都要从检索目录 开始。为了避免多次重复地检索目录，在大多数 OS 中都引入了“打开”(open)这一文件系统 调用，当用户第一次请求对某文件进行操作时，先利用 open 系统调用将该文件打开。 

**所谓“打开”，是指系统将指名文件的属性(包括该文件在外存上的物理位置)从外存拷 贝到内存打开文件表的一个表目中，并将该表目的编号(或称为索引)返回给用户**。以后，当 用户再要求对该文件进行相应的操作时，便可利用系统所返回的索引号向系统提出操作请 求。系统这时便可直接利用该索引号到打开文件表中去查找，从而避免了对该文件的再次 检索。这样不仅节省了大量的检索开销，也显著地提高了对文件的操作速度。如果用户已 不再需要对该文件实施相应的操作时，可利用“关闭”(close)系统调用来关闭此文件，OS 将会把该文件从打开文件表中的表目上删除掉。

### 



## 文件逻辑结构

通常，文件是由一系列的记录组成的。文件系统设计的关键要素，是指将这些记录构 成一个文件的方法，以及将一个文件存储到外存上的方法。事实上，对于任何一个文件， 都存在着以下两种形式的结构:

(1) 文件的逻辑结构(File Logical Structure)。这是从用户观点出发所观察到的文件组织 形式，是用户可以直接处理的数据及其结构，它独立于文件的物理特性，又称为文件组织(File Organization)。

(2) 文件的物理结构，又称为文件的存储结构，是指文件在外存上的存储组织形式。这 不仅与存储介质的存储性能有关，而且与所采用的外存分配方式有关。

> 这里说到与外存的分配方式有关，就是说的设备管理中的磁盘调度问题；

### 逻辑结构类型

对文件逻辑结构所提出的基本要求，首先是能提高检索速度，即在将大批记录组成文 件时，应有利于提高检索记录的速度和效率；其次是便于修改，即便于在文件中增加、删 除和修改一个或多个记录；第三是降低文件的存储费用，即减少文件占用的存储空间，不 要求大片的连续存储空间。

文件的逻辑结构可分为两大类，一类是有结构文件，这是指由一个以上的记录构成的 文件，故又把它称为记录式文件；其二是无结构文件，这是指由字符流构成的文件，故又 称为流式文件。

#### 按文件是否有结构分类

##### 1．有结构文件

在记录式文件中，每个记录都用于描述实体集中的一个实体，各记录有着相同或不同 数目的数据项。记录的长度可分为定长和不定长两类。

(1) 定长记录。这是指文件中所有记录的长度都是相同的，所有记录中的各数据项都处 在记录中相同的位置，具有相同的顺序和长度。文件的长度用记录数目表示。对定长记录 的处理方便、开销小，所以这是目前较常用的一种记录格式，被广泛用于数据处理中。

(2) 变长记录。这是指文件中各记录的长度不相同。产生变长记录的原因，可能是由于 一个记录中所包含的数据项数目并不相同，如书的著作者、论文中的关键词等；也可能是 数据项本身的长度不定，例如，病历记录中的病因、病史；科技情报记录中的摘要等。不 论是哪一种，在处理前，每个记录的长度是可知的。

##### 2 无结构文件

无结构文件通常说的是流式文件，比如系统中运行的源程序、可执行文件、库函数等等，其文件长度是以字节为单位的，对流式文件的访问是通过读写指针实现的。可以把流式文件 看做是记录式文件的一个特例，一个记录只有一个字节。

#### 按文件组织方式分类

(1) 顺序文件。这是由一系列记录按某种顺序排列所形成的文件。其中的记录通常是定 长记录，因而能用较快的速度查找文件中的记录。

(2) 索引文件。当记录为可变长度时，通常为之建立一张索引表，并为每个记录设置一 个表项，以加快对记录检索的速度。

(3) 索引顺序文件。这是上述两种文件构成方式的结合。它为文件建立一张索引表，为 每一组记录中的第一个记录设置一个表项。

(4) Pile file 堆文件

(5)hash文件

### 堆文件

是一种最简单的方式，按照数据到来的顺序来组建文件，没有结构。检索起来非常费时，

### 顺序文件

记录按其在文件中的逻辑顺序依次进入存储介质而建立的，即顺序文件中物理记录的顺序和逻辑记录的顺序是一致的。在顺序文件中，可以按照不同的顺序进行排列，可以分为两种情况：

第一种情况是串结构，各记录之间的顺序与关键字无关。通常的办法是由时间来决定，即按存入时间的先后排列，最先存入的记录作为第一个记录，其次存入的为第二个记录……，以此类推。

第二种情况是顺序结构，指文件中的所有记录按关键字（词）排列。可以按关键词的长短从小到大排序，也可以从大到小排序；或按其英文字母排序。

顺序文件的查询、增删效率都很慢，为此系统便要去逐个地查找诸记录。这时，顺序文件所表现出来的性能就可能很差，为了解决这一问题，可以为顺序文件配置一个运行记录文件(Log File)或称为事务文件(Transaction File)，把试图增加、删除或修改的信息记录于其中，规定每隔一定时间，例如4小时，将运行记录文件与原来的主文件加以合并，产生一个按关键字排序的新文件。

**顺序文件的最佳应用场合，是在对诸记录进行批量存取时，即每次要读或写一大批记录。**

### 索引文件

对于定长记录，除了可以方便地实现顺序存取外，还可较方便地实现直接存取。 然而，对于变长记录就较难实现直接存取了，因为用直接存取方法来访问变长记录文件中 的一个记录是十分低效的，其检索时间也很难令人接受。为了解决这一问题，可为变长记 录文件建立一张索引表，对主文件中的每个记录，在索引表中设有一个相应的表项，用于 记录该记录的长度 L 及指向该记录的指针(指向该记录在逻辑地址空间的首址)。由于索引表 是按记录键排序的，因此，索引表本身是一个定长记录的顺序文件，从而也就可以方便地 实现直接存取。

![image-20201117212632349](https://tva1.sinaimg.cn/large/0081Kckwgy1gksho7p3zfj30wa0cemy6.jpg)

在对索引文件进行检索时，首先是根据用户(程序)提供的关键字，并利用折半查找法去 检索索引表，从中找到相应的表项；再利用该表项中给出的指向记录的指针值，去访问所 需的记录。

> 索引文件的思想就是把顺序文件中关键字摘取出来建立一张表，然后通过对该表进行增删查找，最后在映射到真正的文件上，这样到达快速操作的目的



### 索引顺序文件

它是 顺序文件和索引文件相结合的产物。它将顺序文件中的所有记录分为若干个组(例如，50 个 记录为一个组)；为顺序文件建立一张索引表，在索引表中为每组中的第一个记录建立一个 索引项，其中含有该记录的键值和指向该记录的指针。如下图：

![image-20201117213000282](https://tva1.sinaimg.cn/large/0081Kckwgy1gkshrt97aij30wo0cwab7.jpg)

在对索引顺序文件进行检索时，首先也是利用用户(程序)所提供的关键字以及某种查 找算法去检索索引表，找到该记录所在记录组中第一个记录的表项，从中得到该记录组第 一个记录在主文件中的位置；然后，再利用顺序查找法去查找主文件，从中找到所要求的 记录。

> 其思想和索引文件是一样的，只不过他在建立索引表时进行了分组，这样使得索引表的容量变小，相当于压缩了文件数量。同理，还可以把索引表再一次建立索引，再次的进行映射分组，再次压缩了文件数量，这样就会比之前的数据量更小，这就是索引顺序文件的核心思路。对比看来，每次新的文件组织方式都是一点点的改进，而改进的思想都是差不多的 。
>
> 或者这样理解以字典为例，字典前面会以字母建立索引一级索引，然后再在之前的字母下在写一个字母，这样形成了2级索引，每个索引对应的实际字很多，但却用了少量的索引去标识出来了；同样的还有书，书的大章节、目录、二级目录这些都是索引的应用。

注意：索引文件是在顺序文件的基础上发展来的，顺序文件为了应对增、删情况多了一个事务文件（溢出文件）来记录增删、更新情况，那索引文件仍然有这个事务文件存在，不然单纯的建立这个索引仍然解决不了增删、更新的这种情况，这个要注意。

![image-20201117220836009](https://tva1.sinaimg.cn/large/0081Kckwgy1gksivzp8bsj30lw0fotbj.jpg)

### hash文件

这是目前应用最为广泛的一种直接文件。它利用 Hash 函数(或称散列函数)，可将记录 键值转换为相应记录的地址。但为了能实现文件存储空间的动态分配，通常由 Hash 函数所 求得的并非是相应记录的地址，而是指向一目录表相应表目的指针，该表目的内容指向相 应记录所在的物理块。

> 这个和java中的hashMap的中思想一致，把文件信息通过hash转换为一个特有的值，然后通过这个值去查找对应的文件，不过有个问题就是hash算法的通病，会存在hash碰撞，解决办法和hashMap是一样的，在hash法、移位等

![image-20201117213655913](https://tva1.sinaimg.cn/large/0081Kckwgy1gkshz0knphj30ow0g4js1.jpg)

## 文件目录

在现代计算机系统中，都要存储大量的文件。为了能对这些文件实施有效的管 理，必须对它们加以妥善组织，这主要是通过文件目录实现的。文件目录也是一种数据结 构，用于标识系统中的文件及其物理地址，供检索时使用。

对目录管理的要求如下：

(1) 实现“按名存取”，即用户只须向系统提供所需访问文件的名字，便能快速准确地 找到指定文件在外存上的存储位置。这是目录管理中最基本的功能，也是文件系统向用户 提供的最基本的服务。

(2) 提高对目录的检索速度。通过合理地组织目录结构的方法，可加快对目录的检索速 度，从而提高对文件的存取速度。这是在设计一个大、中型文件系统时所追求的主要目标。

(3) 文件共享。在多用户系统中，应允许多个用户共享一个文件。这样就须在外存中只 保留一份该文件的副本，供不同用户使用，以节省大量的存储空间，并方便用户和提高文 件利用率。

(4) 允许文件重名。系统应允许不同用户对不同文件采用相同的名字，以便于用户按照 自己的习惯给文件命名和使用文件。

### 文件控制块和索引结点

#### 文件控制块

为了能对一个文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构， 称之为“文件控制块(FCB)”。文件管理程序可借助于文件控制块中的信息，对文件施以各种 操作。文件与文件控制块一一对应，而人们把文件控制块的有序集合称为文件目录，即一个 文件控制块就是一个文件目录项。

为了能对系统中的大量文件施以有效的管理，在文件控制块中，通常应含有三类信息， 即基本信息、存取控制信息及使用信息。

1) 基本信息类

基本信息类包括: ① 文件名，指用于标识一个文件的符号名。在每个系统中，每一个 文件都必须有惟一的名字，用户利用该名字进行存取。② 文件物理位置，指文件在外存上 的存储位置，它包括存放文件的设备名、文件在外存上的起始盘块号、指示文件所占用的 盘块数或字节数的文件长度。③ 文件逻辑结构，指示文件是流式文件还是记录式文件、记录数；文件是定长记录还是变长记录等。④ 文件的物理结构，指示文件是顺序文件，还是 链接式文件或索引文件。

2) 存取控制信息类

存取控制信息类包括：文件主的存取权限、核准用户的存取权限以及一般用户的存取 权限。

3) 使用信息类

使用信息类包括: 文件的建立日期和时间、文件上一次修改的日期和时间及当前使用信 息(这项信息包括当前已打开该文件的进程数、是否被其它进程锁住、文件在内存中是否已 被修改但尚未拷贝到盘上)。应该说明，对于不同 OS 的文件系统，由于功能不同，可能只 含有上述信息中的某些部分。

![image-20201118170648002](https://tva1.sinaimg.cn/large/0081Kckwgy1gktfsdqh9cj30ec02y0ss.jpg)

#### 索引结点

文件目录通常是存放在磁盘上的，当文件很多时，文件目录可能要占用大量的盘块。 在查找目录的过程中，先将存放目录文件的第一个盘块中的目录调入内存，然后把用户所 给定的文件名与目录项中的文件名逐一比较。若未找到指定文件，便再将下一个盘块中的 目录项调入内存。设目录文件所占用的盘块数为 N，按此方法查找，则查找一个目录项平均 需要调入盘块(N+1)/2 次。假如一个 FCB 为 64 B，盘块大小为 1 KB，则每个盘块中只能存 放 16 个 FCB；若一个文件目录中共有 640 个 FCB，需占用 40 个盘块，故平均查找一个文 件需启动磁盘 20 次。

稍加分析可以发现，在检索目录文件的过程中，只用到了文件名，仅当找到一个目录 项(即其中的文件名与指定要查找的文件名相匹配)时，才需从该目录项中读出该文件的物理 地址。而其它一些对该文件进行描述的信息，在检索目录时一概不用。显然，这些信息在 检索目录时不需调入内存。为此，在有的系统中，如 UNIX 系统，便采用了把文件名与文 件描述信息分开的办法，亦即，使文件描述信息单独形成一个称为索引结点的数据结构， 简称为 i 结点。在文件目录中的每个目录项仅由文件名和指向该文件所对应的 i 结点的指针 所构成。

在 UNIX 系统中一个目录仅占 16 个字节，其中 14 个字节是文件名，2 个字节为 i 结点指针。在 1 KB 的盘块中可做 64 个目录项，这样，为找到一个文件，可使平均启动磁 盘次数减少到原来的 1/4（之前存放FCB的全部信息，一个FCB大小为64B，这里只有16B，所以相比缩减了1/4），大大节省了系统开销。

![image-20201118171437254](https://tva1.sinaimg.cn/large/0081Kckwgy1gktg0egdbpj309z04e3yl.jpg)

**2) 磁盘索引结点**

这是存放在磁盘上的索引结点。每个文件有惟一的一个磁盘索引结点，它主要包括以 下内容：

(1) 文件主标识符，即拥有该文件的个人或小组的标识符。

(2) 文件类型，包括正规文件、目录文件或特别文件。

(3) 文件存取权限，指各类用户对该文件的存取权限。

(4) 文件物理地址，每一个索引结点中含有 13 个地址项，即 iaddr(0)～iaddr(12)，它们 以直接或间接方式给出数据文件所在盘块的编号。

(5) 文件长度，指以字节为单位的文件长度。

(6) 文件连接计数，表明在本文件系统中所有指向该(文件的)文件名的指针计数。

(7) 文件存取时间，指本文件最近被进程存取的时间、最近被修改的时间及索引结点最 近被修改的时间。

**3) 内存索引结点**

这是存放在内存中的索引结点。当文件被打开时，要将磁盘索引结点拷贝到内存的索 引结点中，便于以后使用。在内存索引结点中又增加了以下内容：

(1) 索引结点编号，用于标识内存索引结点。

(2) 状态，指示 i 结点是否上锁或被修改。

(3) 访问计数，每当有一进程要访问此 i 结点时，将该访问计数加 1，访问完再减 1。

(4) 文件所属文件系统的逻辑设备号。

(5) 链接指针。设置有分别指向空闲链表和散列队列的指针。

### 目录结构

目录结构的组织，关系到文件系统的存取速度，也关系到文件的共享性和安全性。因 此，组织好文件的目录，是设计好文件系统的重要环节。目前常用的目录结构形式有单级 目录、两级目录。

#### 单级目录结构

这是最简单的目录结构。在整个文件系统中只建立一张目录表，每个文件占一个目录 项，目录项中含文件名、文件扩展名、文件长度、文件类型、文件物理地址以及其它文件 属性。

![image-20201118172514390](https://tva1.sinaimg.cn/large/0081Kckwgy1gktgbfzl2zj30dk03jdfx.jpg)

​																											单级目录

单级目录实现了文件**按名存取**，但有很多缺点：

(1) 查找速度慢。对于稍具规模的文件系统，会拥有数目可观的目录项，致使为找到一 个指定的目录项要花费较多的时间。对于一个具有 N 个目录项的单级目录，为检索出一个 目录项，平均需查找 N/2 个目录项。

(2) 不允许重名。在一个目录表中的所有文件，都不能与另一个文件有相同的名字。然 而，重名问题在多道程序环境下却又是难以避免的；

>  一级目录对于多用户系统来说，每个用户的文件都放在一起，这样来说绝对是一个非常不好的体验，现在这样基本不用了

#### 两级目录

两级目录就是在一级目录上，添加了一个表示用户的目录，形成 user file directory/mater file directory 的形式，相比一级目录，多了user file directory 目录，这样解决了文件重名问题，同时也会较一级目录提升文件检索速度。

![image-20201118175041960](https://tva1.sinaimg.cn/large/0081Kckwgy1gkth1xyl2mj30jz082wfb.jpg)

### 树形目录

树形目录是现在采用最多的目录结构形式。树型目录结构又称为多级目录结构，主目录在这里被称为根目录，把 数据文件称为树叶，其它的目录均作为树的结点。如下图：

![树形目录](https://tva1.sinaimg.cn/large/0081Kckwgy1gkth5xypgnj30fq0bjwhk.jpg)

![image-20201118175453364](https://tva1.sinaimg.cn/large/0081Kckwgy1gkth6aft8kj30h1096758.jpg)

主(根)目录中有三个用户的 总目录项 A、B 和 C。在 B 项所指出的 B 用户的总目录 B 中，又包括三个分目录 F、E 和 D， 其中每个分目录中又包含多个文件。这种结构在提升效率方面提升了很多，因为该结构类似于建立了索引，每一层都是一个索引，有多少层就是相当于建立了多少级索引，仔细想想是不是？

### 目录查询

当用户要访问一个已存在文件时，系统首先利用用户提供的文件名对目录进行查询， 找出该文件的文件控制块或对应索引结点；然后，根据 FCB 或索引结点中所记录的文件物 理地址(盘块号)，换算出文件在磁盘上的物理位置；最后，再通过磁盘驱动程序，将所需文 件读入内存。目前对目录进行查询的方式有两种: 线性检索法和 Hash 方法。

> 这里就是要对目录检索有一个感性认识

**1．线性检索法**

线性检索法又称为顺序检索法。在单级目录中，利用用户提供的文件名，用顺序查找 法直接从文件目录中找到指名文件的目录项。在树型目录中，用户提供的文件名是由多个 文件分量名组成的路径名， 此时须对多级目录进行查找。 假定用户给定的文件路径名是 /usr/ast/mbox，则查找/usr/ast/mbox 文件的过程如图

![image-20201118183455762](https://tva1.sinaimg.cn/large/0081Kckwgy1gktibyb6cuj30gq08s751.jpg)

具体查找过程说明如下： 首先，系统应先读入第一个文件分量名 usr，用它与根目录文件(或当前目录文件)中各 目录项中的文件名顺序地进行比较，从中找出匹配者，并得到匹配项的索引结点号 6，再从 6 号索引结点中得知 usr 目录文件放在 132 号盘块中，将该盘块内容读入内存。

接着，系统再将路径名中的第二个文件分量名 ast 读入，用它与放在 132 号盘块中的第二 级目录文件中各目录项的文件名顺序进行比较，又找到匹配项，从中得到 ast 的目录文件放在 26 号索引结点中，再从 26 号索引结点中得知/usr/ast 是存放在 496 号盘块中，再读入 496 号盘块。

然后，系统又将该文件的第三个分量名 mbox 读入，用它与第三级目录文件/usr/ast 中各 目录项中的文件名进行比较，最后得到/usr/ast/mbox 的索引结点号为 60，即在 60 号索引结 点中存放了指定文件的物理地址。目录查询操作到此结束。如果在顺序查找过程中发现有 一个文件分量名未能找到，则应停止查找，并返回“文件未找到”信息。

**2．Hash 方法**

前面讲过的hash 目录一样，通过hash算法实现，就是把提供的用户名通过hash算法转换为文件目录索引，然后在存好的hash索引文件目录表中去查找。

## 记录组块方式

记录是存取文件的逻辑单位，数据块是I/O的基本单位，记录必须组织成数据块以便于I/O；这里的东西和内存分配很相似。每个扇区就像一个页，而一个记录就像一个作业进行装入到页内，这样就会存在内零头。

**问题：**

**数据块的长度是固定还是可变？**

大多数系统采用固定长度数据块，简化I/O操作，buffer 的分配及辅存中数据块的组织管理

**根据记录的平均长度如何设置数据块的长度？**

数据块越大，一次I/O传输的记录就越多；

大数据块适合文件顺序访问，因为这样可以减少I/O次数，加快处理速度；

当随机访问文件，或访问局部性很差时，传输的部分记录不会使用，效率低；

大数据块需要更大的buffer ，增加管理复杂度；



数据块一般按扇区容量大小，不宜太大太小。

### 固定块大小

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktpkoz7a0j30vm0ioguy.jpg" alt="image-20201118224530855" style="zoom:67%;" />

数据块由定长记录组成；

不允许一条记录跨越两个数据块；

### 固定块跨块组织

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktp3ndvk5j30ua0jk139.jpg" alt="image-20201118222906447" style="zoom: 67%;" />

数据块由定长记录组成；

允许一条记录跨越两个数据块；

### 可变长跨块组织

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktp6bg0psj30uc0k8k0u.jpg" alt="image-20201118223141974" style="zoom:67%;" />

数据块由变长记录组成；

不允许一条记录跨越两个数据块；

块内可能存在被浪费空间

## 外存的组织方式

第一节讲了什么是文件及文件分类，文件是一个软件概念，是操作系统抽象出来的一个东西，物理中是不存在，只是为了方便用户更好的使用而提出来的一个概念。同样，文件它对应的物理介质就是外存，即设备，最常用的设备就是磁盘，还有一些其他设备比如打印机、投影仪等等。我们现在要研究的是如何划分这些外存的组织方式，才能有效地利用外存空间和如何提高对文件的访问速度。这就是我们要研究的。

常用的外存分配方法有连续分配、链接分配和索引分配三种。文件的物理结构直接与外存分配方式有关。在采用不同的分配方式时，将 形成不同的文件物理结构。例如，在采用连续分配方式时的文件物理结构，将是顺序式的 文件结构；链接分配方式将形成链接式文件结构；而索引分配方式则将形成索引式文件 结构。

### 连续分配

**连续分配(Continuous Allocation)要求为每一个文件分配一组相邻接的盘块。**一组盘块的 地址定义了磁盘上的一段线性地址。例如，第一个盘块的地址为 b，则第二个盘块的地址为 b+1，第三个盘块的地址为 b+2……。通常，它们都位于一条磁道上，在进行读/写时，不必 移动磁头，仅当访问到一条磁道的最后一个盘块后，才需要移到下一条磁道，于是又去连 续地读/写多个盘块。**在采用连续分配方式时，可把逻辑文件中的记录按顺序地存储到邻接的各物理盘块中，这样所形成的文件结构称为顺序文件结构，此时的物理文件称为顺序文件**。 这种分配方式保证了逻辑文件中的记录顺序与存储器中文件占用盘块的顺序的一致性。为 使系统能找到文件存放的地址，应在目录项的“文件物理地址”字段中，记录该文件第一 个记录所在的盘块号和文件长度(以盘块数进行计量)。下图示出了连续分配的情况。图中 假定了记录与盘块的大小相同。Count 文件的第一个盘块号是 0，文件长度为 2，因此是在 盘块号为 0 和 1 的两盘块中存放文件 1 的数据。

![image-20201118212119419](https://tva1.sinaimg.cn/large/0081Kckwgy1gktn53hz1mj30yo0i6q5d.jpg)

​												这里有文件count、f、tr、mail、list，并假设文件记录刚好和每块磁盘大小一致。

如同内存的动态分区分配一样，随着文件建立时空间的分配和文件删除时空间的回收， 将使磁盘空间被分割成许多小块，这些较小的连续区已难于用来存储文件，此即外存的碎片。同样，我们也可以利用紧凑的方法，将盘上所有的文件紧靠在一起，把所有的碎片拼 接成一大片连续的存储空间。

>  例如，可以运行一个再装配例程(repack routine)，由它将磁盘 A 上的大量文件拷贝到一张软盘 B 或几张软盘(C，D，…)上，并释放原来的 A 盘，使之成 为一个空闲盘。然后再将软盘 B(C，D，…)上的文件拷回 A 盘上。这种方法能将含有多个 文件的盘上的所有空闲盘块都集中在一起，从而消除了外部碎片。但为了将外存上的空闲 空间进行一次紧凑，所花费的时间远比将内存紧凑一次所花费的时间多得多。

**2．连续分配的主要优缺点**

连续分配的主要优点如下：

(1) 顺序访问容易。访问一个占有连续空间的文件非常容易。系统可从目录中找到该顺 序文件所在的第一个盘块号，从此开始顺序地、逐个盘块地往下读/写。

(2) 顺序访问速度快。因为由连续分配所装入的文件，其所占用的盘块可能是位于一条 或几条相邻的磁道上，这时，磁头的移动距离最少，因此，这种对文件访问的速度是几种 存储空间分配方式中最高的一种。 

连续分配的主要缺点如下：

(1) 要求有连续的存储空间。要为每一个文件分配一段连续的存储空间，这样，便会产 生出许多外部碎片（外零头），严重地降低了外存空间的利用率。如果是定期地利用紧凑方法来消除 碎片，则又需花费大量的机器时间。

(2) 必须事先知道文件的长度。要将一个文件装入一个连续的存储区中，必须事先知道 文件的大小，然后根据其大小，在存储空间中找出一块其大小足够的存储区，将文件装入。 在有些情况下，知道文件的大小是件非常容易的事，如可拷贝一个已存文件。但有时却很 难，在此情况下，只能靠估算。如果估计的文件大小比实际文件小，就可能因存储空间不足而中止文件的拷贝，须再要求用户重新估算，然后再次执行。这样，显然既费时又麻烦。

> 这里说顺序组织速度很快，前面说的顺序文件查询又很慢，是不是矛盾？其实这里的顺序组织相当于一个数组形式，数组的访问很慢，但增删效率很低，对应了顺序组织的优缺点。而顺序文件查询很慢是相比较于索引文件查询很慢，要搞清楚这一点含义。

### 链接组织方式

如同内存管理一样，连续分配所存在的问题就在于: 必须为一个文件分配连续的磁盘空 间。如果在将一个逻辑文件存储到外存上时，并不要求为整个文件分配一块连续的空间， 而是可以将文件装到多个离散的盘块中，这样也就可以消除上述缺点。在采用链接分配 (Chained Allocation)方式时，可通过在每个盘块上的链接指针，将同属于一个文件的多个离 散的盘块链接成一个链表，把这样形成的物理文件称为链接文件。

由于链接分配是采取离散分配方式，消除了外部碎片，故而显著地提高了外存空间的 利用率；又因为是根据文件的当前需要，为它分配必需的盘块，当文件动态增长时，可动 态地再为它分配盘块，故而无需事先知道文件的大小。此外，对文件的增、删、改也十分 方便。

==想一想：这里的离散其实就是链表的数据结构，所以说数据结构真的是计算机的灵魂，底层设计思想全部提现在数据结构上，甚至思路都能看出来。==

链接方式又可分为隐式链接和显式链接两种形式。

#### 隐式链接

<img src="../../../Library/Application Support/typora-user-images/image-20201118213049453.png" alt="image-20201118213049453" style="zoom:67%;" />

图中示出了一个占用 5 个盘块的链接式文件。在相 应的目录项中，指示了其第一个盘块号是 9，最后一个盘块号是 25。而在每个盘块中都含 有一个指向下一个盘块的指针，如在第一个盘块 9 中设置了第二个盘块的盘块号是 16；在 16 号盘块中又设置了第三个盘块的盘块号 1。在文件目录的每个目录项中，都须含有指向链接文件第 一个盘块和最后一个盘块的指针。

#### 显式链接

这是指把用于链接文件各物理块的指针，显式地存放在内存的一张链接表中。该表在 整个磁盘仅设置一张，如图所示。表的序号是物理盘块号，从 0 开始，直至 N-1；N 为 盘块总数。在每个表项中存放链接指针，即下一个盘块号。在该表中，凡是属于某一文件 的第一个盘块号，或者说是每一条链的链首指针所对应的盘块号，均作为文件地址被填入 相应文件的 FCB 的“物理地址”字段中。由于查找记录的过程是在内存中进行的，因而不 仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。由于分配给文件的所有盘块 号都放在该表中，故把该表称为文件分配表 FAT(File Allocation Table)。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktni2wc3xj30lg0asq3g.jpg" alt="image-20201118213348588" style="zoom:67%;" />

我们看到这里显示链接的思想前面也有体现：就是抽离部分关键信息作为一个表，形成映射关系，然后查找关键字，在通过表查找真正要找的东西。

### 索引组织方式

#### 单级索引分配

链接分配方式虽然解决了连续分配方式所存在的问题，但又出现了下述另外两个问题：

(1) 不能支持高效的直接存取。要对一个较大的文件进行直接存取，须首先在 FAT 中顺 序地查找许多盘块号。

(2) FAT 需占用较大的内存空间。由于一个文件所占用盘块的盘块号是随机地分布在 FAT 中的，因而只有将整个 FAT 调入内存，才能保证在 FAT 中找到一个文件的所有盘块号。 当磁盘容量较大时，FAT 可能要占用数兆字节以上的内存空间，这是令人难以接受的。

***怎么办呢？但凡涉及到数量大的查找，似乎都可以建立索引，抽离关键信息形成映射。如果建立索引之后，还有大量数据，那就再次建立索引，再次形成映射关系。这样查找效率会成数量级的提升。这一点会在文件、磁盘的组织中大量用到。***

看到这里单级索引，就是相当于建立一级索引，后面肯定还有多级索引，就是这样一点点改进。

事实上，在打开某个文件时，只需把该文件占用的盘块的编号调入内存即可，完全没 有必要将整个 FAT 调入内存。为此，应将每个文件所对应的盘块号集中地放在一起。索引 分配方法就是基于这种想法所形成的一种分配方法。它为每个文件分配一个索引块(表)，再 把分配给该文件的所有盘块号都记录在该索引块中，因而该索引块就是一个含有许多盘块 号的数组。在建立一个文件时，只需在为之建立的目录项中填上指向该索引块的指针。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktnqpb6x5j30yq0iaad8.jpg" alt="image-20201118214204829" style="zoom:67%;" />

索引分配方式支持直接访问。当要读文件的第 i 个盘块时，可以方便地直接从索引块中 找到第 i 个盘块的盘块号；此外，索引分配方式也不会产生外部碎片。当文件较大时，索引 分配方式无疑要优于链接分配方式。

索引分配方式的主要问题是：可能要花费较多的外存空间。每当建立一个文件时，便 须为之分配一个索引块，将分配给该文件的所有盘块号记录于其中。但在一般情况下，总 是中、小型文件居多，甚至有不少文件只需 1～2 个盘块，这时如果采用链接分配方式，只 需设置 1～2 个指针。如果采用索引分配方式，则同样仍须为之分配一索引块。通常是采用 一个专门的盘块作为索引块，其中可存放成百个、甚至上千个盘块号。可见，对于小文件 采用索引分配方式时，其索引块的利用率将是极低的。

#### 多级索引分配

当 OS 为一个大文件分配磁盘空间时，如果所分配出去的盘块的盘块号已经装满一个索 引块时，OS 便为该文件分配另一个索引块，用于将以后继续为之分配的盘块号记录于其中。 依此类推，再通过链指针将各索引块按序链接起来。显然，当文件太大，其索引块太多时， 这种方法是低效的。此时，应为这些索引块再建立一级索引，称为第一级索引，即系统再 分配一个索引块，作为第一级索引的索引块，将第一块、第二块……等索引块的盘块号填 入到此索引表中，这样便形成了两级索引分配方式。如果文件非常大时，还可用三级、四 级索引分配方式。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktnsnlqqmj30za0oogoc.jpg" alt="image-20201118214358275" style="zoom:67%;" />





## 文件存储空间管理

文件管理要解决的重要问题之一是如何为新创建的文件分配存储空间。其分配方法与内存的分配有许多相似之处，即同样可采取连续分配方式或离散分配方式。前者具有较高 的文件访问速度，但可能产生较多的外存零头；后者能有效地利用外存空间，但访问速度 较慢。

现在要明白为文件分配存储空间，那谁来提供空间呢？当然是磁盘，所以这里就要研究如何为文件提供空间，而磁盘的存储单位是磁盘块而非字节，即找到磁盘块和文件的组成逻辑单位的记录数量关系，使得按该数量关系去分配是最合理的，所以就是要盘块如何去分配，如何记录已经分配了的盘块，也要像内存一样提供回收手段。

下面介绍几种常用的文件存储空间的管理方法。

### 空闲表法

#### 1) 空闲表

空闲表法属于连续分配方式，它与内存的动态分配方式雷同，它为每个文件分配一块 连续的存储空间，即系统也为外存上的所有空闲区建立一张空闲表，每个空闲区对应于一 个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息。 再将所有空闲区按其起始盘块号递增的次序排列

| 序号 | 第一空闲盘块号 | 空闲盘块数 |
| ---- | -------------- | ---------- |
| 1    | 2              | 4          |
| 2    | 9              | 3          |
| 3    | 15             | 5          |
| 4    | —              | —          |

2) 存储空间的分配与回收

空闲盘区的分配与内存的动态分配类似，同样是采用首次适应算法、循环首次适应算 法等。例如，在系统为某新创建的文件分配空闲盘块时，先顺序地检索空闲表的各表项， 直至找到第一个其大小能满足要求的空闲区，再将该盘区分配给用户(进程)，同时修改空闲 表。系统在对用户所释放的存储空间进行回收时，也采取类似于内存回收的方法，即要考 虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。

应该说明，在内存分配上，虽然很少采用连续分配方式，然而在外存的管理中，由于 这种分配方式具有较高的分配速度，可减少访问磁盘的 I/O 频率，故它在诸多分配方式中仍 占有一席之地。

#### 2．空闲链表法

空闲链表法是将所有空闲盘区拉成一条空闲链。根据构成链所用基本元素的不同，可把链表分成两种形式：空闲盘块链和空闲盘区链。

(1) 空闲盘块链。这是将磁盘上的所有空闲空间，以盘块为单位拉成一条链。当用户因 创建文件而请求分配存储空间时，系统从链首开始，依次摘下适当数目的空闲盘块分配给 用户。当用户因删除文件而释放存储空间时，系统将回收的盘块依次插入空闲盘块链的末 尾。这种方法的优点是用于分配和回收一个盘块的过程非常简单，但在为一个文件分配盘 块时，可能要重复操作多次。

(2) 空闲盘区链。这是将磁盘上的所有空闲盘区(每个盘区可包含若干个盘块)拉成一条 链。在每个盘区上除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小(盘块 数)的信息。分配盘区的方法与内存的动态分区分配类似，通常采用首次适应算法。在回收 盘区时，同样也要将回收区与相邻接的空闲盘区相合并。在采用首次适应算法时，为了提 高对空闲盘区的检索速度，可以采用显式链接方法，亦即，在内存中为空闲盘区建立一张 链表。

### 位示图法

#### 位示图

![image-20201118232034409](https://tva1.sinaimg.cn/large/0081Kckwgy1gktql7xriij314g07mn0t.jpg)

|      | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   | 16   |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 1    | 1    | 1    | 0    | 0    | 0    | 1    | 1    | 1    | 0    | 0    | 1    | 0    | 0    | 1    | 1    | 0    |
| 2    | 0    | 0    | 0    | 1    | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0    | 1    | 1    | 1    |
| 3    | 1    | 1    | 1    | 0    | 0    | 0    | 1    | 1    | 1    | 1    | 1    | 1    | 0    | 0    | 0    | 0    |
| 4    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
| M    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
| 16   |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |

### 成组链接法

空闲表法和空闲链表法都不适用于大型文件系统，因为这会使空闲表或空闲链表太长。 在 UNIX 系统中采用的是成组链接法，这是将上述两种方法相结合而形成的一种空闲盘块 管理方法，它兼备了上述两种方法的优点而克服了两种方法均有的表太长的缺点



## 文件共享

在现代计算机系统中，必须提供文件共享手段，即系统应允许多个用户(进程)共享同一 份文件。这样，在系统中只需保留该共享文件的一份副本。如果系统不能提供文件共享功 能，就意味着凡是需要该文件的用户，都须各自备有此文件的副本，显然这会造成对存储 空间的极大浪费。随着计算机技术的发展，文件共享的范围也在不断扩大，从单机系统中 的共享，扩展为多机系统的共享，进而又扩展为计算机网络范围的共享，甚至实现全世界 的文件共享。

下面说两种常用的文件共享方式: 硬连接、软连接

### 基于索引结点的共享方式（硬链接）

在树形结构的目录中，当有两个或多个用户要共享一个子目录或文件时，必须将共享文件或子目录链接到两个或多个用户的目录中，才能方便地找到该文件，如下图所示。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktm4a9m0yj30wo0hyq6a.jpg" alt="image-20201118204556551" style="zoom:67%;" />

在这种共享方式中引用索引结点，即诸如文件的物理地址及其他的文件属性等信息，不再是放在目录项中，而是放在索引结点中。在文件目录中只设置文件名及指向相应索引结点的指针。在索引结点中还应有一个链接计数count,用于表示链接到本索引结点（亦即文件） 上的用户目录项的数目。当count=2时，表示有两个用户目录项链接到本文件上，或者说是有两个用户共享此文件。

当用户A创建一个新文件时，它便是该文件的所有者，此时将count置为1。当有用户 B要共享此文件时，在用户B的目录中增加一个目录项，并设置一指针指向该文件的索引结点。此时，文件主仍然是用户A，count=2。如果用户A不再需要此文件，不能将文件直接删除。因为，若删除了该文件，也必然删除了该文件的索引结点，这样便会便用户B的指针悬空，而用户B则可能正在此文件上执行写操作，此时用户B会无法访问到文件。因此用户A不能删除此文件，只是将该文件的count减1，然后删除自己目录中的相应目录项。用户B仍可以使用该文件。当Count=0时，表示没有用户使用该文件，系统将负责删除该文件。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gktm7x72l3j30vk0d40vp.jpg" alt="image-20201118204926832" style="zoom:67%;" />



### 利用符号链实现文件共享 软连接

为使用户B能共享用户A的一个文件F,可以由系统创建一个LINK类型的新文件，也取名为F，并将文件F写入用户B的目录中，以实现用户B的目录与文件F的链接。在新文件中只包含被链接文件F的路径名。这样的链接方法被称为符号链接。

新文件中的路径名则只被看做是符号链，当用户B要访问被链接的文件F且正要读 LINK类新文件时，操作系统根据新文件中的路径名去读该文件，从而实现了用户B对文件 F的共享。

在利用符号链方式实现文件共享时，只有文件的拥有者才拥有指向其索引结点的指针。而共享该文件的其他用户则只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除一共享文件后留下一悬空指针的情况。当文件的拥有者把一个共享文件删除后，其他用户通过符号链去访问它时，会出现访问失败，于是将符号链删除，此时不会产生任何影响。当然，利用符号链实现文件共享仍然存在问题.

>  例如：一个文件釆用符号链方式共享，当文件拥有者将其删除，而在共享的其他用户使用其符号链接访问该文件之前，又有人在同一路径下创建了另一个具有同样名称的文件，则该符号链将仍然有效，但访问的文件已经改变，从而导致错误。

在符号链的共享方式中，当其他用户读共享文件时，需要根据文件路径名逐个地查找目录，直至找到该文件的索引结点。因此，每次访问时，都可能要多次地读盘，使得访问文件的开销变大并增加了启动磁盘的频率。此外，符号链的索引结点也要耗费一定的磁盘空间。符号链方式有一个很大的优点，即网络共享只需提供该文件所在机器的网络地址以及该机器中的文件路径即可.

### 比较

硬链接的限制比较多，既不能跨文件系统，也不能链接目录，而且源文件和硬链接文件之间除 inode 号是一样的之外，没有其他明显的特征。而软连接像软件启动的快捷方式、网络中url 都是软连接，当我们删除快捷方式，而源文件还存在，当删除源文件则链接文件就会失效，这和我们的认知是一样的。

## 文件保护

文件权限

E（Execution）:可以执行程序，但不能复制copy。

R （Read）：可以执行程序，可以复制。

Appending ：可以追加内容，但是不能修改、删除内容。

> 比如超市收银员，他只能对客户买的东西进行扫描，然后把扫描的内容添加进数据库，但不能说删除某个数据。对应的情况就是某个收银员把客户买的的东西都扫描了，并按了确认键，这时候客户说某个东西不要了，这时候收银员一般说不行，已经进库了，除非让经理过来登录一个具有修改权限的账号进行操作。

Updating :可以修改、删除、新增文件内容，同时也可以创建文件、移除文件；**注意：不能删除文件，只能删除文件内容**

Changing proteciton: 用户可以修改权限对某个用户的权限；**比如：系统管理人员**

Deletion：删除文件；

Linux中分 E 、R、W 三种权限。

文件所有者Owner

拥有所有权限；给某些人员分配文件权限