**写在前面的思考？**

这门课连接了计算机组成原理、Linux 基础、其他各种编程语言的基础。它的下一级是计算机组成原理，对上其他的各种应用软件、编程语言，而各种编程语言的实现也是基于操作系统的，所以明白了最底层的操作系统，在来反过来理解编程语言，就会发现他们大同小异，或多或少都有操作系统的影子，包括思想、设计、概念。举例来说，操作系统讲进程调度，那对应的编程语言肯定也会涉及到这个东西，比如说线程的调度，而且线程中的中断，会对应到进程，甚至对应到计算机组成原理中讲的硬件中断，在到微机层面的中断，到数电模电的中断，你就会发现这一些列的东西原理如此，他们的之间的关系是这样的，就会发现大学里面的课程都是有其意义的，只不过明白了有点晚，哈哈。学东西，如果您能够高屋建瓴、俯视而下，系统综合的看待这门学科，把其和其他的东西练习起来，形成一个系统，这个系统就我讲的就是整个计算机领域，这样你就会豁然开朗，一往无前。

# 第一章 概述与引论

- 操作系统的概念、特征、功能和提供的服务
- 操作系统的发展与分类
- 运行环境：内核态与用户态：中断、异常、系统调用
- 体系结构

![image-20200925232140076](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj3b5qv1dyj313e0e6gux.jpg)

体系结构图：如上



## 发展历程

1. 人工处理：人工把带孔的纸带装入纸带机，进行输入

2. 脱机处理：用机器控制纸带的输入，而不是人工，提升输入效率；

3. 单道批处理：用晶体管替代真空管；**把一批作业以脱机方式输入到磁带上，并在系统中配上监督程序(Monitor)，使得作业能够持续进行，进一步提升效率，解决人机速度不匹配问题**——标志操作系统的出现

4. 多道批处理：集成电路替代单个晶体管；在单道批处理系统中，内存中仅有一道作业，系统资源利用不充分，引入多道处理，**同时在内存中装有若干道程序，并使它们交替地运行，当正在运行的程序因 I/O 而暂停执行时，系统可调度另一道程序运行**，从而保持了 CPU 处于忙碌状态；**实现作业自动控制无需人工干预，实现批处理的**

   > 其实这里，我们是不是可以知道为啥会有锁、资源共享的概念？因为在物理世界中不可能有两个物体同时占有一个东西，对应到计算机里面也是一样的，然而，由于计算机的处理和转换的速度很快，所以这时候可以在一段时间内，表现“共享”的现象，但本质仍然是来回切换独占，不过这个时间很短，就称之为一段时间内共享了。

5. 分时系统：把处理器运行时间分成很短的时间片，时间片轮流把处理器分给某个程序；将一台主机提供给多个用户同时使用，提高计算机的利用率；**分时系统是解决人机交互性的**

   - 多路性：一台主机上同时联接多台联机终端，系统按分时原则为每个用户服 

     务

   - 独立性：每个用户各占一个终端，彼此独立操作，互不干扰

   - 及时性：用户的请求能在很短的时间内获得响应

   - 交互性：用户可通过终端与系统进行广泛的人机对话

6. 实时系统：所谓“实时”，是表示“及时”，而实时系统(Real Time System)是指系统能及时(或即时)

   响应外部事件的请求，在规定的时间内完成对该事件的处理

   实时系统和分时系统有类似的特性，但他更强调了可靠性。

7. 微机时代：

   1. 单用户单任务

   2. 单用户多任务：单用户多任务操作系统的含义是，只允许一个用户上机，但允许用户把程序分为若干 

      个任务，使它们并发执行，从而有效地改善了系统的性能

   3. 多用户多任务：允许多个用户通过各自的终端使用同一台机器，共享主机系统中的各种资源，而每个用户程序又可进一步分为几个任务，使它们能并发执行

## 特征

1. **并发**

   系统从单人单任务——单人多任务——多人任务；从单任务到多任务就是并发（一段时间内，执行多个程序）

   > 并发（一段时间内，执行多个程序）;并行——同一时间，执行多个程序

   **引入进程**

   **进程是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆 栈等组成的，是一个能独立运行的活动实体。** 目的是为了并行执行程序，提升效率（提升的本质是有效的利用了计算机资源）。

   > 在操作系统中引入进程的目的，就是为了使多个 程序能并发执行。例如，在一个未引入进程的系统中，在属于同一个应用程序的计算程序 和 I/O 程序之间，两者只能是顺序执行，即只有在计算程序执行告一段落后，才允许 I/O 程 序执行；反之，在程序执行 I/O 操作时，计算程序也不能执行，这意味着处理机处于空闲状 态，这样就浪费了cpu资源。或者可以一边读取内存数据，一边用cpu进行处理，这样也可以提升效率。因为读取数据不需要cpu的参与，相当于我们可以实时的利用两种计算机资源。

   **引入线程**

   长期以来，进程都是操作系统中可以拥有资源并作为独立运行的基本单位。当一个进程因故不能继续运行时，操作系统便调度另一进程运行。由于进程拥有自己的资源，故使调度付出的开销较大；所以用线程来调度。通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源；==通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度 的基本单位==。由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多。

2. **共享**

   1. 互斥：就是编程概念上对某个资源上锁，线程独占的意思。在应用程序上就是进程独占；
   2. 同时访问：这里的“同时”指的一段时间内多个进程同时访问，同时是宏观概念上的，在微观上仍然是交替进行的。

3. **虚拟**

   虚拟指的是把物理上的实体变为若干逻辑上对应物；比如多处理器，虚拟多个cpu；虚拟多个终端设备；

   1．时分复用技术

   时分复用，亦即分时使用方式，它最早用于电信业中。为了提高信道的利用率，人们利用时分复用方式，将一条物理信道虚拟为多条逻辑信道，将每条信道供一对用户通话。我们在计算机网络原理中 看到了这个名词；比如说有多个进程，但只有一个cpu，一个cpu为多个进程服务，就是一种在时间上的复用。

   2. 空分复用技术

      电信业中就使用频分复用技术来提高信道的利用率。它是将一个频率 范围非常宽的信道，划分成多个频率范围较窄的信道，其中的任何一个频带都只供一对用户通话。早期的频分复用只能将一条物理信道划分为十几条到几十条话路，后来又很快发 展成上万条话路，每条话路也只供一对用户通话。之后，在计算机中也使用了空分复用技 术来提高存储空间的利用率。

      1) 虚拟磁盘技术：将一台硬盘虚拟为多台虚拟磁盘，

4. **异步**

   多道环境允许多个程序（进程）并发执行，由于资源有限，进程执行并不是一贯到底的，是走走停停的；

## 操作系统作用

操作系统管理计算机的资源（处理器cpu、存储器——内存、IO——设备、文件），连接硬件和软件的桥梁。会对 处理器管理、存储器管理、设备管理、文件管理；方便用户操作系统，还必须提供用户接口。

![image-20200925234100103](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj3bpsbkd8j30e808udgh.jpg)



### 处理机管理

在传统的多道程序系统中，处理机的分配和运行都是以进程为基本单位，因而对处理机的管理可归结为对进程的管理；在引入了线程OS 中，也包含对线程的管理。处理机管理的主要功能是创建和撤消进程(线程)，对诸进程(线程)的运行进行协调，实现进程(线程)之间的信息交换，以及按照一定的算法把处理机分配给进程(线程)。

#### 1 进程控制

创建、撤销进程，同时包含进程内的线程。

#### 2 进程同步

进程是以异步方式运行的，并以人们不可预知的速度向前推进。为使多个进程能有条不紊地运行，系统中必须设置进程同步机制。进程同步的主要任务是为多个进程(含线程)的运行进行协调。有两种协调方式：

(1) 进程互斥方式。这是指诸进程(线程)在对临界资源进行访问时，应采用互斥方式；

(2) 进程同步方式。这是指在相互合作去完成共同任务的诸进程(线程)间，由同步机构对它们的执行次序加以协调。

实现进程同步，必须有相应的同步机制，比如说锁机制，对共享资源访问时，用锁来控制谁该访问，其内部原理是信号量机制。

#### 3 进程通信

一个任务往往需要多个进程进行配合完成，这时候涉及到进程通信，IPC、binder；看到这里来是不是很熟悉，android里这些都有，因为android也是一个操作系统 

#### 4  调度

在后备队列上等待的每个作业都需经过调度才能执行。在传统的操作系统中，包括作业调度和进程调度两步。 

(1) **作业调度**。作业调度的基本任务是从后备队列中按照一定的算法，选择出若干个 作业，为它们分配运行所需的资源(首先是分配内存)。在将它们调入内存后，便分别为它们建立进程，使它们都成为可能获得处理机的就绪进程，并按照一定的算法将它们插入就 绪队列。

(2) **进程调度。**进程调度的任务是从进程的就绪队列中，按照一定的算法选出一个进程，把处理机分配给它，并为它设置运行现场，使进程投入执行。值得提出的是，在多线程 OS中，通常是把线程作为独立运行和分配处理机的基本单位，为此，须把就绪线程排成一个队列，每次调度时，是从就绪线程队列中选出一个线程，把处理机分配给它。 

### 存储器管理（内存管理）

存储器管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以及能从逻辑上扩充内存。为此，存储器管理应具有内存分配、内存保护、地址映射和内存扩充等功能。

#### 1 内存分配

内存分配的主要任务是为每道程序分配内存空间，使它们“各得其所”；提高存储器的利用率，以减少不可用的内存空间；允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。

#### 2 内存保护

内存保护的主要任务是确保每道用户程序都只在自己的内存空间内运行，彼此互不干 扰；绝不允许用户程序访问操作系统的程序和数据；也不允许用户程序转移到非共享的其 它用户程序中去执行。

> 内存保护和OOM异常有联系的，我们OOM就是因为内存不够，越界了导致发生了OOM。

#### 3 地址映射

一个应用程序(源程序)经编译后，通常会形成若干个目标程序；这些目标程序再经过链接便形成了可装入程序。这些程序的地址都是从“0”开始的，程序中的其它地址都是相对于起始地址计算的。**由这些地址所形成的地址范围称为“地址空间”，其中的地址称为“逻辑地址”或“相对地址”；**在多道程序环境下，每道程序不可能都从“0”地址开始装入(内存)，这就致使地址空间内的逻辑地址和内存空间中的物理地址不相一致。为使程序能正确运行，存储器管理必须提供地址映射功能，以将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。该功能应在硬件的支持下完成。

#### 4 **内存扩充**

存储器管理中的内存扩充任务并非是去扩大物理内存的容量，而是借助于虚拟存储技术，从逻辑上去扩充内存容量，使用户所感觉到的内存容量比实际内存容量大得多。

(1) 请求调入功能。允许在装入一部分用户程序和数据的情况下，便能启动该程序运行。在程序运行过程中，若发现要继续运行时所需的程序和数据尚未装入内存，可向 OS 发出请求，由 OS 从磁盘中将所需部分调入内存，以便继续运行。 

(2) 置换功能。若发现在内存中已无足够的空间来装入需要调入的程序和数据时，系统应能将内存中的一部分暂时不用的程序和数据调至盘上，以腾出内存空间，然后再将所需调入的部分装入内存。

### 设备管理

用于管理计算机系统中所有的外围设备，比如鼠标、键盘、光驱、磁盘等等外设；设备管理应具有缓存管理、设备分配和设备处理以及虚拟设备等功能。

#### 1．缓冲管理

CPU 运行的高速性和 I/O 低速性间的矛盾自计算机诞生时起便已存在了。而随着 CPU速度迅速提高，使得此矛盾更为突出，严重降低了 CPU 的利用率。如果在 I/O 设备和 CPU之间引入缓冲，则可有效地缓和 CPU 与 I/O 设备速度不匹配的矛盾，提高 CPU 的利用率， 进而提高系统吞吐量。因此，在现代计算机系统中，都无一例外地在内存中设置了缓冲区，而且还可通过增加缓冲区容量的方法来改善系统的性能。

最常见的缓冲区机制有单缓冲机制、 能实现双向同时传送数据的双缓冲机制，以及能供多个设备同时使用的公用缓冲池机制。 上述这些缓冲区都将由 OS 中的缓冲管理机制将它们管理起来。

#### 2．设备分配

设备分配的基本任务是根据用户进程的 I/O 请求、系统的现有资源情况以及按照某种设 备的分配策略，为之分配其所需的设备。如果在 I/O 设备和 CPU 之间还存在着设备控制器 和 I/O 通道时，还须为分配出去的设备分配相应的控制器和通道。

为了实现设备分配，系统中应设置设备控制表、控制器控制表等数据结构，用于记录 设备及控制器的标识符和状态。根据这些表格可以了解指定设备当前是否可用，是否忙碌， 以供进行设备分配时参考。在进行设备分配时，应针对不同的设备类型而采用不同的设备 分配方式。对于独占设备(临界资源)的分配，还应考虑到该设备被分配出去后系统是否安全。 在设备使用完后，应立即由系统回收。

#### 3 设备处理

设备处理程序又称为设备驱动程​序。其基本任务是用于**实现 CPU 和设备控制器之间的通信**，即由 CPU 向设备控制器发出 I/O 命令，要求它完成指定的 I/O 操作； 

### 文件管理

人们总是把程序和数据以文件的形式存储在磁盘和磁带上，供所有的或指定的用户使用。为此，在操作系统中必须配置文件管理机构。文件管理的主要任务 是对用户文件和系统文件进行管理，以方便用户使用，并保证文件的安全性。件 管理应具有对文件存储空间的管理、目录管理、文件的读/写管理，以及文件的共享与保护 等功能。

#### 1．文件存储空间的管理

#### 2 目录管理

为了使用户能方便地在外存上找到自己所需的文件，通常由系统为每个文件建立一个 目录项。目录项包括文件名、文件属性、文件在磁盘上的物理位置等。

#### 3 文件读/写

通过读写指针进行读写

### 操作系统与用户之间接口

为了让用户调用操作系统的服务，提供了接口，分为：

(1) 用户接口。它是提供给用户使用的接口，用户可通过该接口取得操作系统的服务；

(2) 程序接口。它是提供给程序员在编程时使用的接口，是用户程序取得操作系统服务的唯一途径

#### 用户接口

- 联机用户接口 ：当用户在终端或控制台上每键入一条命令后，系统便立即转入命令解释程序，对该 命令加以解释并执行该命令。
- 脱机用户接口 ： 该接口是为批处理作业的用户提供的，故也称为批处理用户接口。 该接口由一组作业控制语言(JCL)组成。批处理作业的用户不能直接与自己的作业交互作用， 只能委托系统代替用户对作业进行控制和干预。
- 图形用户接口 ：用户虽然可以通过联机用户接口来取得 OS 的服务，但这时要求用 户能熟记各种命令的名字和格式，并严格按照规定的格式输入命令。这既不方便又花时间， 于是，另一种形式的联机用户接口——图形用户接口便应运而生。

#### 程序接口

由一组系统调用组成，每一个系统调用都是一个能完成特定功能的子程 序，每当应用程序要求 OS 提供某种服务(功能)时，便调用具有相应功能的系统调用

- 

## 运行环境

计算机中，cpu通常执行两种不同的程序，一种是操作系统的内核程序，一种是用户自编程序。前者是后者的管理者，因此内核程序需要执行一些特权指令，而用户程序出于安全考虑其不能执行这些指令，比如IO指令、中断指令、存取寄存器等。我们可以理解为 cpu内部有一个开关，小开关为1 时，cpu处于核心态，可以执行特权指令，为0时，为用户态，不能执行。当然，操作系统运行在内核态，用户程序运行在用户态。

## 微内核

微内核(Micro Kernel)操作系统结构：微内核和多个服务器。微内核只提供基本的功能，把其他的非核心的功能用服务的形式提供，这样的做法目的保证os 灵活、易维护、可扩展。一般有以下特点：

1. 足够小的内核

2. 基于客户/服务器模式：**操作系统中最基本的部分放入内核中，而把操作系统的绝大部 分功能都放在微内核外面的一组服务器(进程)中实现**。例如用于提供对进程(线程)进行管理的进程(线程)服务器，提供虚拟存储器管理功能的虚拟存储器服务器，提供 I/O 设备管理的 I/O 设备管理服务器等，它们都是被作为进程来实现的，运行在用户态，客户与服务器之 间是借助微内核提供的消息传递机制来实现信息交互的。

   ![image-20200929224012349](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj7wft156jj30uw06gmy6.jpg)

3. 应用“机制与策略分离”原理

   所谓机制，是指实现某一功能的具体执行机构。而策略，则是在机制的基础上，借助于某 些参数和算法来实现该功能的优化，或达到不同的功能目标。通常，机制处于一个系统的 基层，而策略则处于系统的高层。在传统的 OS 中，将机制放在 OS 的内核的较低层，把策 略放在内核的较高层次中。而在微内核操作系统中，通常将机制放在 OS 的微内核中。正因 为如此，才有可能将内核做得很小。

4. 采用面向对象技术：这样便于程序的编写

### 微内核缺点

由于客户对 OS 提出的服务请求时，需要利用消息 实现多次交互和进行用户/内核模式及上下文的多次切换，频繁的状态（用户/内核态）切换导致效率低下。

> 在早期的 OS 中，用户进 程在请求取得 OS 服务时，一般只需进行两次上下文的切换：一次是在执行系统调用后，由 用户态转向系统态时；另一次是在系统完成用户请求的服务后，由系统态返回用户态时。 在微内核 OS 中，由于客户和服务器及服务器和服务器之间的通信，都需通过微内核，致使 同样的服务请求至少需要进行四次上下文切换。第一次是发生在客户发送请求消息给内核， 以请求取得某服务器特定的服务时；第二次是发生在由内核把客户的请求消息发往服务器 时；第三次是当服务器完成客户请求后，把响应消息发送到内核时；第四次是在内核将响 应消息发送给客户时。

![image-20200929224455196](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj7wkqzv8sj31080u01ky.jpg)

# 第二章 进程描述与控制

本章节重点：

- 进程和线程
  - 进程的概念与状态转换
  - 进程控制与管理
  - 进程通信：线程概念与多线程
- 处理机调度
  - 调度的概念、时机、切换
  - 调度基本准则、方式
- 进程同步
  - 信号量、管程，经典同步问题
  - 临界资源互斥
- 死锁
  - 概念、处理方法
  - 死锁预防、处理、检测

![image-20201014101050085](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjon2o27hdj30nh0cawm1.jpg)



## 2.1 前趋图和程序执行

### 2.1.1 前趋图

### 2.1.2 顺序执行

- 顺序性：处理机的操作严格按照程序所规定的顺序执行
- 封闭性：程序运行时独占全机资源，资源的状态(除初始状态外)只有本程序才能改变它。程序一旦开始执行，其执行结果不受外界因素影响
- 可再现性：只要程序执行时的环境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿地执行，还是“停停走走”地执行，都将获得相同的结果

### 2.1.3 并发执行

- 间断性：由于有多个程序在同一段时间执行，可能多个程序之间要相互协作，依赖，所以程序可能要等待其他程序，所以出现间断。
- 非封闭性：对比上面
- 不可再现性：对比上面

## 2.2 进程定义与特征

在多道程序环境下，程序的执行属于并发执行，此时它们将失去其封闭性，并具有间断性及不可再现性的特征。为了对并发执行的程序加以描述和控制，引入**进程**概念：

**进程 = 程序program + 数据 data + 进程控制块PCB（Process Control Block）** 

> 通常的程序是不能并发执行的。为使程序(含数据)能独立运行，应为之配置一进程控制块，即 PCB(Process Control Block)；而由程**序段、相关的数据段和 PCB 三部分便构成了进程实体**。在早期的 UNIX 版本中，把这三部分总称为“进程映像”。值得指出的是，在许多情况下所说的进程，实际上是指进程实体，例如，所谓创建进程，实质上是创建进程实体中的 PCB；而撤消进程，实质上是撤消进程的 PCB。

**「进程」**：是程序的一次执行，动态的；

**「程序」**：一组有序指令的集合，并存放于某种介质上，其本身并不具有运动的含义，因而是静态的；



下面说几个结论：

**(1) 进程是程序的一次执行。**

**(2) 进程是一个程序及其数据在处理机上顺序执行时所发生的活动。** 

**(3) 进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。**

### 进程控制块PCB

#### 作用：

1. 为了描述和控制进程的运行，系统为每个进程定义了一个数据结构——进程控制块 PCB(Process Control Block)，它是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB 中记录了操作系统所需的、用于描述进程的当前情况以及控制进程运行的全部信息。

2. 使一个在多道程序环境下不能独立运行的程序(含数据)，成为一个能独立运行的基本单位，一个能与其它进程并发执行的进程。或者说，OS 是根据 PCB 来对并发执行的进程进行控制和管理的。

> 当 OS 要调度某进程执行时，要从该进程的 PCB中查出其现行状态及优先级；在调度到某进程后，要根据其 PCB 中所保存的处理机状态信息，设置该进程恢复运行的现场，并根据其 PCB 中的程序和数据的内存始址，找到其程序和数据；进程在执行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也都需要访问 PCB；当进程由于某种原因而暂停执行时，又须将其断点的处理机环境保存在 PCB .

#### 信息

1) 进程标识符：自己id，父id，子id等等；

2) 处理机状态 

由处理机的各种寄存器中的内容组成的。处理机在运行时，许多信息都放在寄存器中。当处理机被中断时，所有这些信息都必须保存在 PCB 中，以便在该进程重新执行时，能从断点继续执行。

3) 进程调度信息

在 PCB 中还存放一些与进程调度和进程对换有关的信息，包括：① 进程状态，指明进程的当前状态，作为进程调度和对换时的依据；② 进程优先级，用于描述进程使用处理机的优先级别的一个整数，优先级高的进程应优先获得处理机；③ 进程调度所需的其它信息，它们与所采用的进程调度算法有关，比如，进程已等待 CPU 的时间总和、进程已执行的时间总和等；④ 事件，指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。

4) 进程控制信息

进程控制信息包括：① 程序和数据的地址，指进程的程序和数据所在的内存或外存地(首)址，以便再调度到该进程执行时，能从 PCB 中找到其程序和数据；② 进程同步和通信机制，指实现进程同步和进程通信时必需的机制，如消息队列指针、信号量等，它们可能 全部或部分地放在 PCB 中；③ 资源清单，即一张列出了除 CPU 以外的、进程所需的全部资源及已经分配到该进程的资源的清单；④ 链接指针，它给出了本进程(PCB)所在队列中的下一个进程的 PCB 的首地址。

###  进程管理中的数据结构

![image-20201014102223550](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjonep2qakj30fc0da76z.jpg)

计算机对各类资源进行抽象为各种数据结构，然后用表记录，这些包含内存、设备、文件、进程（多个进程）。

## 2.3 进程状态及转换

因为进程具有间断性，所以进程会处于不同的状态，下面探讨进程状态：

### 2.3.1 进程两状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnie8gs2vj30v40n447t.jpg" alt="进程2状态图" style="zoom:67%;" />

Running：进程获取cpu资源正在执行；

Not Running：非执行的进程就是Not Running；未执行的状态有可以分为阻塞和就绪状态。

如果展开来说非执行状态，其图例为：

![image-20201013105232980](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjninrkuxqj309q084aal.jpg)

**1) 就绪(Ready)状态**

当进程已分配到除 CPU 以外的所有必要资源后，只要再获得 CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。 

**2) 阻塞状态**

正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态， 亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求 I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。

> 阻塞状态是不能直接到运行态的，某个进程由于I/O 处于阻塞态，然后当事件发生获取到I/O资源后，此时进程需要先进入就绪队列，等待操作系统调度，当他被选中后，才能被执行

#### 进程阻塞与唤醒

##### 进程阻塞

正在执行的进程，当发现上述某事件时，由于无法继续执行，于是进程便通过调用阻塞原语 block 把自己阻塞。可见，进程的阻塞是进程自身的一种主动行为。进入 block 过程后，由于此时该进程还处于执行状态，所以应先立即停止执行，把进程控制块中的现行状 态由“执行”改为“阻塞”，并将 PCB 插入阻塞队列。如果系统中设置了因不同事件而阻塞的多个阻塞队列，则应将本进程插入到具有相同事件的阻塞(等待)队列。最后，转调度程序进行重新调度，将处理机分配给另一就绪进程并进行切换，亦即，保留被阻塞进程的处理机状态(在 PCB 中)，再按新进程的 PCB 中的处理机状态设置 CPU 的环境。

##### 进程唤醒过程

当被阻塞进程所期待的事件出现时，如 I/O 完成或其所期待的数据已经到达，则由有关进程(比如用完并释放了该 I/O 设备的进程)调用唤醒原语 wakeup( )，将等待该事件的进程唤醒。唤醒原语执行的过程是：首先把被阻塞的进程从等待该事件的阻塞队列中移出，将其 PCB 中的现行状态由阻塞改为就绪，然后再将该 PCB 插入到就绪队列中。应当指出，block 原语和 wakeup 原语是一对作用刚好相反的原语。因此，如果在某进程中调用了阻塞原语，则必须在与之相合作的另一进程中或其他相关的进程中安排唤醒原 语，以能唤醒阻塞进程；否则，被阻塞进程将会因不能被唤醒而长久地处于阻塞状态，从 而再无机会继续运行。

##### 引起进程阻塞和唤醒的事件

**1) 请求系统服务**

当正在执行的进程请求操作系统提供服务时，由于某种原因，操作系统并不立即满足该进程的要求时，该进程只能转变为阻塞状态来等待。例如，一进程请求使用某资源，如打印机，由于系统已将打印机分配给其他进程而不能分配给请求进程，这时请求者进程只能被阻塞，仅在其他进程在释放出打印机的同时，才将请求进程唤醒。 

**2) 启动某种操作**

当进程启动某种操作后，如果该进程必须在该操作完成之后才能继续执行，则必须先使该进程阻塞，以等待该操作完成。例如，进程启动了某 I/O 设备，如果只有在 I/O 设备完成了指定的 I/O 操作任务后进程才能继续执行，则该进程在启动了 I/O 操作后，便自动进入阻塞状态去等待。在 I/O 操作完成后，再由中断处理程序或中断进程将该进程唤醒。 

**3) 新数据尚未到达**

对于相互合作的进程，如果其中一个进程需要先获得另一(合作)进程提供的数据后才能 对数据进行处理，则只要其所需数据尚未到达，该进程只有(等待)阻塞。例如，有两个进程，进程 A 用于输入数据，进程 B 对输入数据进行加工。假如 A 尚未将数据输入完毕，则进程B 将因没有所需的处理数据而阻塞；一旦进程 A 把数据输入完毕，便可去唤醒进程 B。 

**4) 无新工作可做**

系统往往设置一些具有某特定功能的系统进程，每当这种进程完成任务后，便把自己阻塞起来以等待新任务到来。例如，系统中的发送进程，其主要工作是发送数据，若已有 的数据已全部发送完成而又无新的发送请求，这时(发送)进程将使自己进入阻塞状态； 仅 当又有进程提出新的发送请求时，才将发送进程唤醒。



### 2.3.2 进程五状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnitbm0jij30wo0m87br.jpg" alt="进程5状态图" style="zoom:67%;" />

或者：

<img src="../../../Desktop/进程图1.png" alt="进程图1" style="zoom:67%;" />

对比两状态、三状态，发现多了创建、退出状态，而且要搞明白创建状态和就绪状态的区别；

#### **「创建状态」**

进程是由PCB 描述的，包含进程id、名称等信息，当进程有了自己的PCB后，在装入内存，进入就绪队列。这样看到进程创建分两步1 是创建PCB，2是装入内存；所以在装入内存之前都是处于创建状态，所以要搞清楚这个概念。

> 程序是在内存中执行的，由于内存资源有限，所以创建好的进程不一定都会被及时的装入内存中，这就是我们平时说的加大内存可以提升电脑速度就是这个原因，这样我们就知道了创建的状态，和就绪状态区别是后者是需要等待处理机cpu的调度，当被调度后才能执行。这里就能明白如果cpu很强大，处理速度快，电脑性能也会比较好。但是要知道如果内存不够大，cpu的处理速度超过了内存数据处理速度，这时候单单提高cpu就没有意义，内存、cpu就像一个木桶效应。

**「进程的创建(Creation of Process)」** 

一旦操作系统发现了要求创建新进程的事件后，便调用进程创建原语 Creat( )按下述步 骤创建一个新进程。

(1) 申请空白 PCB。为新进程申请获得惟一的数字标识符，并从 PCB 集合中索取一个空白 PCB。 

(2) 为新进程分配资源。为新进程的程序和数据以及用户栈分配必要的内存空间。显然，此时操作系统必须知道新进程所需内存的大小。

(3) 初始化进程控制块。PCB 的初始化包括：① 初始化标识信息，将系统分配的标识符和父进程标识符填入新 PCB 中；② 初始化处理机状态信息，使程序计数器指向程序的入口地址，使栈指针指向栈顶；③ 初始化处理机控制信息，将进程的状态设置为就绪状态或 静止就绪状态，对于优先级，通常是将它设置为最低优先级，除非用户以显式方式提出高优先级要求。 

(4) 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列。

#### **「退出/终止状态」**

进程终止首先等待操作系统进行善后处理，然后将其 PCB 清零，并将 PCB 空间返还系统。终止的进程会在系统保留一些数据或记录，当这些数据被处理后，系统才会删除该进程。（我们看到终止的进程就是把PCB回收，返回给系统，这里也能看到PCB在进程中所起的作用）

**「进程的终止过程」**

如果系统中发生了上述要求终止进程的某事件，OS 便调用进程终止原语，按下述过程去终止指定的进程。

(1) 根据被终止进程的标识符，从 PCB 集合中检索出该进程的 PCB，从中读出该进程的状态。

(2) 若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度。 

(3) 若该进程还有子孙进程，还应将其所有子孙进程予以终止，以防它们成为不可控的进程。

(4) 将被终止进程所拥有的全部资源，或者归还给其父进程，或者归还给系统。

(5) 将被终止进程(PCB)从所在队列(或链表)中移出，等待其他程序来搜集信息。

> 会引起进程终止的原因：
>
> 1.正常执行完成后，执行退出、终止。
>
> 2.程序异常或错误——非法指令、运行超时、越界错误（访问的区域不存在）、算术错误等其他在编写程序时发生的错误；
>
> 3.外界干预——用户或操作系统终止某个进程、父进程请求终止子进程、父进程终止则其子进程也将被终止。

#### 「状态转换」

null——创建：进程创建，即为程序准备pcb 和数据；

创建——就绪：内存接纳外存中创建好的进程，把其放入就绪队列，成为就绪状态；

就绪——运行：系统调度就绪队列中的某个进程，获取了cpu资源，从就绪状态到执行状态；

运行——阻塞：在执行进程中，该进程需要从外部设备获取I/O数据，发生阻塞；

运行——就绪：在一个cpu执行周期内，该进程没有执行完，系统调度了其他进程，把该进程放入就绪队列中；

阻塞——就绪：当被阻塞的进程获取到相应的条件（IO事件完成），重新进入到就绪队列；

运行——终止：执行完成、外部干预、程序异常；

### 2.3.3 进程挂起

说起挂起，先了解一下 swaping 交换。 

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnzf1jd0pj30uy0ku15k.jpg" alt="swaping" style="zoom:67%;" />



#### 进程的挂起与激活

##### 进程的挂起

当出现了引起进程挂起的事件时，比如，用户进程请求将自己挂起，或父进程请求将自己的某个子进程挂起，系统将利用挂起原语 suspend( )将指定进程或处于阻塞状态的进程挂起。挂起原语的执行过程是：首先检查被挂起进程的状态，若处于活动就绪状态，便将其改为静止就绪； 对于活动阻塞状态的进程，则将之改为静止阻塞。**==为了方便用户或父进 程考查该进程的运行情况而把该进程的 PCB 复制到某指定的内存区域==**。

<!--处于挂起的时候，只是程序和数据被放到外存了，PCB放在内存中。这样系统才能感知进程状态，改变进程状态。这一个理解非常重要-->

##### 进程的激活过程

当发生激活进程的事件时，例如，父进程或用户进程请求激活指定进程，若该进程驻 留在外存而内存中已有足够的空间时，则可将在外存上处于静止就绪状态的该进程换入内 存。这时，系统将利用激活原语 active( )将指定进程激活。激活原语先将进程从外存调入内 存，检查该进程的现行状态，若是静止就绪，便将之改为活动就绪；若为静止阻塞，便将之改为活动阻塞。假如采用的是抢占调度策略，则每当有新进程进入就绪队列时，应检查 是否要进行重新调度，即由调度程序将被激活进程与当前进程进行优先级的比较，如果被激活进程的优先级更低，就不必重新调度；否则，立即剥夺当前进程的运行，把处理机分配给刚被激活的进程。

#### **进程什么时候会被挂起呢**？

(1) 终端用户的请求。当终端用户在自己的程序运行期间发现有可疑问题时，希望暂时使自己的程序静止下来。亦即，使正在执行的进程暂停执行；若此时用户进程正处于就绪状态而未执行，则该进程暂不接受调度，以便用户研究其执行情况或对程序进行修改。我们把这种静止状态称为挂起状态。 

(2) 父进程请求。有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，或者协调各子进程间的活动。 

(3) 负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。

(4) 操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。

**挂起的本质**

挂起实际上就是把进程从内存中调换到外存中，通过swaping 实现；

### 2.3.4进程七状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnzjfnmauj30v60pq7fs.jpg" alt="进程7状态" style="zoom:67%;" />

增加了就绪挂起、阻塞挂起；



#### 状态转换

就绪<——>就绪挂起：一般，OS挂起阻塞进程，但有时也会挂起就绪进程，释放内存；当某个时刻内存够用，则会把就绪挂起进程转变为就绪

阻塞<——>阻塞挂起：OS通常将阻塞进程换出，以腾出内存空间；当阻塞挂起的进程等待的事件发生时，也会被放入内存，变为block；

阻塞挂起——>就绪挂起：当进程等待的事件发生，可以从阻塞挂起到就绪挂起；



#### **Block vs Supend 挂起**

进程是否等待事件：阻塞与否

进程是否被换出内存：挂起与否

Ready：进程在内存，准备执行

Block：进程在内存，等待事件

Ready、Suspend：进程在外存，等待激活（调入内存）

Block、Suspend：进程在外存，等待事件。



![image-20201014101226368](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjon4c8vguj30fy0a8tc2.jpg)

P 代表进程、实现代表占用、虚线代表请求，p1、p2、p3 这三个进程会处于什么状态？

P1 为running、p2为block、p3为创建



## 2.4 进程控制

进程控制是进程管理中最基本的功能。它用于创建一个新进程，终止一个已完成的进程，或终止一个因出现某事件而使其无法运行下去的进程，还可负责进程运行中的状态转换。如当一个正在执行的进程因等待某事件而暂时不能继续执行时，将其转换为阻塞状态， 而当该进程所期待的事件出现时，又将该进程转换为就绪状态等等。进程控制一般是由 OS的内核中的**原语**来实现的。

一句话：**<u>进程控制负责进程的状态切换、进程创建及销毁，靠os中原语实现的</u>**；

<!--原语这个词是相对的，在操作系统层面，像wrtie、read这种系统指令对于程序员而言是不可分割的，原子性的，但是从系统本身来说，write、read指令也是由多条汇编语言组成，而每个汇编语言又是多个逻辑指令，即二进制的电极信号，这样说我们就明白了。 -->

### 2.4.1 操作系统功能

操作系统os内核一般有两大功能：**<u>支撑功能 、资源管理功能</u>**

#### 支撑功能

- Interrupt handing 中断处理 

  是多道程序系统最基本的功能，是其他活动赖以实现的基础。系统调用、I/O输入、进程调度、设备驱动都会用到中断。（想想，中断在现实生活中的含义）

- Timing 时钟管理 

  基本功能之一，时间片轮转调度中会用到时钟计功能；

- Primitive 原语 ：atomic operation 原子操作（这个原子操作其实也是基于中断实现的，所有锁的机制都是通过这个东西实现的）

  <!-- -->

- Accounting 统计

- Monitoring 监测

#### 资源管理功能

- 进程管理
- 内存管理
- 设备管理
- 文件管理

相关的介绍都在[第一章节](#操作系统作用) 

### 2.4.2 进程创建

[参考](# 「创建状态 )

### 2.4.3 进程终止

[参考](# 「退出/终止状态」)

### 2.4.4 进程阻塞

[参考](#进程阻塞与唤醒 )

### 2.4.5 进程挂起

[参考](#2.3.3 进程挂起 )

### 2.4.6 进程切换 vs 模式切换

![image-20201014154621913](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjowruf0yxj30ee09xafl.jpg)

用户进程切换一定引起模式切换，因为进程切换是os 在内核态提供的原语提供的指令，同时还有调度，这些都是内核态的功能，切换完之后去另一个进程，这样就会涉及模式的切换；但模式切换不一定会引起进程切换，因为从用户态到内核态不一定要新进程。

假如说：系统进程或者内核进程，这种不涉及到用户态的进程会有模式切换吗？

## 2.5 进程同步

主要掌握进程 并发、同步与互斥、死锁与饥饿、临界区；3个金典问题；

多进程系统在使用临界资源时，必须做好协调和同步工作，否则会造成竞争和死锁；

### 2.5.1基本概念

#### 临界资源

同处于一个系统中的进程，通常都共享着某种系统资源，如共 享 CPU、共享 I/O 设备等资源都是临界资源，进程间应采取互斥方式，实现对这种资源的共享。

#### 临界区

在每个进程中访问临界资源的那段代码称为临界区(critical section)。显然， 若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。

临界区前面增加一段用于进行上述检查的代码，把这段代码称为进入区(entry section)。相应 地，在临界区后面也要加上一段称为退出区(exit section)的代码，用于将临界区正被访问的 标志恢复为未被访问的标志。进程中除上述进入区、临界区及退出区之外的其它部分的代 码，在这里都称为剩余区。

```
while (true){
		进入区
		临界区
		退出区
		剩余区
}
```



#### 同步机制遵循的规则

(1) 空闲让进。当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求 进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。

(2) 忙则等待。当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进 入临界区的进程必须等待，以保证对临界资源的互斥访问。

(3) 有限等待。对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区， 以免陷入“死等”状态。

(4) 让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙 等”状态。



### 2.5.2 信号量机制

这个机制由荷兰科学家Dijkstra提出的，其机制为：

**进行代码抽象**

![IMG_5681](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjxwua2i4jj31sk0u04qp.jpg)



把临界资源定义为S，并提供**两个原子操作 Wait（S） 和Signal（S），不能被中断**，其操作如下：

```
wait(S)和 signal(S)操作可描述为：

procedure wait(S) 
		var S：semaphore； 
		begin 
			S.value:=S.value-1； 
			if S.value<0 then block(S.L)；
    end 
//value 表示临界资源可用数量    
procedure signal(S) 
		var S: semaphore； 
		begin 
			S.value:=S.value+1； 
			if S.value<=0 then wakeup(S.L)； 
		end
```

每次 wait 操作，意味着进程请求一个单位的该类资源，使系统中可供分配 的该类资源数减少一个，因此描述为 S.value:=S.value-1；当 S.value<0 时，表示该类资源已 分配完毕，**因此进程应调用 block 原语，进行自我阻塞，放弃处理机，并插入到信号量链表 S.L 中（不像软件、硬件中断出现忙等现象，因为他会进入阻塞状态，不占用processer）**。可见，该机制遵循了“让权等待”准则。此时 S.value 的绝对值表示在该信号量链 表中已阻塞进程的数目。对信号量的每次 signal 操作，表示执行进程释放一个单位资源，使 系统中可供分配的该类资源数增加一个，故 S.value:=S.value+1 操作表示资源数目加 1。若 加 1 后仍是 S.value≤0，则表示在该信号量链表中，仍有等待该资源的进程被阻塞，故还应 调用 wakeup 原语，将 S.L 链表中的第一个等待进程唤醒。**如果 S.value 的初值为 1，表示只允许一个进程访问临界资源，此时的信号量转化为互斥信号量，用于进程互斥。** 这就是用信号量实现进程互斥的原理；如何实现呢？

==我们只需要把 临界区代码 放到 互斥量mutex 的wait（mutex）和 signal（mutex）之间即可，并把互斥量的数量value设置为1。==  这就是实现核心精髓。

> 每个欲访问该临界资源的进程在进入临界区之前，都要先对 mutex 执行 wait 操作，若该资源此刻未被访问，本次 wait 操作必然成功，进程便可进入自己的临界区， 这时若再有其他进程也欲进入自己的临界区，此时由于对 mutex 执行 wait 操作定会失败，因而该进程阻塞，从而保证了该临界资源能被互斥地访问。当访问临界资源的进程退出临 界区后，又应对 mutex 执行 signal 操作，以便释放该临界资源。

假如说，有多个临界资源或者说某个资源的数目满足一定条件，则只需要在if 条件判断时，修改条件即可。

### 2.5.3 管程

由于进程同步很常见，会导致系统中存在很多临界资源，那每个临界资源都各自维护同步操作，带来了管理麻烦。于是用一种面向对象的“封装”的思想，引入管程来管理。它和信号量有同等的表达能力。

定义：

代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源 管理程序，共同构成了一个操作系统的资源管理模块，我们称之为管程。管程被请求和释放 资源的进程所调用。

管程由四部分组成：① 管程的名称；② 局部于管程内部的共享 数据结构说明；③ 对该数据结构进行操作的一组过程；④ 对局部于管程内部的共享数据 设置初始值的语句。

![image-20201020183042006](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvz8nk4oij30df09kq3h.jpg)

特性：

（1） 模块化：管程是一个基本程序单位，可以单独编译。

  (2) 抽象数据类型。管程中不仅有数据，而且有对数据的操作。

  (3) 信息掩蔽。管程中的数据结构只能被管程中的过程访问，这些过程也是在管程内部 定义的，供管程外的进程调用，而管程中的数据结构以及过程(函数)的具体实现外部不可见。

管程和进程不同，主要体现在以下几个方面：

(1) 虽然二者都定义了数据结构，但进程定义的是私有数据结构 PCB，管程定义的是公 共数据结构，如消息队列等；

(2) 二者都存在对各自数据结构上的操作，但进程是由顺序程序执行有关的操作，而管 程主要是进行同步操作和初始化操作；

(3) 设置进程的目的在于实现系统的并发性，而管程的设置则是解决共享资源的互斥使 用问题；

(4) 进程通过调用管程中的过程对共享数据结构实行操作，该过程就如通常的子程序一 样被调用，因而管程为被动工作方式，进程则为主动工作方式；

(5) 进程之间能并发执行，而管程则不能与其调用者并发；

(6) 进程具有动态性，由“创建”而诞生，由“撤销”而消亡，而管程则是操作系统中 的一个资源管理模块，供进程调用。

### **2.5.4 互斥方法**

软件方法 —— 内存中设置一个变量标记临界资源，使用时进行检查该变量，变量为true时表示为可用，否则不可用；缺陷：只能用于两个进程间互斥。或者说某个进程在进行检测和设置时，不能保证原子性；可能多个进程同时检查，同时进入了。

硬件方法

- 屏蔽中断：因为中断是程序调度的基础，所以通过屏蔽中断，不进行调度，达到原子目的。但是系统是多处理器，多个cpu就不适用了。相比软件方法：实现了原子操作，但缺点是代价太大，不能响应中断，如果此时有个高级别的任务则无法响应。
- 特殊机器指令：一个指令周期不产生中断。test-set 、exchange；缺陷：会产生忙等现象。占用资源，却不干事情。

信号量 ：[见上面](#2.5.2 信号量机制)

消息传递：是一种进程通信的方式，见[下面](#2.6 进程通信)。

## 2.6 进程通信

通信机制可归结为三大类： 共享存储器系统、消息传递系统以及管道通信系统。

### 2.6.1 简述

#### 共享存储器系统 Shared-Memory System  

基于共享存储区的通信方式。为了传输大量数据，在存储器中划出了一块共享存储 区，诸进程可通过对共享存储区中数据的读或写来实现通信。

#### 消息传递

应用最为广泛的一种进程间的通信机制。 在该机制中，进程间的数据交换是以格式化的消息(message)为单位的；在计算机网络中， 又把 message 称为报文。程序员直接利用操作系统提供的一组通信命令(原语)，不仅能实现 大量数据的传递，而且还隐藏了通信的实现细节，使通信过程对用户是透明的，从而大大 减化了通信程序编制的复杂性，因而获得了广泛的应用。

> 网络通信都是基于这个原理建立起来的，而这一块的内容又是一整个大块：计算机网络原理。而android 系统中进程间通信也是用的这种方式 Message。

#### 管道通信 pipe

所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享 文件，又名 pipe 文件。向管道(共享文件)提供输入的发送进程(即写进程)，以字符流形式将 大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。 由于发送进程和接收进程是利用管道进行通信的，故又称为管道通信。这种方式首创于 UNIX 系统，由于它能有效地传送大量数据，因而又被引入到许多其它的操作系统中。

#### 客户机-服务器系统

上面三种方式都可以应用于不同计算机之间通信，但是客户机——服务器这种方式更为流行，其实现是 socket 套接字、远程过程（方法）调用。

上述四种方式，重点理解消息传递系统实现的进程间通信。

### 2.6.2 消息传递通信实现

消息传递需要源进程和目标进程，系统要为其提供发送和接收原语。

#### 1 通信方式

直接通信：双方需要显示的知道对方的地址。

间接通信：有可能存在多个发送进程，比如打印请求，多个进程可以发送这个请求。

#### 2 通信链路

为使在发送进程和接收进程之间能进行通信， **必须在两者之间建立一条通信链路 (communication link)。有两种方式建立通信链路。第一种方式是由发送进程在通信之前用显 式的“建立连接”命令(原语)请求系统为之建立一条通信链路；在链路使用完后，也用显式 方式拆除链路。这种方式主要用于计算机网络中。**第二种方式是发送进程无须明确提出建 立链路的请求，只须利用系统提供的发送命令(原语)，系统会自动地为之建立一条链路。这 种方式主要用于单机系统中

#### 3 消息格式

message 包含什么信息；公用的消息头，包含主体消息的消息体；

#### 4 消息缓冲队列

这个东西，也在android 中看到，其实都是差不多的。这个东西的数据结构：

1 消息缓冲区：

```
typed struct message_buffer{
	int sender; //发送者进程标识
	int size;   //消息长度
	char text;  //消息内容
	struct message_buffer next; //下一个消息缓冲区指针
}
```

2 PCB 中新增的消息缓冲队列数据项

```
typedef struct processcontrol_block{
	struct message_buffer mq; 消息队列首指针
	semaphore mutex； 互斥信号量
	semaphore sm 资源信号量
}
```

3 发送原语

下图是 消息缓冲通信示意图：



![image-20201022144725282](https://tva1.sinaimg.cn/large/0081Kckwgy1gjy40ygmnpj30jw0al0tm.jpg)

```
procedure send(receiver，a)
	begin 
		getbuf(a.size,i)； 根据 a.size 申请缓冲区；
		i.sender:= a.sender； 将发送区 a 中的信息复制到消息缓冲区 i 中；
		i.size:=a.size； 
		i.text:=a.text； 
		i.next:=0； 
		getid(PCB set，receiver.j)； 获得接收进程内部标识符； 
		wait(j.mutex)； insert(j.mq，i)； 将消息缓冲区插入消息队列； 
		signal(j.mutex)； 
		signal(j.sm)；
end
```

4 接收原语

```
procedure receive(b)
	begin
  	j:= internal name；  j 为接收进程内部的标识符；
  	wait(j.sm)； 
  	wait(j.mutex)； 
  	remove(j.mq，i)；  将消息队列中第一个消息移出；
  	signal(j.mutex)； 
  	b.sender:=i.sender； 将消息缓冲区 i 中的信息复制到接收区 b；
  	b.size:=i.size； 
  	b.text:=i.text；

end
```



## 2.7 线程

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjoy84ppstj30fn0bz78r.jpg" alt="image-20201014163640010" style="zoom:80%;" />



为了减少程序在并发执行时所付出的时空开销，使 OS 具有更好的并发性，在进程的基础上引入线程；我们知道的进程两个基本属性: **① 进程是一个可拥有资源的独立单位；② 进程同时又是一个可独立调度和分派的基本单位**，使得进程能够独立运行而且并发执行。但是在进程的切换会消耗大量的资源，为了解决这个问题，把上述两个功能分开，引入线程承担第二个功能，进程只是拥有资源的独立单位。以线程作为调度和分派的基本单位，则可以有效地改善多处理机系统的性能。

### 2.7.1 线程vs 进程

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjoy84ppstj30fn0bz78r.jpg" alt="image-20201014163640010" style="zoom:80%;" />

​                                                                                            <!--单线程和多线程模型-->

线程具有许多传统进程所具有的特征，又称为轻型进程(Light-Weight Process)，传统进程相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都拥有若干个线程，至少也有一个线程。

1. 调度

在传统的操作系统中，作为拥有资源的基本单位和独立调度、分派的基本单位都是进程。而在引入线程的操作系统中，则把线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位，把传统进程的两个属性分开，使线程基本上不拥有资源，这样线程便能 轻装前进，从而可显著地提高系统的并发程度。在同一进程中，线程的切换不会引起进程的切换，但从一个进程中的线程切换到另一个进程中的线程时，将会引起进程的切换。 

2. 并发性

在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，使得操作系统具有更好的并发性，从而能更加有效地提高系统资源的利用率和系统的吞吐量。

3. 拥有资源 ：进程拥有资源，线程不拥有资源，但线程可以访问它隶属的进程的资源；
4. 系统开销

在创建或撤消进程时，系统都要为之创建和回收进程控制块，分配或回收资源，如内存空间和 I/O 设备等，操作系统所付出的开销明显大于线程创建或撤消时的开销。类似地，在进程切换时，涉及到当前进程 CPU 环境的保存及新被调度运行进程的 CPU 环境的设置，而线程的切换则仅需保存和设置少量寄存器内容，不涉及存储器管理方面的操作，所以就 切换代价而言，进程也是远高于线程的。此外，由于一个进程中的多个线程具有相同的地址空间，在同步和通信的实现方面线程也比进程容易。在一些操作系统中，线程的切换、 同步和通信都无须操作系统内核的干预。 

### 2.7.2 线程属性

在多线程os 中**（一定是多线程系统）**，一个进程包含多个线程，线程有下面属性：

1. 轻型：不具有系统资源，其组成有TCB 线程控制块，程序计数器，保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈；
2. 独立调度和分派的基本单位。在多线程 OS 中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位
3. 可并发执行。在一个进程中的多个线程之间可以并发执行，甚至允许在一个进程中的所有线程都能并发执行
4. 共享进程资源。在同一进程中的各个线程都可以共享该进程所拥有的资源，这首先表现在所有线程都具有相同的地址空间(进程的地址空间)

### 2.7.3 线程状态

线程的状态和进程一样，可以类比。

在多线程 OS 环境下，应用程序在启动时，通常仅有一个线程在执行，该线程被人们称 为“初始化线程”。它可根据需要再去创建若干个线程。在创建新线程时，需要利用一个线 程创建函数(或系统调用)。

> 这里我们可以想到android，创建了主线程(UI线程)，后面可以在主线程中去创建新的线程，

终止线程的方式有两种：一种是在线程完成了自己的工作后自愿退出；另一种是线程在运行中出现错误或由于某种原因而被其它线程 强行终止。。在大多数的 OS 中，线程被中止后并不立即释放它所占有的资源，只有当进程中的其它线程执行了分离函数后，被终止的线程才与资源分离，此时的资源才能被其它线程利用。

### 2.7.4 多线程OS中的进程

多线程os中，进程时拥有资源的独立单位，但不就不再作为一个执行的实体。是把线程作为独立运行的基本单位， 所以此时的进程已不再是一个可执行的实体。虽然如此，进程仍具有与执行相关的状态。例如，所谓进程处于“执行”状态，实际上是指该进程中的某线程正在执行。此外，对进程所施加的与进程状态有关的操作，也对其线程起作用。例如，在把某个进程挂起时，该进程中的所有线程也都将被挂起；又如，在把某进程激活时，属于该进程的所有线程也都将被激活。 

### 2.7.5 线程实现方式

#### **内核支持线程**

在内核的支持下运行的，即无论是用户进程中的线程，还是系统进程中的线程，他们的创建、撤消和切换等也是依靠内核，在内核空间实现的。此外，在内核空间还为每一个内核支持线程设置了一个线程控制块，内核是根据该控制块而感知某线程的存在，并对其加以控制。

这种线程实现方式主要有如下四个优点：

(1) 在多处理器系统中，内核能够同时调度同一进程中多个线程并行执行；

(2) 如果进程中的一个线程被阻塞了，内核可以调度该进程中的其它线程占有处理器运行，也可以运行其它进程中的线程；

(3) 内核支持线程具有很小的数据结构和堆栈，线程的切换比较快，切换开销小； 

(4) 内核本身也可以采用多线程技术，可以提高系统的执行速度和效率。 

内核支持线程的主要缺点是：对于用户的线程切换而言，其模式切换的开销较大，在同一个进程中，从一个线程切换到另一个线程时，需要从用户态转到内核态进行，这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的，系统开销较大。

#### **用户级线程**

用户级线程 ULT(User Level Threads)仅存在于用户空间中。对于这种线程的创建、撤消、线程之间的同步与通信等功能，都无须利用系统调用来实现。对于用户级线程的切换，通常发生在一个应用进程的诸多线程之间，这时，也同样无须内核的支持。由于这些线程的任务控制块都是设置在用户空间，而线程所执行的操作也无须内核的帮助，因而内核完全不知道用户级线程的存在。

> 对于设置了用户级线程的系统，其调度仍是以进程为单位进行的。在采用轮转调度算法时，各个进程轮流执行一个时间片，这对诸进程而言似乎是公平的。但 假如在进程 A 中包含了一个用户级线程，而在另一个进程 B 中含有 100 个用户级线程，这样，进程 A 中线程的运行时间将是进程 B 中各线程运行时间的 100 倍；相应地，其速度要 快上 100 倍。如果设置的是内核支持线程，则调度以线程为单位，B两个进程获取的时间片是A的100倍，则两个进程运行速度差不多。

**优缺点**

(1) 线程切换不需要转换到内核空间，对一个进程而言，其所有线程的管理数据结构均在该进程的用户空间中，线程管理在用户态完成即可，节省了模式切换带来的消耗。 

(2) 用户级线程的实现与操作系统平台无关，因为对于线程管理的代码是在用户程序内的，属于用户程序的一部分，所有的应用程序都可以对之进行共享。因此，用户级线程甚至可以在不支持线程机制的操作系统平台上实现。 

用户级线程实现方式的主要缺点在于如下两个方面： 

(1) 系统调用的阻塞问题。在基于进程机制的操作系统中，大多数系统调用将阻塞进程，因此，当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的所有线程都会被阻 塞。而在内核支持线程方式中，则进程中的其它线程仍然可以运行。

> 内核线程则不会，因为他们是调度的单位，而用户线程，进程是调度基本单位。

**实现**

用户级线程是在用户空间实现的。所有的用户级线程都具有相同的结构，它们都运行在一个中间系统的上面。当前有两种方式实现的中间系统，即运行时系统和内核控制线程。

1) 运行时系统(Runtime System) 

所谓“运行时系统”，实质上是用于管理和控制线程的函数(过程)的集合，其中包括用于创建和撤消线程的函数、 线程同步和通信的函数以及实现线程调度的函数等。正因为有这些函数，才能使用户级线程与内核无关。运行时系统中的所有函数都驻留在用户空间，并作为用户级线程与内核之间的接口。

 2) 内核控制线程

这种线程又称为轻型进程 LWP(Light Weight Process)。每一个进程都可拥有多个 LWP，同用户级线程一样，每个 LWP 都有自己的数据结构(如 TCB)，其中包括线程标识符、优先级、状态，另外还有栈和局部存储区等。它们也可以共享进程所拥有的资源。LWP 可通过系统调用来获得内核提供的服务，这样，当一个用户级线程运行时，只要将它连接到一个LWP 上，此时它便具有了内核支持线程的所有属性。

在一个系统中的用户级线程数量可能很大，为了节省系统开销，不可能设置太多的LWP，而把这些 LWP 做成一个缓冲池，称为“线程池”。

![image-20201014201117233](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjp4ffged0j30hc08tq3q.jpg)

#### 用户级线程与内核控制线程的连接

在不同的操作系统中，实现用户级线程与内核控制线程的连接有三种不同的模型：一对一模型、多对一模型和多对多模型。 

1) 一对一模型

该模型是为每一个用户线程都设置一个内核控制线程与之连接，当一个线程阻塞时，允许调度另一个线程运行。在多处理机系统中，则有多个线程并行执行。该模型并行能力较强，但每创建一个用户线程相应地就需要创建一个内核线程，开销 较大，因此需要限制整个系统的线程数。

2) 多对一模型

该模型是将多个用户线程映射到一个内核控制线程，为了管理方便，这些用户线程一般属于一个进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完成。当用户线程需要访问内核时，才将其映射到一个内核控制线程上，但每次 只允许一个线程进行映射。 该模型的主要优点是线程管理的开销小，效率高，但当一个线程在访问内核时发生阻 塞，则整个进程都会被阻塞，而且在多处理机系统中，一个进程的多个线程无法实现并行。

3) 多对多模型

该模型结合上述两种模型的优点，将多个用户线程映射到多个内核控制线程，内核控 制线程的数目可以根据应用进程和系统的不同而变化，可以比用户线程少，也可以与之相同。

## 2.8 调度

在多道程序环境下，主存中有着多个进程，其数目往往多于处理机数目。这就要求系统能按某种算法，动态地把处理机分配给就绪队列中的一个进程，使之执行。分配处理机的任务是由处理机调度程序完成的。由于处理机是最重要的计算机资源，提高处理机的利用率及改善系统性能(吞吐量、响应时间)，在很大程度上取决于处理机调度性能的好坏，因而，处理机调度便成为操作系统设计的中心问题之一.

**进程调度和状态转换关系**<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvmnx5hrtj30xg0pegwo.jpg" alt="image-20201020111536419" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvmrbq3kjj30wi0qak2s.jpg" alt="image-20201020111853154" style="zoom:67%;" />

### 2.8.1 长程调度

根据某种算法，**==把外存上处于外存队列中的那些作业选中某个调入内存==**，也就是说，它的调度对象是存在于外存中的作业队列。这时候还没有创建进程，对应的状态转换是：new——Ready/Suspend Ready；发生在内外存之间。就是选择哪个程序进入内存以及有多少程序被调入内存（注意：调入内存的程序不一定是ready态，还要给其分配资源、创建pcb时才能成为ready）；

#### 1．作业和作业步

(1) 作业(Job)。作业是一个比程序更为广泛的概念，它不仅包含了通常的程序和数据， 而且还应配有一份作业说明书，系统根据该说明书来对程序的运行进行控制。在批处理系统中，是以作业为基本单位从外存调入内存的。

(2) 作业步(Job Step)。通常，在作业运行期间，每个作业都必须经过若干个相对独立， 又相互关联的顺序加工步骤才能得到结果，我们把其中的每一个加工步骤称为一个作业步， 各作业步之间存在着相互联系，往往是把上一个作业步的输出作为下一个作业步的输入。例如，一个典型的作业可分成三个作业步：① “编译”作业步，通过执行编译程序对源程序进行编译，产生若干个目标程序段；② “连结装配”作业步，将“编译”作业步所产生的若干个目标程序段装配成可执行的目标程序；③ “运行”作业步，将可执行的目标程序读入内存并控制其运行。

(3) 作业流。若干个作业进入系统后，被依次存放在外存上，这便形形成了输入的作业流；在操作系统的控制下，逐个作业进行处理，于是便形成了处理作业流。 

#### 2. 作业控制块 JCB(Job Control Block) 

同进程控制块PCB一样, 为作业设置了作业控制块用来管理作业, 它是作业在系统中存在的标志，其中保存了

系统对作业进行管理和调度所需的全部信息。在 JCB 中所包含的内容因系统而异，通常应包含的内容有：作业标识、用户名称、用户帐户、作业类型(CPU 繁忙型、I/O 繁忙型、批量型、终端型)、作业状态、调度信息(优先级、作业已运行时间)、资源需求(预计运行时间、 要求内存大小、要求 I/O 设备的类型和数量等)、进入系统时间、开始处理时间、作业完成 时间、作业退出时间、资源使用情况等。 每当作业进入系统时，系统便为每个作业建立一个 JCB，根据作业类型将它插入相应的后备队列中。

#### 3. 作业调度

作业调度的主要功能是根据作业控制块中的信息，==<u>审查系统能否满足用户作业的资源需求</u>==，以及按照一定的算法，==<u>从外存的后备队列中选取某些作业调入内存</u>==，并为它们创建进程、分配必要的资源。然后再将新创建的进程插入就绪队列，准备执行。因此，有时也 把作业调度称为接纳调度(Admission Scheduling)。

<!-- 作业调度也是根据系统资源,比如系统规定的最大程序并发数,来进行接纳调度,有点像swapping 把进程挂起-->

### 2.8.2 中程调度

引入中程调度的主要目的是**<u>为了提高内存利用率和系统吞吐量</u>**。为此，应使那些暂时不能运行的进程不再占用宝贵的内存资源，而将它们调至外存上去等待，把此时的进程状态称为就**<u>绪驻外存状态或挂起状态</u>**。当这些进程重又具备运行条件且内存又稍有空闲时，由中程调度来决定把外存上的那些又具备运行条件的就绪进程重新调入内存，并修改其状态为就绪状态，挂在就绪队列上等待进程调度。中程调度实际上就是存储器管理中的对换功能swapping，

**发生在内外存之间.** **对应的状态转换：Ready——Ready Suspend ；Block —— Block Suspend**

### 2.8.3 短程调度

它所调度的对象是进程(或内核级线程)。进程调度是最基本的一种调度； 对应的状态转换是：Ready——Running， **发生在内存内**

#### 1．短程调度的功能

低级调度用于决定就绪队列中的哪个进程(或内核级线程，为叙述方便，以后只写进程) 应获得处理机，然后再由分派程序执行把处理机分配给该进程的具体操作。

**低级调度的主要功能如下：**

(1) 保存处理机的现场信息。在进程调度进行调度时，首先需要保存当前进程的处理机的现场信息，如程序计数器、多个通用寄存器中的内容等，将它们送入该进程的进程控制块(PCB)中的相应单元。 

(2) 按某种算法选取进程。如优先数算法、轮转法、剩余时间法等，从就绪队列中选取一个进程，把它的状态改为运行状态，并准备把处理机分配给它。 

(3) 把处理器分配给进程。由分派程序(Dispatcher)把处理器分配给进程。此时需为选中的进程恢复处理机现场，即把选中进程的进程控制块内有关处理机现场的信息装入处理器相应的各个寄存器中，把处理器的控制权交给该进程，让它从取出的断点处开始继续运行.

#### 2．进程调度中的三个基本机制

为了实现进程调度，应具有如下三个基本机制：

(1) 排队器。为了提高进程调度的效率，先将所有的就绪进程按照一定的方式排成**<u>一个或多个队列</u>**，以便调度程序能最快地找到它。 

(2) 分派器(分派程序)。分派器把由进程调度程序所选定的进程，从就绪队列中取出该进程，然后进行上下文切换，将处理机分配给它。 

(3) 上下文切换机制。当对处理机进行切换时，会发生两对上下文切换操作。在第一对上下文切换时，操作系统将保存当前进程的上下文，而装入分派程序的上下文，以便分派程序运行；在第二对上下文切换时，将移出分派程序，而把新选进程的 CPU 现场信息装入 到处理机的各个相应寄存器中。

> 应当指出，上下文切换将花去不少的处理机时间，即使是现代计算机，每一次上下文切换大约需要花费几毫秒的时间，该时间大约可执行上千条指令。为此，现在已有通过硬 件(采用两组或多组寄存器)的方法来减少上下文切换的时间。一组寄存器供处理机在系统态时使用，另一组寄存器供应用程序使用。在这种条件下的上下文切换只需改变指针，使其 指向当前寄存器组即可。

#### 3．进程调度方式

进程调度可采用下述两种调度方式。

**1) 非抢占方式(Nonpreemptive Mode)** 

在采用这种调度方式时，一旦把处理机分配给某进程后，不管它要运行多长时间，都一直让它运行下去，决不会因为时钟中断等原因而抢占正在运行进程的处理机，也不允许其它进程抢占已经分配给它的处理机。直至该进程完成，自愿释放处理机，或发生某事件而被阻塞时，才再把处理机分配给其他进程。

在采用非抢占调度方式时，可能引起进程调度的因素可归结为如下几个： 

**(1)** 正在执行的进程执行完毕，或因发生某事件而不能再继续执行；

**(2)** 执行中的进程因提出 I/O 请求而暂停执行；

**(3)** 在进程通信或同步过程中执行了某种原语操作，如 P 操作(wait 操作)、Block 原语、 Wakeup 原语等。 



**2) 抢占方式(Preemptive Mode)** 

这种调度方式允许调度程序根据某种原则去暂停某个正在执行的进程，将已分配给该进程的处理机重新分配给另一进程。抢占方式的优点是，可以防止一个长进程长时间占用处理机，能为大多数进程提供更公平的服务，特别是能满足对响应时间有着较严格要求的 实时任务的需求。但抢占方式比非抢占方式调度所需付出的开销较大。抢占调度方式是基于一定原则的，

(1) 优先权原则。通常是对一些重要的和紧急的作业赋予较高的优先权。当这种作业到 达时，如果其优先权比正在执行进程的优先权高，便停止正在执行(当前)的进程，将处理机分配给优先权高的新到的进程，使之执行；或者说，允许优先权高的新到进程抢占当前进程的处理机。

(2) 短作业(进程)优先原则。当新到达的作业(进程)比正在执行的作业(进程)明显的短时，将暂停当前长作业(进程)的执行，将处理机分配给新到的短作业(进程)，使之优先执行；或者说，短作业(进程)可以抢占当前较长作业(进程)的处理机。

(3) 时间片原则。各进程按时间片轮流运行，当一个时间片用完后，便停止该进程的执行而重新进行调度。这种原则适用于分时系统、大多数的实时系统，以及要求较高的批处理系统。

#### 4 发生时机

时钟中断、IO中断、系统请求、信号发生

---

总结：

> 搞、中、低是以调度频率起名的, 进程最频繁、其次内存、最后作业. 而且他们面对的对象也不一样, 都是计算机中最重要的进程、内存、作业这样的对象.

在上述三种调度中，进程调度的运行频率最高，在分时系统中通常是 10～100 ms 便进行一次进程调度，因此把它称为短程调度。为避免进程调度占用太多的 CPU 时间，进程调度算法不宜太复杂。作业调度往往是发生在一个(批)作业运行完毕，退出系统，而需要重新调入一个(批)作业进入内存时，故作业调度的周期较长，大约几分钟一次，因此把它称为长程调度。由于其运行频率较低，故允许作业调度算法花费较多的时间。中级调度的运行频 率基本上介于上述两种调度之间，因此把它称为中程调度。

### 2.8.4 调度队列和准则

#### 1. 仅有进程调度的调度队列模型

在分时系统中，常把就绪进程组织成 FIFO 队列形式。每当 OS 创建一个新进程时，便将它挂 在就绪队列的末尾，然后按时间片轮转方式运行。

每个进程在执行时都可能出现以下三种情况： 

(1) 任务在给定的时间片内已经完成，该进程便在释放处理机后进入完成状态； 

(2) 任务在本次分得的时间片内尚未完成，OS 便将该任务再放入就绪队列的末尾； 

(3) 在执行期间，进程因为某事件而被阻塞后，被 OS 放入阻塞队列。

![image-20201016183355362](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd1yyrp0j30jy07fmxs.jpg)

#### 2．具有高级和低级调度的调度队列模型

在批处理系统中，不仅需要进程调度，而且还需有作业调度，由后者按一定的作业调度算法，从外存的后备队列中选择一批作业调入内存，并为它们建立进程，送入就绪队列，然 后才由进程调度按照一定的进程调度算法选择一个进程，把处理机分配给该进程。图 3-2 示 出了具有高、低两级调度的调度队列模型。该模型与上一模型的主要区别在于如下两个方面。

(1) 就绪队列的形式。在批处理系统中，最常用的是最高优先权优先调度算法，相应地， 最常用的就绪队列形式是优先权队列。进程在进入优先级队列时，根据其优先权的高低，被插入具有相应优先权的位置上，这样，调度程序总是把处理机分配给就绪队列中的队首进程。

![image-20201016183601081](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd1wqlwwj30oy0bjdgv.jpg)

(2) 设置多个阻塞队列。对于小型系统，可以只设置一个阻塞队列；但当系统较大时， 若仍只有一个阻塞队列，其长度必然会很长，队列中的进程数可以达到数百个，这将严重影响对阻塞队列操作的效率。故在大、中型系统中通常都设置了若干个阻塞队列，每个队 列对应于某一种进程阻塞事件。 

#### 3．同时具有三级调度的调度队列模型

在 OS 中引入中级调度后，人们可把进程的就绪状态分为内存就绪(表示进程在内存中就绪)和外存就绪(进程在外存中就绪)。类似地，也可把阻塞状态进一步分成内存阻塞和外存阻塞两种状态。在调出操作的作用下，可使进程状态由内存就绪转为外存就绪，由内 存阻塞转为外存阻塞；在中级调度的作用下，又可使外存就绪转为内存就绪.

![image-20201016183747798](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd2gmsp5j30nh0cqt9x.jpg)

#### 4. 调度算法选择准则

在一个操作系统的设计中，应如何选择调度方式和算法，在很大程度上取决于操作系统的类型及其目标。选择调度方式和算法的准则，有的是面向用户的，有的是面向系统的。

##### 面向用户

(1) 周转时间短: 通常把周转时间的长短作为评价批处理系统的性能、选择作业调度方式与算法的重要准则之一。所谓周转时间，是指从作业被提交给系统开始，到作业完成为 止的这段时间间隔(称为作业周转时间)。

(2) 响应时间快: 是选择分时系统中进程调度算法的重要准则之一。所谓响应时间，是从用户通过键盘提交一个请求开始，直至系统首次产生响应为止的时间

(3) 截止时间的保证。这是评价实时系统性能的重要指标，因而是选择实时调度算法的重要准则。

(4) 优先权准则。在批处理、分时和实时系统中选择调度算法时，都可遵循优先权准则，以便让某些紧急的作业能得到及时处理。

##### 面向系统的准则

(1) 系统吞吐量高: 指在单位时间内系统所完成的作业数

(2) 处理机利用率好: 因为cpu资源很宝贵, 要多利用cpu资源,尽量不让其空闲, 

(3) 各类资源的平衡利用: 在大、中型系统中，不仅要使处理机的利用率高，而且还应 能有效地利用其它各类资源，如内存、外存和 I/O 设备等。选择适当的调度方式和算法可以 保持系统中各类资源都处于忙碌状态。但对于微型机和某些实时系统而言，该准则并不重要。

### 2.8.5 调度算法

调度的实质是一种资源分配，因而调度算法是指：根据系统的资源分配策略所 规定的资源分配算法。对于不同的系统和系统目标，通常采用不同的调度算法。

#### 1 先来先服务 FCFS 和 短作业(进程)优先调度算法

##### 先来先服务 FCFS —— first come first server

先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也 可用于进程调度。FCFS 算法比较有利于长作业(进程)，而不利于短作业(进程)。FCFS 调度算法有利于 CPU 繁忙型的作业，而 不利于 I/O 繁忙型的作业(进程)。CPU 繁忙型作业是指该类作业需要大量的 CPU 时间进行 计算，而很少请求 I/O。通常的科学计算便属于 CPU 繁忙型作业。I/O 繁忙型作业是指 CPU 进行处理时需频繁地请求 I/O。目前的大多数事务处理都属于 I/O 繁忙型作业。

> 当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一 个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放 入就绪队列。在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进 入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件 而阻塞后才放弃处理机。
>
> 后面的调度算法，都可以参考这个定义来去看，比如短作业调度

##### 短作业(进程)优先调度算法 SJF——short job first

短作业(进程)优先调度算法 SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以 分别用于作业调度和进程调度。

SJ(P)F 调度算法也存在不容忽视的缺点：

(1) 该算法对长作业不利，更严重的是，如果有一长作业(进程)进入系统的后备队列(就绪队列)，由于调度程序 总是优先调度那些(即使是后进来的)短作业(进程)，将导致长作业(进程)长期不被调度。

(2) 该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业(进程)会被及时处理。

(3) 由于作业(进程)的长短只是根据用户所提供的估计执行时间而定的，而用户又可能 会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先 调度。

#### 2 高优先权调度

##### a 优先权调度算法的类型

根据进程、作业的优先级按顺序调度。算法分成如下两种：

1) 非抢占式优先权算法

系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便 一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机 重新分配给另一优先权最高的进程。用于批处理系统，或实时性不严的情况；

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执 行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原 优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。用于要求严格的实时系统；

##### b 优先权类型

对于最高优先权优先调度算法，其关键在于：它是使用静态优先权，还是用动态优先 权，以及如何确定进程的优先权。

- 静态：静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。
- 动态：动态优先权是指在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间 的增加而改变的，以便获得更好的调度性能。例如，我们可以规定，在就绪队列中的进程， 随其等待时间的增长，其优先权以速率 a 提高。

##### C 高响应比优先调度算法

在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业 的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先 级随着等待时间的增加而以速率 a 提高，则长作业在等待一定的时间后，必然有机会分配 到处理机。该优先权的变化规律可描述为：

![image-20201020104024760](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvlnaiouij30ax01yjrf.jpg)

#### 3 基于时间片的轮转调度算法

##### 1．时间片轮转法

1) 基本原理

在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列， 每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到 几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号 来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中 新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一 给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应 所有用户的请求。

2) 时间片大小的确定

在时间片轮转算法中，时间片的大小对系统性能有很大的影响，如选择很小的时间片 将有利于短作业，因为它能较快地完成，但会频繁地发生中断、进程上下文的切换，从而 增加系统的开销；反之，如选择太长的时间片，使得每个进程都能在一个时间片内完成， 时间片轮转算法便退化为 FCFS 算法，无法满足交互式用户的需求。一个较为可取的大小是， 时间片略大于一次典型的交互所需要的时间。这样可使大多数进程在一个时间片内完成。

##### 2. 多级反馈队列调度

**多级反馈 = FCFS + 多级就绪队列（每个队列的时间片时间不一样，依次递增；优先级依次降低）**

应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高， 第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片 的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例 如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第 i+1 个队列的时间片要 比第 i 个队列的时间片长一倍。

![image-20201020104833949](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvlvrwz0wj30f007z0tb.jpg)

当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待 调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一 个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第 三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第 n 队列后，在第 n 队列中便采取按时间片轮转的方式运行。

仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1)队 列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时， 又有新进程进入优先权较高的队列(第 1～(i-1)中的任何一个队列)，则此时新进程将抢占正 在运行进程的处理机，即由调度程序把正在运行的进程放回到第 i 队列的末尾，把处理机分 配给新到的高优先权进程。

### 2.8.6  实时调度

可以按不同方式对实时调度算法加以分类

- 根据实时任务（截止时间）性质的不同，
  - 硬实时调度算法：必须满足；
  - 软实时调度算法：尽最大努力；
- 周期性
  - 周期和非周期（非周期连着一个deadline）
- 按调度方式的不同，又可分为非抢占调度算法和抢占调度算法； 还可因调度程序调度时间的不同而分成静态调度算法和动态调 度算法，前者是指在进程执行前，调度程序便已经决定了各进程间的执行顺序，而后者则 是在进程的执行过程中，由调度程序届时根据情况临时决定将哪一进程投入运行。



## 2.9 死锁

### 2.9.1 相关概念

产生死锁的原因可归纳为：

(1) 竞争资源。当系统中供多个进程共享的资源如打印机、公用队列等，其数目不足以 满足诸进程的需要时，会引起诸进程对资源的竞争而产生死锁。

(2) 进程间推进顺序非法。进程在运行过程中，请求和释放资源的顺序不当，也同样会 导致产生进程死锁。

#### 定义

一组进（线）程中的每一个进（线）程都在等待仅由该组进（线）程中其他进（线）程才能引发的事件，那么该组进（线）程是死锁的Deadlock

#### 必要条件

虽然进程在运行过程中可能发生死锁，但死锁的发生也必须具备一定的条件。综上所 述不难看出，死锁的发生必须具备下列四个必要条件。

(1) 互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由 一个进程占用。如果此时还有其它进程请求该资源，则请求者只能等待，直至占有该资源 的进程用毕释放。

(2) 请求和保持条件：指进程已经保持了至少一个资源，但又提出了新的资源请求，而 该资源又已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。**这句话的对立含义：一次性把所有临界资源都分配该进程**

(3) 不剥夺条件（不可占用）：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完 时由自己释放。

(4) 环路等待条件：资源闭环，指在发生死锁时，必然存在一个进程——资源的环形链，即进程集 合{P0 ，P1 ，P2 ，…，Pn }中的 P 0 正在等待一个 P 1 占用的资源；P 1 正在等待 P 2 占用的资源，……， P n 正在等待已被 P 0 占用的资源。

总结一下：就是两点

- 资源具备不可占用性，且互斥；
- 进程之间占用的资源信号量循环等待；

#### 处理死锁方法

1 预防死锁：预先防止产生死锁。该方法是通过设置某些限制 条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来预防发生死锁。

2 避免死锁：该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施 去破坏产生死锁的四个必要条件，而是在资源的动态分配过程中，用某种方法去防止系统 进入不安全状态，从而避免发生死锁。

3 检测死锁：这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进 入不安全区，而是允许系统在运行过程中发生死锁。但可通过系统所设置的检测机构，及 时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源；

4 解除死锁。这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须 将进程从死锁状态中解脱出来。常用的实施方法是撤消或挂起一些进程，以便回收一些资 源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。

后面就围绕这几方面去讨论，预防、避免、检测、解除四个方面。

### 2.9.2 预防死锁

预防死锁的方法是使四个必要条件中的第 2、3、4 个条件之一不能成立，来避免发生 死锁。至于必要条件 1，因为它是由设备的固有特性所决定的，用户无法改变。

#### 破坏“请求和保持”

一次性把进程所需的所有临界资源都分配给他，或者说把进程运行初期所需的资源分配给他。这两种方式都是破坏 “请求和保持” ，第二种方式所需的代价比较小，因为进程涉及到很多的临界资源时，要想把所有的临界资源都准备好，代价太大，同样也存在资源的浪费，效率不高

#### 破坏“不可抢占”

就是允许某个进程P占用了某个临界资源R时，当有一个更高级的进程P1过来时，允许P1获取R资源的使用权，P进程释放该资源的使用权。这种方式的代价就是假如某个进程P已经完成了大部分工作，这时要求其释放资源，暂停工作，可能下次又要花费较长时间去运行之前已经完成的工作，这对于P进程存在反反复复的做某个进程中的部分工作，但却无法完成整个工作。

#### 破坏“循环等待”

这种方法中规定，系统将所有资源按类型进行线性排队，并赋予不同的序号。例如， 令输入机的序号为 1，打印机的序号为 2，磁带机为 3，磁盘为 4。**所有进程对资源的请求 必须严格按照资源序号递增的次序提出，这样，在所形成的资源分配图中，不可能再出现 环路**，因而摒弃了“环路等待”条件。事实上，在采用这种策略时，总有一个进程占据了 较高序号的资源，此后它继续申请的资源必然是空闲的，因而进程可以一直向前推进。

但也存在下述严重问题：某进程先用磁带机，后用打印机，但按系统规定，该进 程应先申请打印机而后申请磁带机，致使先获得的打印机被长时间闲置

### 2.9.3 避免死锁

在预防死锁的几种方法中，都施加了较强的限制条件；避免死锁也是预先预防的策略，并不是实现采取某种限制错死，而是在资源动态分配中，防止系统进入不安全状态来避免死锁。

#### 系统安全状态

在避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给 进程；否则，令进程等待。

虽然并非所有的不安全状态都必然会转为死锁状态，但当系统进入不安全状态后，便 有可能进而进入死锁状态；反之，只要系统处于安全状态，系统便可避免进入死锁状态。 因此，避免死锁的实质在于：系统在进行资源分配时，如何使系统不进入不安全状态。

> 例子：。假定系统中有三个进程 P1、P 2和 P3，共有 12 台磁带 机。进程 P 1 总共要求 10 台磁带机，P 2 和 P 3 分别要求 4 台和 9 台。假设在 T 0 时刻，进程 P1 、 P 2 和 P 3 已分别获得 5 台、2 台和 2 台磁带机，尚有 3 台空闲未分配，如下表所示：
>
> | 进程 | 最大需求 | 已 分 配 | 可用 |
> | ---- | -------- | -------- | ---- |
> | P1   | 10       | 5        | 3    |
> | P2   | 4        | 2        |      |
> | P3   | 9        | 2        |      |
>
> 分析发现，在 T 0时刻系统是安全的，因为这时存在一个安全序列〈P2，P1，P3〉，即 只要系统按此进程序列分配资源，就能使每个进程都顺利完成。例如，将剩余的磁带机取 2 台分配给 P2 ，使之继续运行，待 P 2 完成，便可释放出 4 台磁带机，于是可用资源增至 5 台； 以后再将这些全部分配给进程 P1 ，使之运行，待 P 1 完成后，将释放出 10 台磁带机，P 3 便 能获得足够的资源，从而使 P1 、P2 、P 3 每个进程都能顺利完成。

#### 系统不安全状态

如果不按照安全序列分配资源，则系统可能会由安全状态进入不安全状态。例如，在 T 0 时刻以后，P 3 又请求 1 台磁带机，若此时系统把剩余 3 台中的 1 台分配给 P3 ，则系统便 进入不安全状态。因为此时也无法再找到一个安全序列，例如，把其余的 2 台分配给 P2 ， 这样，在 P 2 完成后只能释放出 4 台，既不能满足 P 1 尚需 5 台的要求，也不能满足 P 3 尚需 6 台的要求，致使它们都无法推进到完成，彼此都在等待对方释放资源，即陷入僵局，结果 导致死锁。

#### 银行家算法

四个矩阵：

当前最大资源可用数目的矩阵Available Matrix ：

当前进程所需最大资源数目Max Matrix ：

当前进程已经分配的资源数目矩阵 Allocation Matrix

当前进程还需资源的数目矩阵Need Matrix

其中：Need = Max - Allocation，然后把当前进程申请的资源数目reqeust 和need 、available 相比，要小于他们才行。然后尝试着进行资源分配，再次计算上面四个矩阵值，然后看是否满足安全算法不。这个算法就是当把某个进程分配某个临界资源后，便计算其他进程所需的资源request 是否小于 Available ，当所有进程满足时，就是系统安全状态，然后才真正的分配，否则收回之前的试探分配。



### 2.9.4 解除死锁

#### 死锁检测

资源分配图

死锁定理

死锁检测数据结构



#### 锁锁解除

当发现有进程死锁时，便应立即把它们从死锁状态中解脱出来。常采用解除死锁的两 种方法是：

(1) 剥夺资源。从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态。

(2) 撤消进程。最简单的撤消进程的方法是使全部死锁进程都夭折掉；稍微温和一点的 方法是按照某种顺序逐个地撤消进程，直至有足够的资源可用，使死锁状态消除为止。



# 第三章 存储管理

这一章节讲的是计算机存储。主要有三部分内容，计算机存储相关概念，简单存储、虚拟存储。

## 3.1 存储相关概念

学校目标：

- 明白相关概念：重定位、逻辑/物理地址

现代计算机系统中，存储部件 通常是采用层次结构来组织的。存储层次至少应具有三级：最高层为 CPU 寄存器，中间为主存， 最底层是辅存。还可以根据具体的功能分工细划为

- 寄存器——cpu寄存器
- 高速缓 存、主存储器、磁盘缓存——主存
- 固定磁盘、可移动存储 —— 辅存

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk1qc7yf6pj30q80dwmys.jpg" alt="image-20201025175606974" style="zoom:80%;" />

对于不同层次的存储介质，由操作系统进行统一管理。操作系统的存储管理，负责对可执行存储器（寄存器和主存储器被称为可执行存储器）的分配、回收以及提供在存储层次间数据移动的管理机制，例如主存与磁盘 缓存、高速缓存与主存间的数据移动等。在设备和文件管理中，根据用户的需求提供对辅 存的管理机制。

### 3.1.1 主存储器与寄存器

#### 1. 主存储器

也称可执行存储器，为数十 MB 到数 GB。

作用：

cpu从主存储器读取数据，在把数据放入寄存存储器；或者从寄存器存入到主存储器

#### 2 寄存器

寄存器的长度一般以字(word)为单位，寄存器访问速度最快，完全能与 CPU 协调工作。寄存器 用于加速存储器的访问速度，如用寄存器存放操作数，或用作地址寄存器加快地址转换速 度等。

> 一个文件的数据可能出现在存储器层次的不同级别中，例如，一个文件数据通常被存 储在辅存中(如硬盘)，当其需要运行或被访问时，就必须调入主存，也可以暂时存放在主存 的磁盘高速缓存中。大容量的辅存常常使用磁盘，磁盘数据经常备份到磁带或可移动磁盘 组上，以防止硬盘故障时丢失数据。

注意：断电后，只有辅存中的数据还在，主存和寄存器中的数据都会丢失掉。

### 3.1.2 高速缓存和磁盘缓存

#### 高速缓存

其容量大于或远大于寄存器，而比内 存约小两到三个数量级左右，从几十 KB 到几 MB，访问速度快于主存储器。

作用：将主存中一些经常访问的信息存放在高速缓存中，减少访 问主存储器的次数，可大幅度提高程序执行速度。

> 通常，进程的程序和数据是存放在主存 储器中，每当使用时，被临时复制到一个速度较快的高速缓存中。当 CPU 访问一组特定信 息时，首先检查它是否在高速缓存中，如果已存在，可直接从中取出使用，以避免访问主 存，否则，再从主存中读出信息。如大多数计算机有指令高速缓存，用来暂存下一条欲执 行的指令，如果没有指令高速缓存，CPU 将会空等若干个周期，直到下一条指令从主存中 取出。现在也有很多级高速缓存。

#### 磁盘缓存

磁盘的 I/O 速度远低于对主存的访问速度，因此将频繁使用的一部分磁盘数据 和信息，暂时存放在磁盘缓存中，可减少访问磁盘的次数。其设计目的和高速缓存一样，加速对硬盘的访问速度。

## 3.2 程序链接

要程序运行，必须先为之创建进程。而创建进程的第一件事， 便是将程序和数据装入内存。如何将一个用户源程序变为一个可在内存中执行的程序，通 常都要经过以下几个步骤：首先是要编译，由编译程序(Compiler)将用户源代码编译成若干个目标模块(Object Module)；其次是链接，由链接程序(Linker)将编译后形成的一组目标模块(Load Module)；最后 是装入，由装入程序(Loader)将模块装入内存。

现在讨论一下链接：通常有下面链接方式 静态链接、装入时链接、运行时动态链接；

### 静态链接

在编译时，如果知道程序将驻留在内存的什么位置，那么，编译程序将产生绝对地址 的目标代码。例如，事先已知用户程序(进程)驻留在从 R 处开始的位置，则编译程序所产生 的目标模块(即装入模块)便从 R 处开始向上扩展。绝对装入程序按照装入模块中的地址，将 程序和数据装入内存。装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址完 全相同，故不须对程序和数据的地址进行修改。

程序中所使用的绝对地址，既可在编译或汇编时给出，也可由程序员直接赋予。但在 由程序员直接给出绝对地址时，不仅要求程序员熟悉内存的使用情况，而且一旦程序或数 据被修改后，可能要改变程序中的所有地址。因此，通常是宁可在程序中采用符号地址， 然后在编译或汇编时，再将这些符号地址转换为绝对地址。方式只适用于单道程序环境，多道程序运行时，可能会出现程序交换或者并发等情况，不能采用此方式。

### 装入时链接

在多道程序环境下，所得到的目标模块的起始地址通常是从 0 开始的，程序 中的其它地址也都是相对于起始地址计算的。此时应采用可重定位装入方式，根据内存的 当前情况，将装入模块装入到内存的适当位置。通常是把在装入时对目标 程序中指令和数据的修改过程称为重定位。又因为地址变换通常是在装入时一次完成的， 以后不再改变，故称为静态重定位。

### 运行时动态链接

这是指对某些目标模块的链接，是在程序执行中需要该(目标)模 块时，才对它进行的链接。

在许多情况下，应用程序在运行时，每次要运行的模块可能是不相同的。但由于事先 无法知道本次要运行哪些模块，故只能是将所有可能要运行到的模块都全部装入内存，并 在装入时全部链接在一起。显然这是低效的，因为往往会有些目标模块根本就不运行。比 较典型的例子是作为错误处理用的目标模块，如果程序在整个运行过程中都不出现错误， 则显然就不会用到该模块。 

近几年流行起来的运行时动态链接方式，是对上述在装入时链接方式的一种改进。这 种链接方式是将对某些模块的链接推迟到程序执行时才进行链接，亦即，在执行过程中， 当发现一个被调用模块尚未装入内存时，立即由 OS 去找到该模块并将之装入内存，把它链 接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到 装入模块上，这样不仅可加快程序的装入过程，而且可节省大量的内存空间。

## 3.3 连续分配存储

### 3.1.1 连续分区

把内存分为系统区和用户区两部分，系统区仅提供给 OS 使用，通常 是放在内存的低址部分；用户区是指除系统区以外的全部内存空间，提供给用户使用。

适用：一种存储管理方式，但只能用于单用户、单任务的操作系统中。

### 3.1.2 固定分区

此种分配方式把内存空间分为固定大小的区域，每个分区允许一个作业被装入。分区大小可以不相同。通常会建立一张分区使用表来记录每个分区的起始地址、分区大小、状态。没有足够大的分区则拒绝分配内存。此种分配方式是最早的多道程序的存储管理方式。

缺点：限制了进程的数目，内存空间利用率比较低。比如说只有4个分区，则只能允许最多四个程序运行。其他的程序必须等待其中的一个运行完后才能运行。

### 3.1.3 动态分区

动态分区分配是根据进程的实际需要，动态地为之分配内存空间。在实现可变分区分 配时，将涉及到分区分配中所用的数据结构、分区分配算法和分区的分配与回收操作这样 三个问题。因为是动态的，必须要有相关的数据结构描述对象，相应的算法，已经涉及到的相关问题。这个动态可类比固定分区，解决了进程最大运行数目问题。

#### 数据结构

#### 分配算法

##### 基于顺序搜索的动态分区分配算法

**首次适应**

要求空闲分区链以 地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要 求的空闲分区为止；然后再按照作业的大小，从该分区中划出一块内存空间分配给请求者， 余下的空闲分区仍留在空闲链中。若从链首直至链尾都不能找到一个能满足要求的分区， 则此次内存分配失败，返回

**循环首次适应算法**

在首次适应算法上，不在从开始查找。从上次找到的空闲分区下一个分区开始查找。

**最佳适应算法**

指每次为作业分配内存时，总是把能满足要求的最小的内存分区分配给作业，避免“大材小用”。

**最坏适应算法**

 选择最大的空闲分区，然后进行分配 

##### 基于索引搜索的动态分区分配算法

**快速适应算法**

也叫分类搜索算法，采取分区表加上相同类别管理的链表进行记录，仅需根据进程的长度，即可分配相应的内存空间。就是把内存剩余空间的大小进行分类，再去匹配进程需求。

**伙伴系统**

**哈希算法**

#### 内存回收

### 3.1.4 动态可重定位分区

此种算法考虑到的情况是：有很多内存碎片。对于一个进程来说，没有任何一个碎片能够满足进程所需的容量要求，但是碎片的容量总和能够满足一个或者多个进程的容量要求。

解决方案：①把内存中的所有作业全部移动，让他们紧凑在一起，这样内存碎片便集中在一起了。（需要对移动的程序地址进行修改才行）

分区分配算法：与动态分区分配算法类似，不过多了“紧凑”的操作。

### 3.1.5 对换swapping

将占用内存却没有干什么事情的进程给放到外存。这样来提升内存的使用效率。

#### 引入背景

在多道程序环境下，一方面，在内存中的某些进程由于某事件尚未发生而被阻塞运行， 但它却占用了大量的内存空间，甚至有时可能出现在内存中所有进程都被阻塞而迫使 CPU 停止下来等待的情况；另一方面，却又有着许多作业在外存上等待，因无内存而不能进入 内存运行的情况。显然这对系统资源是一种严重的浪费，且使系统吞吐量下降。为了解决 这一问题，在系统中又增设了对换(也称交换)设施。

在具有对换功能的 OS 中，通常把外存分为文件区和对换区。前者用于存放文件，后者 用于存放从内存换出的进程。

换入：每当一进程由于创建子进程而需要更多的内存空间，但又无足够的内 存空间等情况发生时，系统应将某进程换出。其过程是：系统首先选择处于阻塞状态且优 先级最低的进程作为换出进程，然后启动磁盘，将该进程的程序和数据传送到磁盘的对换 区上。若传送过程未出现错误，便可回收该进程所占用的内存空间，并对该进程的进程控 制块做相应的修改。

换出：系统应定时地查看所有进程的状态，从中找出“就绪”状态但已换出 的进程，将其中换出时间最久(换出到磁盘上)的进程作为换入进程

## 3.4 分页、分段离散存储管理内存

分区是连续分配内存管理方法，分页和分段都是离散方式来管理内存的，根据离散分配的基本单位是不同，可以有以下几种方式：

- 分页存储管理方式：用户程序地址分为若干大小固定的区域，称为“页”
- 分段存储管理：把用户程序的地址空间分为若干个大小不同的段，每段可定义一组相对完整的信息。
- 页段式存储管理：把上述两种方式结合一起。

> 内存的分段和分页管理方式和由此衍生的一堆段页式等都属于内存的**不连续分配**。什么叫不连续分配？就是把程序分割成一块一块的装入内存，在物理上不用彼此相连，在逻辑上使用段表或者页表将离散分布的这些小块串起来形成逻辑上连续的程序。

比如说分段就是将一个程序分成代码段，数据段，堆栈段什么的。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk59qw73ddj30iw0fbq5s.jpg" alt="image-20201028192417262" style="zoom:67%;" />

分页就是将这些段，例如代码段分成均匀的小块，然后这些给这些小块编号，然后就可以放到内存中去，由于编号了的，所以也不怕顺序乱

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk59rl3x7nj30k00eu0t1.jpg" alt="img" style="zoom:67%;" />

然后我们就能通过段号，页号，页内偏移找到程序的地址

![img](https://tva1.sinaimg.cn/large/0081Kckwgy1gk59se15qej30k006kt8q.jpg)

分页、分段、加上对换swapping、以及程序的局部运行的想象奠定了虚拟内存技术。

### 分页的基本概念

1．页面

1) 页面和物理块

分页存储管理是将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页， 并为各页加以编号，从 0 开始，如第 0 页、第 1 页等。相应地，也把内存空间分成与页面 相同大小的若干个存储块，称为(物理)块或页框(frame)，也同样为它们加以编号，如 0# 块、 1# 块等等。在为进程分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相 邻接的物理块中。由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为 “页内碎片”。

2) 页面大小

在分页系统中的页面其大小应适中。页面若太小，一方面虽然可使内存碎片减小，从 而减少了内存碎片的总空间，有利于提高内存利用率，但另一方面也会使每个进程占用较 多的页面，从而导致进程的页表过长，占用大量内存；此外，还会降低页面换进换出的效 率。然而，如果选择的页面较大，虽然可以减少页表的长度，提高页面换进换出的速度， 但却又会使页内碎片增大。因此，页面的大小应选择适中，且页面大小应是 2 的幂，通常 为 512 B～8 KB。

2 页表

在分页系统中，允许将进程的各个页离散地存储在内存不同的物理块中，但系统应能 保证进程的正确运行，即能在内存中找到每个页面所对应的物理块。为此，系统又为每个 进程建立了一张页面映像表，简称页表。在进程地址空间内的所有页(0～n)，依次在页表中 有一页表项，其中记录了相应页在内存中对应的物理块号，在配置 了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表 的作用是实现从页号到物理块号的地址映射。

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk5a0m7f7wj30c508emxl.jpg" alt="image-20201028193340684" style="zoom:80%;" />

3 抵制转换机构

为了能将用户地址空间中的逻辑地址变换为内存空间中的物理地址，在系统中必须设 置地址变换机构——页表寄存器。

### 分段存储

#### 分段的引入

1) 方便编程

通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从 0 开始编址， 并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名(段号)和段内偏移量(段内 地址)决定的。

2) 信息共享

在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，共享某个例程 和函数。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的意义，不便于实现 共享；然而段却是信息的逻辑单位。由此可知，为了实现段的共享，希望存储管理能与用 户程序分段的组织方式相适应。

3) 信息保护

信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地 实现信息保护功能。

4) 动态增长

在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又 无法确切地知道数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动 态增长的情况，而分段存储管理方式却能较好地解决这一问题。

5) 动态链接

动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主 程序所对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段(目 标程序)调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。

#### 基本原理

##### 1 分段

在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑 信息。例如，有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等，如图 4-17 所示。每 个段都有自己的名字。为了实现简单起见，通常可用一个段号来代替段名，每个段都从 0 开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因而 各段长度不等。整个作业的地址空间由于是分成多个段，因而是二维的，亦即，其逻辑地 址由段号(段名)和段内地址所组成。 分段地址中的地址具有如下结构：

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk5abiwx02j30di035jrc.jpg" alt="image-20201028194410013" style="zoom:80%;" />

##### 2 段表

同页表的作用一样。实现从逻辑段到物理内存区的映射

##### 3 地址变换机构

为了实现从进程的逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用 于存放段表始址和段表长度 TL。

### 分段和分页区别

分页和分段系统有许多相似之处。比如，两者都采用离散分配方 式，且都要通过地址映射机构来实现地址变换。但在概念上两者完全不同，主要表现在下 述三个方面。

(1) 页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内 存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的 逻辑单位， 它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的 需要。

(2) 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是 由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度却不固定，决定于 用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。

(3) 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆 符，即可表示一个地址；而分段的作业地址空间则是二维的，程序员在标识一个地址时， 既需给出段名，又需给出段内地址。

## 3.5 虚拟存储器

前面所介绍的各种存储器管理方式有一个共同的特点，即它们都要求将一个作业全部 装入内存后方能运行，于是，出现了下面这样两种情况：

(1) 有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部被装入内存， 致使该作业无法运行。

(2) 有大量作业要求运行，但由于内存容量不足以容纳所有这些作业，只能将少数作业 装入内存让它们先运行，而将其它大量的作业留在外存上等待。 出现上述两种情况的原因，都是由于内存容量不够大。一个显而易见的解决方法，是 从物理上增加内存容量，但这往往会受到机器自身的限制，而且无疑要增加系统成本，因 此这种方法是受到一定限制的。另一种方法是从逻辑上扩充内存容量，这正是虚拟存储技 术所要解决的主要问题。

因为上面虽然采取了离散存储方式，但不能解决有的作业大要求的内存多（超出了物理内存大小），无法去运行这样的作业。这样就引入了虚拟存储，增加逻辑内存大小。如何做到呢？

### 虚拟存储器引入

1．**常规存储器管理方式的特征**

(1) 一次性。在前面所介绍的几种存储管理方式中，都要求将作业全部装入内存后方能 运行，即作业在运行前需一次性地全部装入内存，而正是这一特征导致了上述两种情况的 发生。

(2) 驻留性。作业装入内存后，便一直驻留在内存中，直至作业运行结束。尽管运行中 的进程会因 I/O 而长期等待，或有的程序模块在运行过一次后就不再需要(运行)了，但它们 都仍将继续占用宝贵的内存资源。 由此可以看出，上述的一次性及驻留性，使许多在程序运行中不用或暂不用的程序(数 据)占据了大量的内存空间，使得一些需要运行的作业无法装入运行。现在要研究的问题是： 一次性及驻留性在程序运行时是否是必需的。

2．**程序运行局部性原理**

程序在执行时将呈现出局部性规律，即在一较短 的时间内，程序的执行仅局限于某个部分；相应地，它所访问的存储空间也局限于某个区 域。关于这个可以去了解更多，知道有这个特性就行了。

3．**虚拟存储器的定义** 

基于局部性原理，应用程序在运行之前，没有必要全部装入内存，仅须将那些当前要 运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。程序在运行时，如果它 所要访问的页(段)已调入内存，便可继续执行下去；但如果程序所要访问的页(段)尚未调入 内存(称为缺页或缺段)，此时程序应利用 OS 所提供的请求调页(段)功能，将它们调入内存， 以使进程能继续执行下去。如果此时内存已满，无法再装入新的页(段)，则还须再利用页(段)的置换功能，将内存中暂时不用的页(段)调至盘上，腾出足够的内存空间后，再将要访问的 页(段)调入内存，使程序继续执行下去。这样，便可使一个大的用户程序能在较小的内存空 间中运行；也可在内存中同时装入更多的进程使它们并发执行。从用户角度看，该系统所 具有的内存容量，将比实际内存容量大得多。但须说明，用户所看到的大容量只是一种感 觉，是虚的，故人们把这样的存储器称为虚拟存储器。

**所谓虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑 上对内存容量加以扩充的一种存储器系统。其逻辑容量由内存容量和外存容量之和所决定， 其运行速度接近于内存速度，而每位的成本却又接近于外存。**

### 虚拟存储器的特征

1．多次性 多次性是指一个作业被分成多次调入内存运行，亦即在作业运行时没有必要将其全部装 入，只需将当前要运行的那部分程序和数据装入内存即可；以后每当要运行到尚未调入的那 部分程序时，再将它调入。多次性是虚拟存储器最重要的特征，任何其它的存储管理方式都 不具有这一特征。因此，我们也可以认为虚拟存储器是具有多次性特征的存储器系统。

2．对换性

对换性是指允许在作业的运行过程中进行换进、换出，亦即，在进程运行期间，允许 将那些暂不使用的程序和数据，从内存调至外存的对换区(换出)，待以后需要时再将它们从 外存调至内存(换进)；甚至还允许将暂时不运行的进程调至外存，待它们重又具备运行条件 时再调入内存。换进和换出能有效地提高内存利用率。可见，虚拟存储器具有对换性特征。

3．虚拟性

虚拟性是指能够从逻辑上扩充内存容量，使用户所看到的内存容量远大于实际内存容 量。这是虚拟存储器所表现出来的最重要的特征，也是实现虚拟存储器的最重要的目标。

**虚拟性是以多次性和对换性为基础的，而多次性和对换性又是以离散存储为基础。**

## 3.6 请求分页存储管理

请求分页系统是建立在基本分页基础（这就是3.4中讲的分页离散存储）上的，为了能支持虚拟存储器功能而增加了请求 调页功能和页面置换功能。相应地，每次调入和换出的基本单位都是长度固定的页面，这 使得请求分页系统在实现上要比请求分段系统简单(后者在换进和换出时是可变长度的段)。 因此，请求分页便成为目前最常用的一种实现虚拟存储器的方式。

### 3.6.1 硬件支持

为了实现请求分页，系统必须提供一定的硬件支持。除了需要一台具有一定容量的内 存及外存的计算机系统外，还需要有页表机制、缺页中断机构以及地址变换机构。

#### 1．页表机制 

在请求分页系统中所需要的主要数据结构是页表。其基本作用仍然是将用户地址空间中的逻辑地址变换为内存空间中的物理地址。由于只将应用程序的一部分调入内存，还有 一部分仍在盘上，故须在页表中再增加若干项，供程序(数据)在换进、换出时参考。

#### 2．缺页中断机构

在请求分页系统中，每当所要访问的页面不在内存时，便产生一缺页中断，请求 OS 将 所缺之页调入内存。缺页中断作为中断，它们同样需要经历诸如保护 CPU 环境、分析中断 原因、转入缺页中断处理程序进行处理、恢复 CPU 环境等几个步骤。

#### 3．地址变换机构

 请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，再为实现虚 拟存储器而增加了某些功能而形成的，如产生和处理缺页中断，以及从内存中换出一页的 功能等等。

### 3.6.2 内存分配策略和分配算法**

在为进程分配内存时，将涉及到三个问题：第一，最小物理块数的确定；第二，物理块的分配策略(固定的，还是可变的)；第三，物理块的分配算法。

#### 1．最小物理块数的确定

这里所说的最小物理块数，是指能保证进程正常运行所需的最小物理块数。当系统为 进程分配的物理块数少于此值时，进程将无法运行。进程应获得的最少物理块数与计算机 的硬件结构有关，取决于指令的格式、功能和寻址方式。对于某些简单的机器，若是单地 址指令且采用直接寻址方式，则所需的最少物理块数为 2。其中，一块是用于存放指令的页 面，另一块则是用于存放数据的页面。如果该机器允许间接寻址时，则至少要求有三个物 理块。

#### 2．物理块的分配策略

在请求分页系统中，可采取两种内存分配策略，即固定和可变分配策略。在进行置换 时，也可采取两种策略，即全局置换和局部置换。于是可组合出以下三种适用的策略。

**1) 固定分配局部置换(Fixed Allocation，Local Replacement)**

这是指基于进程的类型(交互型或批处理型等)，或根据程序员、程序管理员的建议，为 每个进程分配一定数目的物理块，在整个运行期间都不再改变。采用该策略时，如果进程 在运行中发现缺页，则只能从该进程在内存的 n 个页面中选出一个页换出，然后再调入一 页，以保证分配给该进程的内存空间不变。实现这种策略的困难在于：应为每个进程分配 多少个物理块难以确定。若太少，会频繁地出现缺页中断，降低了系统的吞吐量；若太多， 又必然使内存中驻留的进程数目减少，进而可能造成 CPU 空闲或其它资源空闲的情况，而 且在实现进程对换时，会花费更多的时间。

**2) 可变分配全局置换(Variable Allocation，Global Replacement)**

**3) 可变分配局部置换(Variable Allocation，Local Replacement)**

#### 3 物理块分配算法

- 平均分配算法
- 按比例分配算法
- 按优先权分配

### 3.6.3 调页策略

使进程正常执行，事先将要执行的<u>**部分**</u>程序和数据调入内存，至此，要考虑的问题：

1. 系统应在何时考虑调入这些页面？
2. 系统从何处调入这些页面？
3. 如何进行调入？

#### 何时调入页面？

为了确定系统将进程运行时所缺的页面调入内存的时机，可采取预调页策略或请求调 页策略。预先调页由于无法确定要调用哪一页，故发生缺页时再去调用。调入过程如下：

每当程序所要访问的页面未在内存时，便向 CPU 发出一缺页中断，中断处理程序首先 保留 CPU 环境，分析中断原因后转入缺页中断处理程序。该程序通过查找页表，得到该页 在外存的物理块后，如果此时内存能容纳新页，则启动磁盘 I/O 将所缺之页调入内存，然后 修改页表。如果内存已满，则须先按照某种置换算法从内存中选出一页准备换出；如果该 页未被修改过，可不必将该页写回磁盘；但如果此页已被修改，则必须将它写回磁盘，然 后再把所缺的页调入内存，并修改页表中的相应表项，置其存在位为“1”，并将此页表项 写入快表中。在缺页调入内存后，利用修改后的页表，去形成所要访问数据的物理地址， 再去访问内存数据。整个页面的调入过程对用户是透明的。

#### 从何处调入这些页面？

请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘I/O速度比文件区的更快。这样从何处调入页面有三种情况：

1. 1. 系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。
   2. 系统缺少足够的对换区空间：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。
   3. UNIX方式：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。

#### 页面调入过程

每当程序所要访问的页面未在内存时，便向cpu发出 缺页中断 请求，中断程序保护cou环境，分析原因后转入缺页中断程序。

程序查找页表得到该页在外存的物理块，若内存此时能够容纳新页，则调入；若内存已满，则选用某种置换算法，从内存中选中一页并替换。（同时还要注意该页有没有被修改过，修改过处理方式不一样）

#### 缺页率

假设一个进程逻辑分页n，系统为其分配的物理内存块数为m （m <= n）运行中，访问页面成功次数为S， 失败的次数为F，则缺页率为

f = F /（S + F）；

通常，缺页率由以下因素影响：

- 页面大小 ——页越大，缺页率越低；反之，越高；
- 进程所分配的物理块数目 —— 越多缺页率越低；
- 页面置换算法——取决算法的好坏
- 程序编写对缺页中断的影响。（这个可以类比android 系统中的内存抖动的因素）

## 3.7 请求分段存储管理

在请求分段系统中，程序运行之前，只需先调入若干个分段(不必调入所有的分段)，便 可启动运行。当所访问的段不在内存中时，可请求 OS 将所缺的段调入内存。像请求分页系 统一样，为实现请求分段存储管理方式，同样需要一定的硬件支持和相应的软件。

### 3.7.1 请求分段中的硬件支持

请求分段管理所需的硬件支持有段表机制、缺段中断机构，以及地址变换机构。和请求分页系统和类似。

#### 1．段表机制

在请求分段式管理中所需的主要数据结构是段表。由于在应用程序的许多段中，只有 一部分段装入内存，其余的一些段仍留在外存上，故须在段表中增加若干项，以供程序在 调进、调出时参考。

|      |      |        |          |          |        |        |        |          |
| ---- | ---- | ------ | -------- | -------- | ------ | ------ | ------ | -------- |
| 段名 | 段长 | 段地址 | 存取方式 | 访问字段 | 修改位 | 存在位 | 增补位 | 外存始址 |

在段表项中，除了段名(号)、段长、段在内存中的起始地址外，还增加了以下诸项。

(1) 存取方式：用于标识本分段的存取属性是只执行、只读，还是允许读/写。

(2) 访问字段 A：其含义与请求分页的相应字段相同，用于记录该段被访问的频繁程度。

(3) 修改位 M：用于表示该页在进入内存后是否已被修改过，供置换页面时参考。

(4) 存在位 P：指示本段是否已调入内存，供程序访问时参考。

(5) 增补位：这是请求分段式管理中所特有的字段，用于表示本段在运行过程中是否做 过动态增长。

(6) 外存始址：指示本段在外存中的起始地址，即起始盘块号。

#### 2．缺段中断机构 

每当发现运行进程所要访问的段尚未调入内存时，便由缺段中断机 构产生一缺段中断信号，进入 OS 后由缺段中断处理程序将所需的段调入内存。

![image-20201029112239470](https://tva1.sinaimg.cn/large/0081Kckwgy1gk61g0tbzfj30g60bvdh1.jpg)

#### 3．地址变换机构 

请求分段系统中的地址变换机构是在分段系统地址变换机构的基础上形成的。因为被 访问的段并非全在内存，所以在地址变换时，若发现所要访问的段不在内存，必须先将所 缺的段调入内存，并修改段表，然后才能再利用段表进行地址变换。

![image-20201029112343052](https://tva1.sinaimg.cn/large/0081Kckwgy1gk61h4ovacj30do0c90tw.jpg)

### 3.7.2 分段的共享和保护

#### 共享分段

分段存储管理方式便于实现分段的共享与保护，也扼要地介绍了 实现分段共享的方法。下面进一步讲解分段共享实现。

1．**共享段表**

为了实现分段共享，可在系统中配置一张共享段表，所有各共享段都在共享段表中占 有一表项。表项中记录了共享段的段号、段长、内存始址、存在位等信息，并记录了共享 此分段的每个进程的情况。

![image-20201029155243030](https://tva1.sinaimg.cn/large/0081Kckwgy1gk6991q32zj30iy062jrv.jpg)

(1) 共享进程计数 count。非共享段仅为一个进程所需要。当进程不再需要该段时，可 立即释放该段，并由系统回收该段所占用的空间。而共享段是为多个进程所需要的，当某 进程不再需要而释放它时，系统并不回收该段所占内存区，仅当所有共享该段的进程全都 不再需要它时，才由系统回收该段所占内存区。为了记录有多少个进程需要共享该分段， 特设置了一个整型变量 count。

(2) 存取控制字段。对于一个共享段，应给不同的进程以不同的存取权限。例如，对于 文件主，通常允许他读和写；而对其它进程，则可能只允许读，甚至只允许执行。

(3) 段号。对于一个共享段，不同的进程可以各用不同的段号去共享该段。

2 **分配和回收**

由于共享段是供多个进程所共享的，每增加一个进程其count 应加1，回收时则应减1，当count= 0 才能回收。

#### 分段保护

在分段系统中，由于每个分段在逻辑上是独立的，因而比较容易实现信息保护。

1) 越界检查

在段表寄存器中放有段表长度信息；同样，在段表中也为每个段设置有段长字段。在 进行存储访问时，首先将逻辑地址空间的段号与段表长度进行比较，如果段号等于或大于 段表长度，将发出地址越界中断信号；其次，还要检查段内地址是否等于或大于段长，若 大于段长，将产生地址越界中断信号，从而保证了每个进程只能在自己的地址空间内运行。

2） 存取控制检查

(1) 只读，即只允许进程对该段中的程序或数据进行读访问。

(2) 只执行，即只允许进程调用该段去执行，但不准读该段的内容，也不允许对该段执 行写操作。

(3) 读/写，即允许进程对该段进行读/写访问。

对于共享段而言，存取控制就显得尤为重要，因而对不同的进程，应赋予不同的读写 权限。这时，既要保证信息的安全性，又要满足运行需要。

3) 环保护机构

这是一种功能较完善的保护机制。在该机制中规定：低编号的环具有高优先权。OS 核 心处于 0 环内；某些重要的实用程序和操作系统服务占居中间环；而一般的应用程序则被 安排在外环上。在环系统中，程序的访问和调用应遵循以下规则：

(1) 一个程序可以访问驻留在相同环或较低特权环中的数据。

(2) 一个程序可以调用驻留在相同环或较高特权环中的服务。

![image-20201029155744625](https://tva1.sinaimg.cn/large/0081Kckwgy1gk69e95jq5j30gn06idgm.jpg)

## 3.8 页面置换与 “抖动”

在进程运行过程中，若其所要访问的页面不在内存而需把它们调入内存，但内存已无 空闲空间时，为了保证该进程能正常运行，系统必须从内存中调出一页程序或数据送磁盘 的对换区中。但应将哪个页面调出，须根据一定的算法来确定。通常，把选择换出页面的 算法称为页面置换算法(Page-Replacement Algorithms)。置换算法的好坏，将直接影响到系统 的性能。这就是页面置换的背景。

### 置换算法

#### 1 最佳置换算法

**最佳置换算法是一种理论上的算法。其所选择的被淘汰页面， 将是以后永不使用的，或许是在最长(未来)时间内不再被访问的页面**。采用最佳置换算法， 通常可保证获得最低的缺页率。但由于人们目前还无法预知一个进程在内存的若干个页面 中，哪一个页面是未来最长时间内不再被访问的，**因而该算法是无法实现的，但可以利用 该算法去评价其它算法**。

#### 2 先进先出(FIFO)页面置换算法

该算法总是淘汰最先进入内存的页面，即选择在内存中驻 留时间最久的页面予以淘汰。类似于队列的实现原理。但其缺点是：最先进入的页面假如是全局变量这种经常使用的，该算法不合适。

#### 3 最近最久未使用(LRU)置换算法

LRU 算法算是比较常用和熟悉的一点了。选择最近最久未 使用的页面予以淘汰。在系统采取这种方法，必须要有硬件支持才行的。下面分析一下硬件特征：移位寄存器和栈

#### 4 CLock 置换算法

是LRU的近似算法。思想：

> 为每页设置一位访问位，再将内存中的所有页面都通过 链接指针链接成一个循环队列。当某页被访问时，其访问位被置 1。置换算法在选择一页淘 汰时，只需检查页的访问位。如果是 0，就选择该页换出；若为 1，则重新将它置 0，暂不 换出，而给该页第二次驻留内存的机会，再按照 FIFO 算法检查下一个页面。

### 进程抖动

虚拟分页请求内存管理系统以离散内存分配为基础，通过多道性、对换性技术，加上程序运行的局部性原理，使得逻辑内存大于物理内存，极大的提高了系统吞吐，程序的并发执行。明白万事有一个度，不可能极大的增加进程数，如果实际内存较小，为每个进程分配的物理块不多，但同时运行的进程很多，这个时候会发生什么呢？进程频繁的出现缺页，请求系统将所缺的页调人内存；当大多进程都出现内存缺页时，每个进程向cpu发出的指令都是请求/置换页（A进程把a页面调入，B进程又把A进程的a页拿走了执行B，这时候cpu先把A进程换出，再把a给B；之后A进程又获取了cpu 又把a页拿回去，导致反反复复的抢夺内存物理块），致使进程不能执行真正有意义的工作，都浪费在页面的置换上了，而且是反复执行这个过程，每个迟迟不能执行完退出。这时候就称之为 进程抖动。

> 刚被置换出去的页，很快又要访问，因而要把它重新调入；可是调入不 久又再次被置换出去，这样再访问、再调入，如此反复，使得整个系统的页面替换非常频繁，以致大部分的机器时间都花在来回进行的页面调度上，只有一小部分时 间用于进程的实际运算。这种局面就称为**系统“抖动”**

![image-20201029171119833](https://tva1.sinaimg.cn/large/0081Kckwgy1gk6bit3mfwj30ye0fo400.jpg)

#### **工作集**

<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk9qlvue30j31c50u0npg.jpg" alt="image-20201029173601662" style="zoom:67%;" />

工作集（或驻留集）是指在某段时间间隔内，进程要访问的页面集合。经常被使用的页面需要在工作集中，而长期不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小。

工作集模型的原理是：让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。如果还有空闲物理块，则可以再调一个进程到内存以增加多道程序数。如果所有工作集之和增加以至于超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。

由于事先并不知道进程会使用到哪些内存，所以这个工作集的确定是在进程执行后，根据一定的策略确定的，比如对刚刚运行的进程所使用的内存作为参考看为当前工作集，这样每次对过去一段时间进程的运行情况分析得到相应的工作集，所以工作集是动态改变的，不固定的。

#### 预防抖动方法

**a) 采取局部置换策略**

仅允许进程在自身范围内进行置换。即使发生抖动，也可以把影响限制在较小范围内。不能采取全局替换，这样可能替换到其他进程正在使用的页，这样会打断其他进程的运行；

**b) 在处理机调度中引入工作集策略**

- 操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。
- 如果所有工作集之和增加到超过了可用物理块的总数，操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。

**c) 用 L=S 准则调节缺页率**

L：缺页之间的平均时间（两次缺页之间的时间差）。S：平均缺页服务时间（用于置换一个页面所需时间）

- L 大于 S，很少缺页，磁盘能力没有被充分利用。
- L 小于 S，频繁缺页，超过磁盘的处理能力。

调整并发程序度，使得 L 与 S 接近。这种情况下，磁盘和处理机到可以达到最佳利用率。

**d) 挂起若干进程**

当多道程序度偏高，已影响到处理机的利用率时，为了防止发生抖动，系统必须减少多道程序的数目。把某些低优先级的进程挂起，从而腾出内存空间。



# 第四章 设备管理



# 第五章 文件管理

