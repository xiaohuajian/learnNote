**写在前面的思考？**

这门课连接了计算机组成原理、Linux 基础、其他各种编程语言的基础。它的下一级是计算机组成原理，对上其他的各种应用软件、编程语言，而各种编程语言的实现也是基于操作系统的，所以明白了最底层的操作系统，在来反过来理解编程语言，就会发现他们大同小异，或多或少都有操作系统的影子，包括思想、设计、概念。举例来说，操作系统讲进程调度，那对应的编程语言肯定也会涉及到这个东西，比如说线程的调度，而且线程中的中断，会对应到进程，甚至对应到计算机组成原理中讲的硬件中断，在到微机层面的中断，到数电模电的中断，你就会发现这一些列的东西原理如此，他们的之间的关系是这样的，就会发现大学里面的课程都是有其意义的，只不过明白了有点晚，哈哈。学东西，如果您能够高屋建瓴、俯视而下，系统综合的看待这门学科，把其和其他的东西练习起来，形成一个系统，这个系统就我讲的就是整个计算机领域，这样你就会豁然开朗，一往无前。

# 第一章 概述与引论

- 操作系统的概念、特征、功能和提供的服务
- 操作系统的发展与分类
- 运行环境：内核态与用户态：中断、异常、系统调用
- 体系结构

![image-20200925232140076](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj3b5qv1dyj313e0e6gux.jpg)

体系结构图：如上



## 发展历程

1. 人工处理：人工把带孔的纸带装入纸带机，进行输入

2. 脱机处理：用机器控制纸带的输入，而不是人工，提升输入效率；

3. 单道批处理：用晶体管替代真空管；**把一批作业以脱机方式输入到磁带上，并在系统中配上监督程序(Monitor)，使得作业能够持续进行，进一步提升效率，解决人机速度不匹配问题**——标志操作系统的出现

4. 多道批处理：集成电路替代单个晶体管；在单道批处理系统中，内存中仅有一道作业，系统资源利用不充分，引入多道处理，**同时在内存中装有若干道程序，并使它们交替地运行，当正在运行的程序因 I/O 而暂停执行时，系统可调度另一道程序运行**，从而保持了 CPU 处于忙碌状态；**实现作业自动控制无需人工干预，实现批处理的**

   > 其实这里，我们是不是可以知道为啥会有锁、资源共享的概念？因为在物理世界中不可能有两个物体同时占有一个东西，对应到计算机里面也是一样的，然而，由于计算机的处理和转换的速度很快，所以这时候可以在一段时间内，表现“共享”的现象，但本质仍然是来回切换独占，不过这个时间很短，就称之为一段时间内共享了。

5. 分时系统：把处理器运行时间分成很短的时间片，时间片轮流把处理器分给某个程序；将一台主机提供给多个用户同时使用，提高计算机的利用率；**分时系统是解决人机交互性的**

   - 多路性：一台主机上同时联接多台联机终端，系统按分时原则为每个用户服 

     务

   - 独立性：每个用户各占一个终端，彼此独立操作，互不干扰

   - 及时性：用户的请求能在很短的时间内获得响应

   - 交互性：用户可通过终端与系统进行广泛的人机对话

6. 实时系统：所谓“实时”，是表示“及时”，而实时系统(Real Time System)是指系统能及时(或即时)

   响应外部事件的请求，在规定的时间内完成对该事件的处理

   实时系统和分时系统有类似的特性，但他更强调了可靠性。

7. 微机时代：

   1. 单用户单任务

   2. 单用户多任务：单用户多任务操作系统的含义是，只允许一个用户上机，但允许用户把程序分为若干 

      个任务，使它们并发执行，从而有效地改善了系统的性能

   3. 多用户多任务：允许多个用户通过各自的终端使用同一台机器，共享主机系统中的各种资源，而每个用户程序又可进一步分为几个任务，使它们能并发执行

## 特征

1. **并发**

   系统从单人单任务——单人多任务——多人任务；从单任务到多任务就是并发（一段时间内，执行多个程序）

   > 并发（一段时间内，执行多个程序）;并行——同一时间，执行多个程序

   **引入进程**

   **进程是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆 栈等组成的，是一个能独立运行的活动实体。** 目的是为了并行执行程序，提升效率（提升的本质是有效的利用了计算机资源）。

   > 在操作系统中引入进程的目的，就是为了使多个 程序能并发执行。例如，在一个未引入进程的系统中，在属于同一个应用程序的计算程序 和 I/O 程序之间，两者只能是顺序执行，即只有在计算程序执行告一段落后，才允许 I/O 程 序执行；反之，在程序执行 I/O 操作时，计算程序也不能执行，这意味着处理机处于空闲状 态，这样就浪费了cpu资源。或者可以一边读取内存数据，一边用cpu进行处理，这样也可以提升效率。因为读取数据不需要cpu的参与，相当于我们可以实时的利用两种计算机资源。

   **引入线程**

   长期以来，进程都是操作系统中可以拥有资源并作为独立运行的基本单位。当一个进程因故不能继续运行时，操作系统便调度另一进程运行。由于进程拥有自己的资源，故使调度付出的开销较大；所以用线程来调度。通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源；==通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度 的基本单位==。由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多。

2. **共享**

   1. 互斥：就是编程概念上对某个资源上锁，线程独占的意思。在应用程序上就是进程独占；
   2. 同时访问：这里的“同时”指的一段时间内多个进程同时访问，同时是宏观概念上的，在微观上仍然是交替进行的。

3. **虚拟**

   虚拟指的是把物理上的实体变为若干逻辑上对应物；比如多处理器，虚拟多个cpu；虚拟多个终端设备；

   1．时分复用技术

   时分复用，亦即分时使用方式，它最早用于电信业中。为了提高信道的利用率，人们利用时分复用方式，将一条物理信道虚拟为多条逻辑信道，将每条信道供一对用户通话。我们在计算机网络原理中 看到了这个名词；比如说有多个进程，但只有一个cpu，一个cpu为多个进程服务，就是一种在时间上的复用。

   2. 空分复用技术

      电信业中就使用频分复用技术来提高信道的利用率。它是将一个频率 范围非常宽的信道，划分成多个频率范围较窄的信道，其中的任何一个频带都只供一对用户通话。早期的频分复用只能将一条物理信道划分为十几条到几十条话路，后来又很快发 展成上万条话路，每条话路也只供一对用户通话。之后，在计算机中也使用了空分复用技 术来提高存储空间的利用率。

      1) 虚拟磁盘技术：将一台硬盘虚拟为多台虚拟磁盘，

4. **异步**

   多道环境允许多个程序（进程）并发执行，由于资源有限，进程执行并不是一贯到底的，是走走停停的；

## 操作系统作用

操作系统管理计算机的资源（处理器cpu、存储器——内存、IO——设备、文件），连接硬件和软件的桥梁。会对 处理器管理、存储器管理、设备管理、文件管理；方便用户操作系统，还必须提供用户接口。

![image-20200925234100103](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj3bpsbkd8j30e808udgh.jpg)



### 处理机管理

在传统的多道程序系统中，处理机的分配和运行都是以进程为基本单位，因而对处理机的管理可归结为对进程的管理；在引入了线程OS 中，也包含对线程的管理。处理机管理的主要功能是创建和撤消进程(线程)，对诸进程(线程)的运行进行协调，实现进程(线程)之间的信息交换，以及按照一定的算法把处理机分配给进程(线程)。

#### 1 进程控制

创建、撤销进程，同时包含进程内的线程。

#### 2 进程同步

进程是以异步方式运行的，并以人们不可预知的速度向前推进。为使多个进程能有条不紊地运行，系统中必须设置进程同步机制。进程同步的主要任务是为多个进程(含线程)的运行进行协调。有两种协调方式：

(1) 进程互斥方式。这是指诸进程(线程)在对临界资源进行访问时，应采用互斥方式；

(2) 进程同步方式。这是指在相互合作去完成共同任务的诸进程(线程)间，由同步机构对它们的执行次序加以协调。

实现进程同步，必须有相应的同步机制，比如说锁机制，对共享资源访问时，用锁来控制谁该访问，其内部原理是信号量机制。

#### 3 进程通信

一个任务往往需要多个进程进行配合完成，这时候涉及到进程通信，IPC、binder；看到这里来是不是很熟悉，android里这些都有，因为android也是一个操作系统 

#### 4  调度

在后备队列上等待的每个作业都需经过调度才能执行。在传统的操作系统中，包括作业调度和进程调度两步。 

(1) **作业调度**。作业调度的基本任务是从后备队列中按照一定的算法，选择出若干个 作业，为它们分配运行所需的资源(首先是分配内存)。在将它们调入内存后，便分别为它们建立进程，使它们都成为可能获得处理机的就绪进程，并按照一定的算法将它们插入就 绪队列。

(2) **进程调度。**进程调度的任务是从进程的就绪队列中，按照一定的算法选出一个进程，把处理机分配给它，并为它设置运行现场，使进程投入执行。值得提出的是，在多线程 OS中，通常是把线程作为独立运行和分配处理机的基本单位，为此，须把就绪线程排成一个队列，每次调度时，是从就绪线程队列中选出一个线程，把处理机分配给它。 

### 存储器管理（内存管理）

存储器管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以及能从逻辑上扩充内存。为此，存储器管理应具有内存分配、内存保护、地址映射和内存扩充等功能。

#### 1 内存分配

内存分配的主要任务是为每道程序分配内存空间，使它们“各得其所”；提高存储器的利用率，以减少不可用的内存空间；允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。

#### 2 内存保护

内存保护的主要任务是确保每道用户程序都只在自己的内存空间内运行，彼此互不干 扰；绝不允许用户程序访问操作系统的程序和数据；也不允许用户程序转移到非共享的其 它用户程序中去执行。

> 内存保护和OOM异常有联系的，我们OOM就是因为内存不够，越界了导致发生了OOM。

#### 3 地址映射

一个应用程序(源程序)经编译后，通常会形成若干个目标程序；这些目标程序再经过链接便形成了可装入程序。这些程序的地址都是从“0”开始的，程序中的其它地址都是相对于起始地址计算的。**由这些地址所形成的地址范围称为“地址空间”，其中的地址称为“逻辑地址”或“相对地址”；**在多道程序环境下，每道程序不可能都从“0”地址开始装入(内存)，这就致使地址空间内的逻辑地址和内存空间中的物理地址不相一致。为使程序能正确运行，存储器管理必须提供地址映射功能，以将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。该功能应在硬件的支持下完成。

#### 4 **内存扩充**

存储器管理中的内存扩充任务并非是去扩大物理内存的容量，而是借助于虚拟存储技术，从逻辑上去扩充内存容量，使用户所感觉到的内存容量比实际内存容量大得多。

(1) 请求调入功能。允许在装入一部分用户程序和数据的情况下，便能启动该程序运行。在程序运行过程中，若发现要继续运行时所需的程序和数据尚未装入内存，可向 OS 发出请求，由 OS 从磁盘中将所需部分调入内存，以便继续运行。 

(2) 置换功能。若发现在内存中已无足够的空间来装入需要调入的程序和数据时，系统应能将内存中的一部分暂时不用的程序和数据调至盘上，以腾出内存空间，然后再将所需调入的部分装入内存。

### 设备管理

用于管理计算机系统中所有的外围设备，比如鼠标、键盘、光驱、磁盘等等外设；设备管理应具有缓存管理、设备分配和设备处理以及虚拟设备等功能。

#### 1．缓冲管理

CPU 运行的高速性和 I/O 低速性间的矛盾自计算机诞生时起便已存在了。而随着 CPU速度迅速提高，使得此矛盾更为突出，严重降低了 CPU 的利用率。如果在 I/O 设备和 CPU之间引入缓冲，则可有效地缓和 CPU 与 I/O 设备速度不匹配的矛盾，提高 CPU 的利用率， 进而提高系统吞吐量。因此，在现代计算机系统中，都无一例外地在内存中设置了缓冲区，而且还可通过增加缓冲区容量的方法来改善系统的性能。

最常见的缓冲区机制有单缓冲机制、 能实现双向同时传送数据的双缓冲机制，以及能供多个设备同时使用的公用缓冲池机制。 上述这些缓冲区都将由 OS 中的缓冲管理机制将它们管理起来。

#### 2．设备分配

设备分配的基本任务是根据用户进程的 I/O 请求、系统的现有资源情况以及按照某种设 备的分配策略，为之分配其所需的设备。如果在 I/O 设备和 CPU 之间还存在着设备控制器 和 I/O 通道时，还须为分配出去的设备分配相应的控制器和通道。

为了实现设备分配，系统中应设置设备控制表、控制器控制表等数据结构，用于记录 设备及控制器的标识符和状态。根据这些表格可以了解指定设备当前是否可用，是否忙碌， 以供进行设备分配时参考。在进行设备分配时，应针对不同的设备类型而采用不同的设备 分配方式。对于独占设备(临界资源)的分配，还应考虑到该设备被分配出去后系统是否安全。 在设备使用完后，应立即由系统回收。

#### 3 设备处理

设备处理程序又称为设备驱动程​序。其基本任务是用于**实现 CPU 和设备控制器之间的通信**，即由 CPU 向设备控制器发出 I/O 命令，要求它完成指定的 I/O 操作； 

### 文件管理

人们总是把程序和数据以文件的形式存储在磁盘和磁带上，供所有的或指定的用户使用。为此，在操作系统中必须配置文件管理机构。文件管理的主要任务 是对用户文件和系统文件进行管理，以方便用户使用，并保证文件的安全性。件 管理应具有对文件存储空间的管理、目录管理、文件的读/写管理，以及文件的共享与保护 等功能。

#### 1．文件存储空间的管理

#### 2 目录管理

为了使用户能方便地在外存上找到自己所需的文件，通常由系统为每个文件建立一个 目录项。目录项包括文件名、文件属性、文件在磁盘上的物理位置等。

#### 3 文件读/写

通过读写指针进行读写

### 操作系统与用户之间接口

为了让用户调用操作系统的服务，提供了接口，分为：

(1) 用户接口。它是提供给用户使用的接口，用户可通过该接口取得操作系统的服务；

(2) 程序接口。它是提供给程序员在编程时使用的接口，是用户程序取得操作系统服务的唯一途径

#### 用户接口

- 联机用户接口 ：当用户在终端或控制台上每键入一条命令后，系统便立即转入命令解释程序，对该 命令加以解释并执行该命令。
- 脱机用户接口 ： 该接口是为批处理作业的用户提供的，故也称为批处理用户接口。 该接口由一组作业控制语言(JCL)组成。批处理作业的用户不能直接与自己的作业交互作用， 只能委托系统代替用户对作业进行控制和干预。
- 图形用户接口 ：用户虽然可以通过联机用户接口来取得 OS 的服务，但这时要求用 户能熟记各种命令的名字和格式，并严格按照规定的格式输入命令。这既不方便又花时间， 于是，另一种形式的联机用户接口——图形用户接口便应运而生。

#### 程序接口

由一组系统调用组成，每一个系统调用都是一个能完成特定功能的子程 序，每当应用程序要求 OS 提供某种服务(功能)时，便调用具有相应功能的系统调用

- 

## 运行环境

计算机中，cpu通常执行两种不同的程序，一种是操作系统的内核程序，一种是用户自编程序。前者是后者的管理者，因此内核程序需要执行一些特权指令，而用户程序出于安全考虑其不能执行这些指令，比如IO指令、中断指令、存取寄存器等。我们可以理解为 cpu内部有一个开关，小开关为1 时，cpu处于核心态，可以执行特权指令，为0时，为用户态，不能执行。当然，操作系统运行在内核态，用户程序运行在用户态。

## 微内核

微内核(Micro Kernel)操作系统结构：微内核和多个服务器。微内核只提供基本的功能，把其他的非核心的功能用服务的形式提供，这样的做法目的保证os 灵活、易维护、可扩展。一般有以下特点：

1. 足够小的内核

2. 基于客户/服务器模式：**操作系统中最基本的部分放入内核中，而把操作系统的绝大部 分功能都放在微内核外面的一组服务器(进程)中实现**。例如用于提供对进程(线程)进行管理的进程(线程)服务器，提供虚拟存储器管理功能的虚拟存储器服务器，提供 I/O 设备管理的 I/O 设备管理服务器等，它们都是被作为进程来实现的，运行在用户态，客户与服务器之 间是借助微内核提供的消息传递机制来实现信息交互的。

   ![image-20200929224012349](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj7wft156jj30uw06gmy6.jpg)

3. 应用“机制与策略分离”原理

   所谓机制，是指实现某一功能的具体执行机构。而策略，则是在机制的基础上，借助于某 些参数和算法来实现该功能的优化，或达到不同的功能目标。通常，机制处于一个系统的 基层，而策略则处于系统的高层。在传统的 OS 中，将机制放在 OS 的内核的较低层，把策 略放在内核的较高层次中。而在微内核操作系统中，通常将机制放在 OS 的微内核中。正因 为如此，才有可能将内核做得很小。

4. 采用面向对象技术：这样便于程序的编写

### 微内核缺点

由于客户对 OS 提出的服务请求时，需要利用消息 实现多次交互和进行用户/内核模式及上下文的多次切换，频繁的状态（用户/内核态）切换导致效率低下。

> 在早期的 OS 中，用户进 程在请求取得 OS 服务时，一般只需进行两次上下文的切换：一次是在执行系统调用后，由 用户态转向系统态时；另一次是在系统完成用户请求的服务后，由系统态返回用户态时。 在微内核 OS 中，由于客户和服务器及服务器和服务器之间的通信，都需通过微内核，致使 同样的服务请求至少需要进行四次上下文切换。第一次是发生在客户发送请求消息给内核， 以请求取得某服务器特定的服务时；第二次是发生在由内核把客户的请求消息发往服务器 时；第三次是当服务器完成客户请求后，把响应消息发送到内核时；第四次是在内核将响 应消息发送给客户时。

![image-20200929224455196](https://tva1.sinaimg.cn/large/007S8ZIlgy1gj7wkqzv8sj31080u01ky.jpg)

# 第二章 进程描述与控制

本章节重点：

- 进程和线程
  - 进程的概念与状态转换
  - 进程控制与管理
  - 进程通信：线程概念与多线程
- 处理机调度
  - 调度的概念、时机、切换
  - 调度基本准则、方式
- 进程同步
  - 信号量、管程，经典同步问题
  - 临界资源互斥
- 死锁
  - 概念、处理方法
  - 死锁预防、处理、检测

![image-20201014101050085](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjon2o27hdj30nh0cawm1.jpg)



## 2.1 前趋图和程序执行

### 2.1.1 前趋图

### 2.1.2 顺序执行

- 顺序性：处理机的操作严格按照程序所规定的顺序执行
- 封闭性：程序运行时独占全机资源，资源的状态(除初始状态外)只有本程序才能改变它。程序一旦开始执行，其执行结果不受外界因素影响
- 可再现性：只要程序执行时的环境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿地执行，还是“停停走走”地执行，都将获得相同的结果

### 2.1.3 并发执行

- 间断性：由于有多个程序在同一段时间执行，可能多个程序之间要相互协作，依赖，所以程序可能要等待其他程序，所以出现间断。
- 非封闭性：对比上面
- 不可再现性：对比上面

## 2.2 进程定义与特征

在多道程序环境下，程序的执行属于并发执行，此时它们将失去其封闭性，并具有间断性及不可再现性的特征。为了对并发执行的程序加以描述和控制，引入**进程**概念：

**进程 = 程序program + 数据 data + 进程控制块PCB（Process Control Block）** 

> 通常的程序是不能并发执行的。为使程序(含数据)能独立运行，应为之配置一进程控制块，即 PCB(Process Control Block)；而由程**序段、相关的数据段和 PCB 三部分便构成了进程实体**。在早期的 UNIX 版本中，把这三部分总称为“进程映像”。值得指出的是，在许多情况下所说的进程，实际上是指进程实体，例如，所谓创建进程，实质上是创建进程实体中的 PCB；而撤消进程，实质上是撤消进程的 PCB。

**「进程」**：是程序的一次执行，动态的；

**「程序」**：一组有序指令的集合，并存放于某种介质上，其本身并不具有运动的含义，因而是静态的；



下面说几个结论：

**(1) 进程是程序的一次执行。**

**(2) 进程是一个程序及其数据在处理机上顺序执行时所发生的活动。** 

**(3) 进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。**

### 进程控制块PCB

#### 作用：

1. 为了描述和控制进程的运行，系统为每个进程定义了一个数据结构——进程控制块 PCB(Process Control Block)，它是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB 中记录了操作系统所需的、用于描述进程的当前情况以及控制进程运行的全部信息。

2. 使一个在多道程序环境下不能独立运行的程序(含数据)，成为一个能独立运行的基本单位，一个能与其它进程并发执行的进程。或者说，OS 是根据 PCB 来对并发执行的进程进行控制和管理的。

> 当 OS 要调度某进程执行时，要从该进程的 PCB中查出其现行状态及优先级；在调度到某进程后，要根据其 PCB 中所保存的处理机状态信息，设置该进程恢复运行的现场，并根据其 PCB 中的程序和数据的内存始址，找到其程序和数据；进程在执行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也都需要访问 PCB；当进程由于某种原因而暂停执行时，又须将其断点的处理机环境保存在 PCB .

#### 信息

1) 进程标识符：自己id，父id，子id等等；

2) 处理机状态 

由处理机的各种寄存器中的内容组成的。处理机在运行时，许多信息都放在寄存器中。当处理机被中断时，所有这些信息都必须保存在 PCB 中，以便在该进程重新执行时，能从断点继续执行。

3) 进程调度信息

在 PCB 中还存放一些与进程调度和进程对换有关的信息，包括：① 进程状态，指明进程的当前状态，作为进程调度和对换时的依据；② 进程优先级，用于描述进程使用处理机的优先级别的一个整数，优先级高的进程应优先获得处理机；③ 进程调度所需的其它信息，它们与所采用的进程调度算法有关，比如，进程已等待 CPU 的时间总和、进程已执行的时间总和等；④ 事件，指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。

4) 进程控制信息

进程控制信息包括：① 程序和数据的地址，指进程的程序和数据所在的内存或外存地(首)址，以便再调度到该进程执行时，能从 PCB 中找到其程序和数据；② 进程同步和通信机制，指实现进程同步和进程通信时必需的机制，如消息队列指针、信号量等，它们可能 全部或部分地放在 PCB 中；③ 资源清单，即一张列出了除 CPU 以外的、进程所需的全部资源及已经分配到该进程的资源的清单；④ 链接指针，它给出了本进程(PCB)所在队列中的下一个进程的 PCB 的首地址。

###  进程管理中的数据结构

![image-20201014102223550](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjonep2qakj30fc0da76z.jpg)

计算机对各类资源进行抽象为各种数据结构，然后用表记录，这些包含内存、设备、文件、进程（多个进程）。

## 2.3 进程状态及转换

因为进程具有间断性，所以进程会处于不同的状态，下面探讨进程状态：

### 2.3.1 进程两状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnie8gs2vj30v40n447t.jpg" alt="进程2状态图" style="zoom:67%;" />

Running：进程获取cpu资源正在执行；

Not Running：非执行的进程就是Not Running；未执行的状态有可以分为阻塞和就绪状态。

如果展开来说非执行状态，其图例为：

![image-20201013105232980](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjninrkuxqj309q084aal.jpg)

**1) 就绪(Ready)状态**

当进程已分配到除 CPU 以外的所有必要资源后，只要再获得 CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。 

**2) 阻塞状态**

正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态， 亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求 I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。

> 阻塞状态是不能直接到运行态的，某个进程由于I/O 处于阻塞态，然后当事件发生获取到I/O资源后，此时进程需要先进入就绪队列，等待操作系统调度，当他被选中后，才能被执行

#### 进程阻塞与唤醒

##### 进程阻塞

正在执行的进程，当发现上述某事件时，由于无法继续执行，于是进程便通过调用阻塞原语 block 把自己阻塞。可见，进程的阻塞是进程自身的一种主动行为。进入 block 过程后，由于此时该进程还处于执行状态，所以应先立即停止执行，把进程控制块中的现行状 态由“执行”改为“阻塞”，并将 PCB 插入阻塞队列。如果系统中设置了因不同事件而阻塞的多个阻塞队列，则应将本进程插入到具有相同事件的阻塞(等待)队列。最后，转调度程序进行重新调度，将处理机分配给另一就绪进程并进行切换，亦即，保留被阻塞进程的处理机状态(在 PCB 中)，再按新进程的 PCB 中的处理机状态设置 CPU 的环境。

##### 进程唤醒过程

当被阻塞进程所期待的事件出现时，如 I/O 完成或其所期待的数据已经到达，则由有关进程(比如用完并释放了该 I/O 设备的进程)调用唤醒原语 wakeup( )，将等待该事件的进程唤醒。唤醒原语执行的过程是：首先把被阻塞的进程从等待该事件的阻塞队列中移出，将其 PCB 中的现行状态由阻塞改为就绪，然后再将该 PCB 插入到就绪队列中。应当指出，block 原语和 wakeup 原语是一对作用刚好相反的原语。因此，如果在某进程中调用了阻塞原语，则必须在与之相合作的另一进程中或其他相关的进程中安排唤醒原 语，以能唤醒阻塞进程；否则，被阻塞进程将会因不能被唤醒而长久地处于阻塞状态，从 而再无机会继续运行。

##### 引起进程阻塞和唤醒的事件

**1) 请求系统服务**

当正在执行的进程请求操作系统提供服务时，由于某种原因，操作系统并不立即满足该进程的要求时，该进程只能转变为阻塞状态来等待。例如，一进程请求使用某资源，如打印机，由于系统已将打印机分配给其他进程而不能分配给请求进程，这时请求者进程只能被阻塞，仅在其他进程在释放出打印机的同时，才将请求进程唤醒。 

**2) 启动某种操作**

当进程启动某种操作后，如果该进程必须在该操作完成之后才能继续执行，则必须先使该进程阻塞，以等待该操作完成。例如，进程启动了某 I/O 设备，如果只有在 I/O 设备完成了指定的 I/O 操作任务后进程才能继续执行，则该进程在启动了 I/O 操作后，便自动进入阻塞状态去等待。在 I/O 操作完成后，再由中断处理程序或中断进程将该进程唤醒。 

**3) 新数据尚未到达**

对于相互合作的进程，如果其中一个进程需要先获得另一(合作)进程提供的数据后才能 对数据进行处理，则只要其所需数据尚未到达，该进程只有(等待)阻塞。例如，有两个进程，进程 A 用于输入数据，进程 B 对输入数据进行加工。假如 A 尚未将数据输入完毕，则进程B 将因没有所需的处理数据而阻塞；一旦进程 A 把数据输入完毕，便可去唤醒进程 B。 

**4) 无新工作可做**

系统往往设置一些具有某特定功能的系统进程，每当这种进程完成任务后，便把自己阻塞起来以等待新任务到来。例如，系统中的发送进程，其主要工作是发送数据，若已有 的数据已全部发送完成而又无新的发送请求，这时(发送)进程将使自己进入阻塞状态； 仅 当又有进程提出新的发送请求时，才将发送进程唤醒。



### 2.3.2 进程五状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnitbm0jij30wo0m87br.jpg" alt="进程5状态图" style="zoom:67%;" />

或者：

<img src="../../../Desktop/进程图1.png" alt="进程图1" style="zoom:67%;" />

对比两状态、无状态，发现多了创建、退出状态，而且要搞明白创建状态和就绪状态的区别；

#### **「创建状态」**

进程是由PCB 描述的，包含进程id、名称等信息，当进程有了自己的PCB后，在装入内存，进入就绪队列。这样看到进程创建分两步1 是创建PCB，2是装入内存；所以在装入内存之前都是处于创建状态，所以要搞清楚这个概念。

> 程序是在内存中执行的，由于内存资源有限，所以创建好的进程不一定都会被及时的装入内存中，这就是我们平时说的加大内存可以提升电脑速度就是这个原因，这样我们就知道了创建的状态，和就绪状态区别是后者是需要等待处理机cpu的调度，当被调度后才能执行。这里就能明白如果cpu很强大，处理速度快，电脑性能也会比较好。但是要知道如果内存不够大，cpu的处理速度超过了内存数据处理速度，这时候单单提高cpu就没有意义，内存、cpu就像一个木桶效应。

**「进程的创建(Creation of Process)」** 

一旦操作系统发现了要求创建新进程的事件后，便调用进程创建原语 Creat( )按下述步 骤创建一个新进程。

(1) 申请空白 PCB。为新进程申请获得惟一的数字标识符，并从 PCB 集合中索取一个空白 PCB。 

(2) 为新进程分配资源。为新进程的程序和数据以及用户栈分配必要的内存空间。显然，此时操作系统必须知道新进程所需内存的大小。

(3) 初始化进程控制块。PCB 的初始化包括：① 初始化标识信息，将系统分配的标识符和父进程标识符填入新 PCB 中；② 初始化处理机状态信息，使程序计数器指向程序的入口地址，使栈指针指向栈顶；③ 初始化处理机控制信息，将进程的状态设置为就绪状态或 静止就绪状态，对于优先级，通常是将它设置为最低优先级，除非用户以显式方式提出高优先级要求。 

(4) 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列。

#### **「退出/终止状态」**

进程终止首先等待操作系统进行善后处理，然后将其 PCB 清零，并将 PCB 空间返还系统。终止的进程会在系统保留一些数据或记录，当这些数据被处理后，系统才会删除该进程。（我们看到终止的进程就是把PCB回收，返回给系统，这里也能看到PCB在进程中所起的作用）

**「进程的终止过程」**

如果系统中发生了上述要求终止进程的某事件，OS 便调用进程终止原语，按下述过程去终止指定的进程。

(1) 根据被终止进程的标识符，从 PCB 集合中检索出该进程的 PCB，从中读出该进程的状态。

(2) 若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度。 

(3) 若该进程还有子孙进程，还应将其所有子孙进程予以终止，以防它们成为不可控的进程。

(4) 将被终止进程所拥有的全部资源，或者归还给其父进程，或者归还给系统。

(5) 将被终止进程(PCB)从所在队列(或链表)中移出，等待其他程序来搜集信息。

> 会引起进程终止的原因：
>
> 1.正常执行完成后，执行退出、终止。
>
> 2.程序异常或错误——非法指令、运行超时、越界错误（访问的区域不存在）、算术错误等其他在编写程序时发生的错误；
>
> 3.外界干预——用户或操作系统终止某个进程、父进程请求终止子进程、父进程终止则其子进程也将被终止。

#### 「状态转换」

null——创建：进程创建，即为程序准备pcb 和数据；

创建——就绪：内存接纳外存中创建好的进程，把其放入就绪队列，成为就绪状态；

就绪——运行：系统调度就绪队列中的某个进程，获取了cpu资源，从就绪状态到执行状态；

运行——阻塞：在执行进程中，该进程需要从外部设备获取I/O数据，发生阻塞；

运行——就绪：在一个cpu执行周期内，该进程没有执行完，系统调度了其他进程，把该进程放入就绪队列中；

阻塞——就绪：当被阻塞的进程获取到相应的条件（IO事件完成），重新进入到就绪队列；

运行——终止：执行完成、外部干预、程序异常；

### 2.3.3 进程挂起

说起挂起，先了解一下 swaping 交换。 

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnzf1jd0pj30uy0ku15k.jpg" alt="swaping" style="zoom:67%;" />



#### 进程的挂起与激活

##### 进程的挂起

当出现了引起进程挂起的事件时，比如，用户进程请求将自己挂起，或父进程请求将自己的某个子进程挂起，系统将利用挂起原语 suspend( )将指定进程或处于阻塞状态的进程挂起。挂起原语的执行过程是：首先检查被挂起进程的状态，若处于活动就绪状态，便将其改为静止就绪； 对于活动阻塞状态的进程，则将之改为静止阻塞。**==为了方便用户或父进 程考查该进程的运行情况而把该进程的 PCB 复制到某指定的内存区域==**。

<!--处于挂起的时候，只是程序和数据被放到外存了，PCB放在内存中。这样系统才能感知进程状态，改变进程状态。这一个理解非常重要-->

##### 进程的激活过程

当发生激活进程的事件时，例如，父进程或用户进程请求激活指定进程，若该进程驻 留在外存而内存中已有足够的空间时，则可将在外存上处于静止就绪状态的该进程换入内 存。这时，系统将利用激活原语 active( )将指定进程激活。激活原语先将进程从外存调入内 存，检查该进程的现行状态，若是静止就绪，便将之改为活动就绪；若为静止阻塞，便将之改为活动阻塞。假如采用的是抢占调度策略，则每当有新进程进入就绪队列时，应检查 是否要进行重新调度，即由调度程序将被激活进程与当前进程进行优先级的比较，如果被激活进程的优先级更低，就不必重新调度；否则，立即剥夺当前进程的运行，把处理机分配给刚被激活的进程。

#### **进程什么时候会被挂起呢**？

(1) 终端用户的请求。当终端用户在自己的程序运行期间发现有可疑问题时，希望暂时使自己的程序静止下来。亦即，使正在执行的进程暂停执行；若此时用户进程正处于就绪状态而未执行，则该进程暂不接受调度，以便用户研究其执行情况或对程序进行修改。我们把这种静止状态称为挂起状态。 

(2) 父进程请求。有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，或者协调各子进程间的活动。 

(3) 负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。

(4) 操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。

**挂起的本质**

挂起实际上就是把进程从内存中调换到外存中，通过swaping 实现；

### 2.3.4进程七状态

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjnzjfnmauj30v60pq7fs.jpg" alt="进程7状态" style="zoom:67%;" />

增加了就绪挂起、阻塞挂起；



#### 状态转换

就绪<——>就绪挂起：一般，OS挂起阻塞进程，但有时也会挂起就绪进程，释放内存；当某个时刻内存够用，则会把就绪挂起进程转变为就绪

阻塞<——>阻塞挂起：OS通常将阻塞进程换出，以腾出内存空间；当阻塞挂起的进程等待的事件发生时，也会被放入内存，变为block；

阻塞挂起——>就绪挂起：当进程等待的事件发生，可以从阻塞挂起到就绪挂起；



#### **Block vs Supend 挂起**

进程是否等待事件：阻塞与否

进程是否被换出内存：挂起与否

Ready：进程在内存，准备执行

Block：进程在内存，等待事件

Ready、Suspend：进程在外存，等待激活（调入内存）

Block、Suspend：进程在外存，等待事件。



![image-20201014101226368](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjon4c8vguj30fy0a8tc2.jpg)

P 代表进程、实现代表占用、虚线代表请求，p1、p2、p3 这三个进程会处于什么状态？

P1 为running、p2为block、p3为创建



## 2.4 进程控制

进程控制是进程管理中最基本的功能。它用于创建一个新进程，终止一个已完成的进程，或终止一个因出现某事件而使其无法运行下去的进程，还可负责进程运行中的状态转换。如当一个正在执行的进程因等待某事件而暂时不能继续执行时，将其转换为阻塞状态， 而当该进程所期待的事件出现时，又将该进程转换为就绪状态等等。进程控制一般是由 OS的内核中的**原语**来实现的。

一句话：**<u>进程控制负责进程的状态切换、进程创建及销毁，靠os中原语实现的</u>**；

<!--原语这个词是相对的，在操作系统层面，像wrtie、read这种系统指令对于程序员而言是不可分割的，原子性的，但是从系统本身来说，write、read指令也是由多条汇编语言组成，而每个汇编语言又是多个逻辑指令，即二进制的电极信号，这样说我们就明白了。 -->

### 2.4.1 操作系统功能

操作系统os内核一般有两大功能：**<u>支撑功能 、资源管理功能</u>**

#### 支撑功能

- Interrupt handing 中断处理 

  是多道程序系统最基本的功能，是其他活动赖以实现的基础。系统调用、I/O输入、进程调度、设备驱动都会用到中断。（想想，中断在现实生活中的含义）

- Timing 时钟管理 

  基本功能之一，时间片轮转调度中会用到时钟计功能；

- Primitive 原语 ：atomic operation 原子操作（这个原子操作其实也是基于中断实现的，所有锁的机制都是通过这个东西实现的）

  <!-- -->

- Accounting 统计

- Monitoring 监测

#### 资源管理功能

- 进程管理
- 内存管理
- 设备管理
- 文件管理

相关的介绍都在[第一章节](#操作系统作用) 

### 2.4.2 进程创建

[参考](# 「创建状态 )

### 2.4.3 进程终止

[参考](# 「退出/终止状态」)

### 2.4.4 进程阻塞

[参考](#进程阻塞与唤醒 )

### 2.4.5 进程挂起

[参考](#2.3.3 进程挂起 )

### 2.4.6 进程切换 vs 模式切换

![image-20201014154621913](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjowruf0yxj30ee09xafl.jpg)

用户进程切换一定引起模式切换，因为进程切换是os 在内核态提供的原语提供的指令，同时还有调度，这些都是内核态的功能，切换完之后去另一个进程，这样就会涉及模式的切换；但模式切换不一定会引起进程切换，因为从用户态到内核态不一定要新进程。

假如说：系统进程或者内核进程，这种不涉及到用户态的进程会有模式切换吗？

## 2.5 进程同步

主要掌握进程 并发、同步与互斥、死锁与饥饿、临界区；3个金典问题；

多进程系统在使用临界资源时，必须做好协调和同步工作，否则会造成竞争和死锁；

### 2.5.1基本概念

#### 临界资源

同处于一个系统中的进程，通常都共享着某种系统资源，如共 享 CPU、共享 I/O 设备等资源都是临界资源，进程间应采取互斥方式，实现对这种资源的共享。

#### 临界区

在每个进程中访问临界资源的那段代码称为临界区(critical section)。显然， 若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。

临界区前面增加一段用于进行上述检查的代码，把这段代码称为进入区(entry section)。相应 地，在临界区后面也要加上一段称为退出区(exit section)的代码，用于将临界区正被访问的 标志恢复为未被访问的标志。进程中除上述进入区、临界区及退出区之外的其它部分的代 码，在这里都称为剩余区。

```
while (true){
		进入区
		临界区
		退出区
		剩余区
}
```



#### 同步机制遵循的规则

(1) 空闲让进。当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求 进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。

(2) 忙则等待。当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进 入临界区的进程必须等待，以保证对临界资源的互斥访问。

(3) 有限等待。对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区， 以免陷入“死等”状态。

(4) 让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙 等”状态。



### 2.5.2 信号量机制

这个机制由荷兰科学家Dijkstra提出的，其机制为：

**进行代码抽象**

![IMG_5681](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjxwua2i4jj31sk0u04qp.jpg)



把临界资源定义为S，并提供**两个原子操作 Wait（S） 和Signal（S），不能被中断**，其操作如下：

```
wait(S)和 signal(S)操作可描述为：

procedure wait(S) 
		var S：semaphore； 
		begin 
			S.value:=S.value-1； 
			if S.value<0 then block(S.L)；
    end 
//value 表示临界资源可用数量    
procedure signal(S) 
		var S: semaphore； 
		begin 
			S.value:=S.value+1； 
			if S.value<=0 then wakeup(S.L)； 
		end
```

每次 wait 操作，意味着进程请求一个单位的该类资源，使系统中可供分配 的该类资源数减少一个，因此描述为 S.value:=S.value-1；当 S.value<0 时，表示该类资源已 分配完毕，**因此进程应调用 block 原语，进行自我阻塞，放弃处理机，并插入到信号量链表 S.L 中（不像软件、硬件中断出现忙等现象，因为他会进入阻塞状态，不占用processer）**。可见，该机制遵循了“让权等待”准则。此时 S.value 的绝对值表示在该信号量链 表中已阻塞进程的数目。对信号量的每次 signal 操作，表示执行进程释放一个单位资源，使 系统中可供分配的该类资源数增加一个，故 S.value:=S.value+1 操作表示资源数目加 1。若 加 1 后仍是 S.value≤0，则表示在该信号量链表中，仍有等待该资源的进程被阻塞，故还应 调用 wakeup 原语，将 S.L 链表中的第一个等待进程唤醒。**如果 S.value 的初值为 1，表示只允许一个进程访问临界资源，此时的信号量转化为互斥信号量，用于进程互斥。** 这就是用信号量实现进程互斥的原理；如何实现呢？

==我们只需要把 临界区代码 放到 互斥量mutex 的wait（mutex）和 signal（mutex）之间即可，并把互斥量的数量value设置为1。==  这就是实现核心精髓。

> 每个欲访问该临界资源的进程在进入临界区之前，都要先对 mutex 执行 wait 操作，若该资源此刻未被访问，本次 wait 操作必然成功，进程便可进入自己的临界区， 这时若再有其他进程也欲进入自己的临界区，此时由于对 mutex 执行 wait 操作定会失败，因而该进程阻塞，从而保证了该临界资源能被互斥地访问。当访问临界资源的进程退出临 界区后，又应对 mutex 执行 signal 操作，以便释放该临界资源。

假如说，有多个临界资源或者说某个资源的数目满足一定条件，则只需要在if 条件判断时，修改条件即可。

### 2.5.3 管程

由于进程同步很常见，会导致系统中存在很多临界资源，那每个临界资源都各自维护同步操作，带来了管理麻烦。于是用一种面向对象的“封装”的思想，引入管程来管理。它和信号量有同等的表达能力。

定义：

代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源 管理程序，共同构成了一个操作系统的资源管理模块，我们称之为管程。管程被请求和释放 资源的进程所调用。

管程由四部分组成：① 管程的名称；② 局部于管程内部的共享 数据结构说明；③ 对该数据结构进行操作的一组过程；④ 对局部于管程内部的共享数据 设置初始值的语句。

![image-20201020183042006](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvz8nk4oij30df09kq3h.jpg)

特性：

（1） 模块化：管程是一个基本程序单位，可以单独编译。

  (2) 抽象数据类型。管程中不仅有数据，而且有对数据的操作。

  (3) 信息掩蔽。管程中的数据结构只能被管程中的过程访问，这些过程也是在管程内部 定义的，供管程外的进程调用，而管程中的数据结构以及过程(函数)的具体实现外部不可见。

管程和进程不同，主要体现在以下几个方面：

(1) 虽然二者都定义了数据结构，但进程定义的是私有数据结构 PCB，管程定义的是公 共数据结构，如消息队列等；

(2) 二者都存在对各自数据结构上的操作，但进程是由顺序程序执行有关的操作，而管 程主要是进行同步操作和初始化操作；

(3) 设置进程的目的在于实现系统的并发性，而管程的设置则是解决共享资源的互斥使 用问题；

(4) 进程通过调用管程中的过程对共享数据结构实行操作，该过程就如通常的子程序一 样被调用，因而管程为被动工作方式，进程则为主动工作方式；

(5) 进程之间能并发执行，而管程则不能与其调用者并发；

(6) 进程具有动态性，由“创建”而诞生，由“撤销”而消亡，而管程则是操作系统中 的一个资源管理模块，供进程调用。

### **2.5.4 互斥方法**

软件方法 —— 内存中设置一个变量标记临界资源，使用时进行检查该变量，变量为true时表示为可用，否则不可用；缺陷：只能用于两个进程间互斥。或者说某个进程在进行检测和设置时，不能保证原子性；可能多个进程同时检查，同时进入了。

硬件方法

- 屏蔽中断：因为中断是程序调度的基础，所以通过屏蔽中断，不进行调度，达到原子目的。但是系统是多处理器，多个cpu就不适用了。相比软件方法：实现了原子操作，但缺点是代价太大，不能响应中断，如果此时有个高级别的任务则无法响应。
- 特殊机器指令：一个指令周期不产生中断。test-set 、exchange；缺陷：会产生忙等现象。占用资源，却不干事情。

信号量 ：[见上面](#2.5.2 信号量机制)

消息传递：是一种进程通信的方式，见[下面](#2.6 进程通信)。

## 2.6 进程通信

通信机制可归结为三大类： 共享存储器系统、消息传递系统以及管道通信系统。

### 2.6.1 简述

#### 共享存储器系统 Shared-Memory System  

基于共享存储区的通信方式。为了传输大量数据，在存储器中划出了一块共享存储 区，诸进程可通过对共享存储区中数据的读或写来实现通信。

#### 消息传递

应用最为广泛的一种进程间的通信机制。 在该机制中，进程间的数据交换是以格式化的消息(message)为单位的；在计算机网络中， 又把 message 称为报文。程序员直接利用操作系统提供的一组通信命令(原语)，不仅能实现 大量数据的传递，而且还隐藏了通信的实现细节，使通信过程对用户是透明的，从而大大 减化了通信程序编制的复杂性，因而获得了广泛的应用。

> 网络通信都是基于这个原理建立起来的，而这一块的内容又是一整个大块：计算机网络原理。而android 系统中进程间通信也是用的这种方式 Message。

#### 管道通信 pipe

所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享 文件，又名 pipe 文件。向管道(共享文件)提供输入的发送进程(即写进程)，以字符流形式将 大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。 由于发送进程和接收进程是利用管道进行通信的，故又称为管道通信。这种方式首创于 UNIX 系统，由于它能有效地传送大量数据，因而又被引入到许多其它的操作系统中。

#### 客户机-服务器系统

上面三种方式都可以应用于不同计算机之间通信，但是客户机——服务器这种方式更为流行，其实现是 socket 套接字、远程过程（方法）调用。

上述四种方式，重点理解消息传递系统实现的进程间通信。

### 2.6.2 消息传递通信实现

消息传递需要源进程和目标进程，系统要为其提供发送和接收原语。

#### 1 通信方式

直接通信：双方需要显示的知道对方的地址。

间接通信：有可能存在多个发送进程，比如打印请求，多个进程可以发送这个请求。

#### 2 通信链路

为使在发送进程和接收进程之间能进行通信， **必须在两者之间建立一条通信链路 (communication link)。有两种方式建立通信链路。第一种方式是由发送进程在通信之前用显 式的“建立连接”命令(原语)请求系统为之建立一条通信链路；在链路使用完后，也用显式 方式拆除链路。这种方式主要用于计算机网络中。**第二种方式是发送进程无须明确提出建 立链路的请求，只须利用系统提供的发送命令(原语)，系统会自动地为之建立一条链路。这 种方式主要用于单机系统中

#### 3 消息格式

message 包含什么信息；公用的消息头，包含主体消息的消息体；

#### 4 消息缓冲队列

这个东西，也在android 中看到，其实都是差不多的。这个东西的数据结构：

1 消息缓冲区：

```
typed struct message_buffer{
	int sender; //发送者进程标识
	int size;   //消息长度
	char text;  //消息内容
	struct message_buffer next; //下一个消息缓冲区指针
}
```

2 PCB 中新增的消息缓冲队列数据项

```
typedef struct processcontrol_block{
	struct message_buffer mq; 消息队列首指针
	semaphore mutex； 互斥信号量
	semaphore sm 资源信号量
}
```

3 发送原语

下图是 消息缓冲通信示意图：



![image-20201022144725282](https://tva1.sinaimg.cn/large/0081Kckwgy1gjy40ygmnpj30jw0al0tm.jpg)

```
procedure send(receiver，a)
	begin 
		getbuf(a.size,i)； 根据 a.size 申请缓冲区；
		i.sender:= a.sender； 将发送区 a 中的信息复制到消息缓冲区 i 中；
		i.size:=a.size； 
		i.text:=a.text； 
		i.next:=0； 
		getid(PCB set，receiver.j)； 获得接收进程内部标识符； 
		wait(j.mutex)； insert(j.mq，i)； 将消息缓冲区插入消息队列； 
		signal(j.mutex)； 
		signal(j.sm)；
end
```

4 接收原语

```
procedure receive(b)
	begin
  	j:= internal name；  j 为接收进程内部的标识符；
  	wait(j.sm)； 
  	wait(j.mutex)； 
  	remove(j.mq，i)；  将消息队列中第一个消息移出；
  	signal(j.mutex)； 
  	b.sender:=i.sender； 将消息缓冲区 i 中的信息复制到接收区 b；
  	b.size:=i.size； 
  	b.text:=i.text；

end
```



## 2.7 线程

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjoy84ppstj30fn0bz78r.jpg" alt="image-20201014163640010" style="zoom:80%;" />



为了减少程序在并发执行时所付出的时空开销，使 OS 具有更好的并发性，在进程的基础上引入线程；我们知道的进程两个基本属性: **① 进程是一个可拥有资源的独立单位；② 进程同时又是一个可独立调度和分派的基本单位**，使得进程能够独立运行而且并发执行。但是在进程的切换会消耗大量的资源，为了解决这个问题，把上述两个功能分开，引入线程承担第二个功能，进程只是拥有资源的独立单位。以线程作为调度和分派的基本单位，则可以有效地改善多处理机系统的性能。

### 2.7.1 线程vs 进程

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjoy84ppstj30fn0bz78r.jpg" alt="image-20201014163640010" style="zoom:80%;" />

​                                                                                            <!--单线程和多线程模型-->

线程具有许多传统进程所具有的特征，又称为轻型进程(Light-Weight Process)，传统进程相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都拥有若干个线程，至少也有一个线程。

1. 调度

在传统的操作系统中，作为拥有资源的基本单位和独立调度、分派的基本单位都是进程。而在引入线程的操作系统中，则把线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位，把传统进程的两个属性分开，使线程基本上不拥有资源，这样线程便能 轻装前进，从而可显著地提高系统的并发程度。在同一进程中，线程的切换不会引起进程的切换，但从一个进程中的线程切换到另一个进程中的线程时，将会引起进程的切换。 

2. 并发性

在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，使得操作系统具有更好的并发性，从而能更加有效地提高系统资源的利用率和系统的吞吐量。

3. 拥有资源 ：进程拥有资源，线程不拥有资源，但线程可以访问它隶属的进程的资源；
4. 系统开销

在创建或撤消进程时，系统都要为之创建和回收进程控制块，分配或回收资源，如内存空间和 I/O 设备等，操作系统所付出的开销明显大于线程创建或撤消时的开销。类似地，在进程切换时，涉及到当前进程 CPU 环境的保存及新被调度运行进程的 CPU 环境的设置，而线程的切换则仅需保存和设置少量寄存器内容，不涉及存储器管理方面的操作，所以就 切换代价而言，进程也是远高于线程的。此外，由于一个进程中的多个线程具有相同的地址空间，在同步和通信的实现方面线程也比进程容易。在一些操作系统中，线程的切换、 同步和通信都无须操作系统内核的干预。 

### 2.7.2 线程属性

在多线程os 中**（一定是多线程系统）**，一个进程包含多个线程，线程有下面属性：

1. 轻型：不具有系统资源，其组成有TCB 线程控制块，程序计数器，保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈；
2. 独立调度和分派的基本单位。在多线程 OS 中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位
3. 可并发执行。在一个进程中的多个线程之间可以并发执行，甚至允许在一个进程中的所有线程都能并发执行
4. 共享进程资源。在同一进程中的各个线程都可以共享该进程所拥有的资源，这首先表现在所有线程都具有相同的地址空间(进程的地址空间)

### 2.7.3 线程状态

线程的状态和进程一样，可以类比。

在多线程 OS 环境下，应用程序在启动时，通常仅有一个线程在执行，该线程被人们称 为“初始化线程”。它可根据需要再去创建若干个线程。在创建新线程时，需要利用一个线 程创建函数(或系统调用)。

> 这里我们可以想到android，创建了主线程(UI线程)，后面可以在主线程中去创建新的线程，

终止线程的方式有两种：一种是在线程完成了自己的工作后自愿退出；另一种是线程在运行中出现错误或由于某种原因而被其它线程 强行终止。。在大多数的 OS 中，线程被中止后并不立即释放它所占有的资源，只有当进程中的其它线程执行了分离函数后，被终止的线程才与资源分离，此时的资源才能被其它线程利用。

### 2.7.4 多线程OS中的进程

多线程os中，进程时拥有资源的独立单位，但不就不再作为一个执行的实体。是把线程作为独立运行的基本单位， 所以此时的进程已不再是一个可执行的实体。虽然如此，进程仍具有与执行相关的状态。例如，所谓进程处于“执行”状态，实际上是指该进程中的某线程正在执行。此外，对进程所施加的与进程状态有关的操作，也对其线程起作用。例如，在把某个进程挂起时，该进程中的所有线程也都将被挂起；又如，在把某进程激活时，属于该进程的所有线程也都将被激活。 

### 2.7.5 线程实现方式

#### **内核支持线程**

在内核的支持下运行的，即无论是用户进程中的线程，还是系统进程中的线程，他们的创建、撤消和切换等也是依靠内核，在内核空间实现的。此外，在内核空间还为每一个内核支持线程设置了一个线程控制块，内核是根据该控制块而感知某线程的存在，并对其加以控制。

这种线程实现方式主要有如下四个优点：

(1) 在多处理器系统中，内核能够同时调度同一进程中多个线程并行执行；

(2) 如果进程中的一个线程被阻塞了，内核可以调度该进程中的其它线程占有处理器运行，也可以运行其它进程中的线程；

(3) 内核支持线程具有很小的数据结构和堆栈，线程的切换比较快，切换开销小； 

(4) 内核本身也可以采用多线程技术，可以提高系统的执行速度和效率。 

内核支持线程的主要缺点是：对于用户的线程切换而言，其模式切换的开销较大，在同一个进程中，从一个线程切换到另一个线程时，需要从用户态转到内核态进行，这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的，系统开销较大。

#### **用户级线程**

用户级线程 ULT(User Level Threads)仅存在于用户空间中。对于这种线程的创建、撤消、线程之间的同步与通信等功能，都无须利用系统调用来实现。对于用户级线程的切换，通常发生在一个应用进程的诸多线程之间，这时，也同样无须内核的支持。由于这些线程的任务控制块都是设置在用户空间，而线程所执行的操作也无须内核的帮助，因而内核完全不知道用户级线程的存在。

> 对于设置了用户级线程的系统，其调度仍是以进程为单位进行的。在采用轮转调度算法时，各个进程轮流执行一个时间片，这对诸进程而言似乎是公平的。但 假如在进程 A 中包含了一个用户级线程，而在另一个进程 B 中含有 100 个用户级线程，这样，进程 A 中线程的运行时间将是进程 B 中各线程运行时间的 100 倍；相应地，其速度要 快上 100 倍。如果设置的是内核支持线程，则调度以线程为单位，B两个进程获取的时间片是A的100倍，则两个进程运行速度差不多。

**优缺点**

(1) 线程切换不需要转换到内核空间，对一个进程而言，其所有线程的管理数据结构均在该进程的用户空间中，线程管理在用户态完成即可，节省了模式切换带来的消耗。 

(2) 用户级线程的实现与操作系统平台无关，因为对于线程管理的代码是在用户程序内的，属于用户程序的一部分，所有的应用程序都可以对之进行共享。因此，用户级线程甚至可以在不支持线程机制的操作系统平台上实现。 

用户级线程实现方式的主要缺点在于如下两个方面： 

(1) 系统调用的阻塞问题。在基于进程机制的操作系统中，大多数系统调用将阻塞进程，因此，当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的所有线程都会被阻 塞。而在内核支持线程方式中，则进程中的其它线程仍然可以运行。

> 内核线程则不会，因为他们是调度的单位，而用户线程，进程是调度基本单位。

**实现**

用户级线程是在用户空间实现的。所有的用户级线程都具有相同的结构，它们都运行在一个中间系统的上面。当前有两种方式实现的中间系统，即运行时系统和内核控制线程。

1) 运行时系统(Runtime System) 

所谓“运行时系统”，实质上是用于管理和控制线程的函数(过程)的集合，其中包括用于创建和撤消线程的函数、 线程同步和通信的函数以及实现线程调度的函数等。正因为有这些函数，才能使用户级线程与内核无关。运行时系统中的所有函数都驻留在用户空间，并作为用户级线程与内核之间的接口。

 2) 内核控制线程

这种线程又称为轻型进程 LWP(Light Weight Process)。每一个进程都可拥有多个 LWP，同用户级线程一样，每个 LWP 都有自己的数据结构(如 TCB)，其中包括线程标识符、优先级、状态，另外还有栈和局部存储区等。它们也可以共享进程所拥有的资源。LWP 可通过系统调用来获得内核提供的服务，这样，当一个用户级线程运行时，只要将它连接到一个LWP 上，此时它便具有了内核支持线程的所有属性。

在一个系统中的用户级线程数量可能很大，为了节省系统开销，不可能设置太多的LWP，而把这些 LWP 做成一个缓冲池，称为“线程池”。

![image-20201014201117233](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjp4ffged0j30hc08tq3q.jpg)

#### 用户级线程与内核控制线程的连接

在不同的操作系统中，实现用户级线程与内核控制线程的连接有三种不同的模型：一对一模型、多对一模型和多对多模型。 

1) 一对一模型

该模型是为每一个用户线程都设置一个内核控制线程与之连接，当一个线程阻塞时，允许调度另一个线程运行。在多处理机系统中，则有多个线程并行执行。该模型并行能力较强，但每创建一个用户线程相应地就需要创建一个内核线程，开销 较大，因此需要限制整个系统的线程数。

2) 多对一模型

该模型是将多个用户线程映射到一个内核控制线程，为了管理方便，这些用户线程一般属于一个进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完成。当用户线程需要访问内核时，才将其映射到一个内核控制线程上，但每次 只允许一个线程进行映射。 该模型的主要优点是线程管理的开销小，效率高，但当一个线程在访问内核时发生阻 塞，则整个进程都会被阻塞，而且在多处理机系统中，一个进程的多个线程无法实现并行。

3) 多对多模型

该模型结合上述两种模型的优点，将多个用户线程映射到多个内核控制线程，内核控 制线程的数目可以根据应用进程和系统的不同而变化，可以比用户线程少，也可以与之相同。

## 2.8 调度

在多道程序环境下，主存中有着多个进程，其数目往往多于处理机数目。这就要求系统能按某种算法，动态地把处理机分配给就绪队列中的一个进程，使之执行。分配处理机的任务是由处理机调度程序完成的。由于处理机是最重要的计算机资源，提高处理机的利用率及改善系统性能(吞吐量、响应时间)，在很大程度上取决于处理机调度性能的好坏，因而，处理机调度便成为操作系统设计的中心问题之一.

**进程调度和状态转换关系**<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvmnx5hrtj30xg0pegwo.jpg" alt="image-20201020111536419" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvmrbq3kjj30wi0qak2s.jpg" alt="image-20201020111853154" style="zoom:67%;" />

### 2.8.1 长程调度

根据某种算法，**==把外存上处于外存队列中的那些作业选中某个调入内存==**，也就是说，它的调度对象是存在于外存中的作业队列。这时候还没有创建进程，对应的状态转换是：new——Ready/Suspend Ready；发生在内外存之间。就是选择哪个程序进入内存以及有多少程序被调入内存（注意：调入内存的程序不一定是ready态，还要给其分配资源、创建pcb时才能成为ready）；

#### 1．作业和作业步

(1) 作业(Job)。作业是一个比程序更为广泛的概念，它不仅包含了通常的程序和数据， 而且还应配有一份作业说明书，系统根据该说明书来对程序的运行进行控制。在批处理系统中，是以作业为基本单位从外存调入内存的。

(2) 作业步(Job Step)。通常，在作业运行期间，每个作业都必须经过若干个相对独立， 又相互关联的顺序加工步骤才能得到结果，我们把其中的每一个加工步骤称为一个作业步， 各作业步之间存在着相互联系，往往是把上一个作业步的输出作为下一个作业步的输入。例如，一个典型的作业可分成三个作业步：① “编译”作业步，通过执行编译程序对源程序进行编译，产生若干个目标程序段；② “连结装配”作业步，将“编译”作业步所产生的若干个目标程序段装配成可执行的目标程序；③ “运行”作业步，将可执行的目标程序读入内存并控制其运行。

(3) 作业流。若干个作业进入系统后，被依次存放在外存上，这便形形成了输入的作业流；在操作系统的控制下，逐个作业进行处理，于是便形成了处理作业流。 

#### 2. 作业控制块 JCB(Job Control Block) 

同进程控制块PCB一样, 为作业设置了作业控制块用来管理作业, 它是作业在系统中存在的标志，其中保存了

系统对作业进行管理和调度所需的全部信息。在 JCB 中所包含的内容因系统而异，通常应包含的内容有：作业标识、用户名称、用户帐户、作业类型(CPU 繁忙型、I/O 繁忙型、批量型、终端型)、作业状态、调度信息(优先级、作业已运行时间)、资源需求(预计运行时间、 要求内存大小、要求 I/O 设备的类型和数量等)、进入系统时间、开始处理时间、作业完成 时间、作业退出时间、资源使用情况等。 每当作业进入系统时，系统便为每个作业建立一个 JCB，根据作业类型将它插入相应的后备队列中。

#### 3. 作业调度

作业调度的主要功能是根据作业控制块中的信息，==<u>审查系统能否满足用户作业的资源需求</u>==，以及按照一定的算法，==<u>从外存的后备队列中选取某些作业调入内存</u>==，并为它们创建进程、分配必要的资源。然后再将新创建的进程插入就绪队列，准备执行。因此，有时也 把作业调度称为接纳调度(Admission Scheduling)。

<!-- 作业调度也是根据系统资源,比如系统规定的最大程序并发数,来进行接纳调度,有点像swapping 把进程挂起-->

### 2.8.2 中程调度

引入中程调度的主要目的是**<u>为了提高内存利用率和系统吞吐量</u>**。为此，应使那些暂时不能运行的进程不再占用宝贵的内存资源，而将它们调至外存上去等待，把此时的进程状态称为就**<u>绪驻外存状态或挂起状态</u>**。当这些进程重又具备运行条件且内存又稍有空闲时，由中程调度来决定把外存上的那些又具备运行条件的就绪进程重新调入内存，并修改其状态为就绪状态，挂在就绪队列上等待进程调度。中程调度实际上就是存储器管理中的对换功能swapping，

**发生在内外存之间.** **对应的状态转换：Ready——Ready Suspend ；Block —— Block Suspend**

### 2.8.3 短程调度

它所调度的对象是进程(或内核级线程)。进程调度是最基本的一种调度； 对应的状态转换是：Ready——Running， **发生在内存内**

#### 1．短程调度的功能

低级调度用于决定就绪队列中的哪个进程(或内核级线程，为叙述方便，以后只写进程) 应获得处理机，然后再由分派程序执行把处理机分配给该进程的具体操作。

**低级调度的主要功能如下：**

(1) 保存处理机的现场信息。在进程调度进行调度时，首先需要保存当前进程的处理机的现场信息，如程序计数器、多个通用寄存器中的内容等，将它们送入该进程的进程控制块(PCB)中的相应单元。 

(2) 按某种算法选取进程。如优先数算法、轮转法、剩余时间法等，从就绪队列中选取一个进程，把它的状态改为运行状态，并准备把处理机分配给它。 

(3) 把处理器分配给进程。由分派程序(Dispatcher)把处理器分配给进程。此时需为选中的进程恢复处理机现场，即把选中进程的进程控制块内有关处理机现场的信息装入处理器相应的各个寄存器中，把处理器的控制权交给该进程，让它从取出的断点处开始继续运行.

#### 2．进程调度中的三个基本机制

为了实现进程调度，应具有如下三个基本机制：

(1) 排队器。为了提高进程调度的效率，先将所有的就绪进程按照一定的方式排成**<u>一个或多个队列</u>**，以便调度程序能最快地找到它。 

(2) 分派器(分派程序)。分派器把由进程调度程序所选定的进程，从就绪队列中取出该进程，然后进行上下文切换，将处理机分配给它。 

(3) 上下文切换机制。当对处理机进行切换时，会发生两对上下文切换操作。在第一对上下文切换时，操作系统将保存当前进程的上下文，而装入分派程序的上下文，以便分派程序运行；在第二对上下文切换时，将移出分派程序，而把新选进程的 CPU 现场信息装入 到处理机的各个相应寄存器中。

> 应当指出，上下文切换将花去不少的处理机时间，即使是现代计算机，每一次上下文切换大约需要花费几毫秒的时间，该时间大约可执行上千条指令。为此，现在已有通过硬 件(采用两组或多组寄存器)的方法来减少上下文切换的时间。一组寄存器供处理机在系统态时使用，另一组寄存器供应用程序使用。在这种条件下的上下文切换只需改变指针，使其 指向当前寄存器组即可。

#### 3．进程调度方式

进程调度可采用下述两种调度方式。

**1) 非抢占方式(Nonpreemptive Mode)** 

在采用这种调度方式时，一旦把处理机分配给某进程后，不管它要运行多长时间，都一直让它运行下去，决不会因为时钟中断等原因而抢占正在运行进程的处理机，也不允许其它进程抢占已经分配给它的处理机。直至该进程完成，自愿释放处理机，或发生某事件而被阻塞时，才再把处理机分配给其他进程。

在采用非抢占调度方式时，可能引起进程调度的因素可归结为如下几个： 

**(1)** 正在执行的进程执行完毕，或因发生某事件而不能再继续执行；

**(2)** 执行中的进程因提出 I/O 请求而暂停执行；

**(3)** 在进程通信或同步过程中执行了某种原语操作，如 P 操作(wait 操作)、Block 原语、 Wakeup 原语等。 



**2) 抢占方式(Preemptive Mode)** 

这种调度方式允许调度程序根据某种原则去暂停某个正在执行的进程，将已分配给该进程的处理机重新分配给另一进程。抢占方式的优点是，可以防止一个长进程长时间占用处理机，能为大多数进程提供更公平的服务，特别是能满足对响应时间有着较严格要求的 实时任务的需求。但抢占方式比非抢占方式调度所需付出的开销较大。抢占调度方式是基于一定原则的，

(1) 优先权原则。通常是对一些重要的和紧急的作业赋予较高的优先权。当这种作业到 达时，如果其优先权比正在执行进程的优先权高，便停止正在执行(当前)的进程，将处理机分配给优先权高的新到的进程，使之执行；或者说，允许优先权高的新到进程抢占当前进程的处理机。

(2) 短作业(进程)优先原则。当新到达的作业(进程)比正在执行的作业(进程)明显的短时，将暂停当前长作业(进程)的执行，将处理机分配给新到的短作业(进程)，使之优先执行；或者说，短作业(进程)可以抢占当前较长作业(进程)的处理机。

(3) 时间片原则。各进程按时间片轮流运行，当一个时间片用完后，便停止该进程的执行而重新进行调度。这种原则适用于分时系统、大多数的实时系统，以及要求较高的批处理系统。

#### 4 发生时机

时钟中断、IO中断、系统请求、信号发生

---

总结：

> 搞、中、低是以调度频率起名的, 进程最频繁、其次内存、最后作业. 而且他们面对的对象也不一样, 都是计算机中最重要的进程、内存、作业这样的对象.

在上述三种调度中，进程调度的运行频率最高，在分时系统中通常是 10～100 ms 便进行一次进程调度，因此把它称为短程调度。为避免进程调度占用太多的 CPU 时间，进程调度算法不宜太复杂。作业调度往往是发生在一个(批)作业运行完毕，退出系统，而需要重新调入一个(批)作业进入内存时，故作业调度的周期较长，大约几分钟一次，因此把它称为长程调度。由于其运行频率较低，故允许作业调度算法花费较多的时间。中级调度的运行频 率基本上介于上述两种调度之间，因此把它称为中程调度。

### 2.8.4 调度队列和准则

#### 1. 仅有进程调度的调度队列模型

在分时系统中，常把就绪进程组织成 FIFO 队列形式。每当 OS 创建一个新进程时，便将它挂 在就绪队列的末尾，然后按时间片轮转方式运行。

每个进程在执行时都可能出现以下三种情况： 

(1) 任务在给定的时间片内已经完成，该进程便在释放处理机后进入完成状态； 

(2) 任务在本次分得的时间片内尚未完成，OS 便将该任务再放入就绪队列的末尾； 

(3) 在执行期间，进程因为某事件而被阻塞后，被 OS 放入阻塞队列。

![image-20201016183355362](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd1yyrp0j30jy07fmxs.jpg)

#### 2．具有高级和低级调度的调度队列模型

在批处理系统中，不仅需要进程调度，而且还需有作业调度，由后者按一定的作业调度算法，从外存的后备队列中选择一批作业调入内存，并为它们建立进程，送入就绪队列，然 后才由进程调度按照一定的进程调度算法选择一个进程，把处理机分配给该进程。图 3-2 示 出了具有高、低两级调度的调度队列模型。该模型与上一模型的主要区别在于如下两个方面。

(1) 就绪队列的形式。在批处理系统中，最常用的是最高优先权优先调度算法，相应地， 最常用的就绪队列形式是优先权队列。进程在进入优先级队列时，根据其优先权的高低，被插入具有相应优先权的位置上，这样，调度程序总是把处理机分配给就绪队列中的队首进程。

![image-20201016183601081](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd1wqlwwj30oy0bjdgv.jpg)

(2) 设置多个阻塞队列。对于小型系统，可以只设置一个阻塞队列；但当系统较大时， 若仍只有一个阻塞队列，其长度必然会很长，队列中的进程数可以达到数百个，这将严重影响对阻塞队列操作的效率。故在大、中型系统中通常都设置了若干个阻塞队列，每个队 列对应于某一种进程阻塞事件。 

#### 3．同时具有三级调度的调度队列模型

在 OS 中引入中级调度后，人们可把进程的就绪状态分为内存就绪(表示进程在内存中就绪)和外存就绪(进程在外存中就绪)。类似地，也可把阻塞状态进一步分成内存阻塞和外存阻塞两种状态。在调出操作的作用下，可使进程状态由内存就绪转为外存就绪，由内 存阻塞转为外存阻塞；在中级调度的作用下，又可使外存就绪转为内存就绪.

![image-20201016183747798](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrd2gmsp5j30nh0cqt9x.jpg)

#### 4. 调度算法选择准则

在一个操作系统的设计中，应如何选择调度方式和算法，在很大程度上取决于操作系统的类型及其目标。选择调度方式和算法的准则，有的是面向用户的，有的是面向系统的。

##### 面向用户

(1) 周转时间短: 通常把周转时间的长短作为评价批处理系统的性能、选择作业调度方式与算法的重要准则之一。所谓周转时间，是指从作业被提交给系统开始，到作业完成为 止的这段时间间隔(称为作业周转时间)。

(2) 响应时间快: 是选择分时系统中进程调度算法的重要准则之一。所谓响应时间，是从用户通过键盘提交一个请求开始，直至系统首次产生响应为止的时间

(3) 截止时间的保证。这是评价实时系统性能的重要指标，因而是选择实时调度算法的重要准则。

(4) 优先权准则。在批处理、分时和实时系统中选择调度算法时，都可遵循优先权准则，以便让某些紧急的作业能得到及时处理。

##### 面向系统的准则

(1) 系统吞吐量高: 指在单位时间内系统所完成的作业数

(2) 处理机利用率好: 因为cpu资源很宝贵, 要多利用cpu资源,尽量不让其空闲, 

(3) 各类资源的平衡利用: 在大、中型系统中，不仅要使处理机的利用率高，而且还应 能有效地利用其它各类资源，如内存、外存和 I/O 设备等。选择适当的调度方式和算法可以 保持系统中各类资源都处于忙碌状态。但对于微型机和某些实时系统而言，该准则并不重要。

### 2.8.5 调度算法

调度的实质是一种资源分配，因而调度算法是指：根据系统的资源分配策略所 规定的资源分配算法。对于不同的系统和系统目标，通常采用不同的调度算法。

#### 1 先来先服务 FCFS 和 短作业(进程)优先调度算法

##### 先来先服务 FCFS —— first come first server

先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也 可用于进程调度。FCFS 算法比较有利于长作业(进程)，而不利于短作业(进程)。FCFS 调度算法有利于 CPU 繁忙型的作业，而 不利于 I/O 繁忙型的作业(进程)。CPU 繁忙型作业是指该类作业需要大量的 CPU 时间进行 计算，而很少请求 I/O。通常的科学计算便属于 CPU 繁忙型作业。I/O 繁忙型作业是指 CPU 进行处理时需频繁地请求 I/O。目前的大多数事务处理都属于 I/O 繁忙型作业。

> 当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一 个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放 入就绪队列。在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进 入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件 而阻塞后才放弃处理机。
>
> 后面的调度算法，都可以参考这个定义来去看，比如短作业调度

##### 短作业(进程)优先调度算法 SJF——short job first

短作业(进程)优先调度算法 SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以 分别用于作业调度和进程调度。

SJ(P)F 调度算法也存在不容忽视的缺点：

(1) 该算法对长作业不利，更严重的是，如果有一长作业(进程)进入系统的后备队列(就绪队列)，由于调度程序 总是优先调度那些(即使是后进来的)短作业(进程)，将导致长作业(进程)长期不被调度。

(2) 该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业(进程)会被及时处理。

(3) 由于作业(进程)的长短只是根据用户所提供的估计执行时间而定的，而用户又可能 会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先 调度。

#### 2 高优先权调度

##### a 优先权调度算法的类型

根据进程、作业的优先级按顺序调度。算法分成如下两种：

1) 非抢占式优先权算法

系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便 一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机 重新分配给另一优先权最高的进程。用于批处理系统，或实时性不严的情况；

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执 行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原 优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。用于要求严格的实时系统；

##### b 优先权类型

对于最高优先权优先调度算法，其关键在于：它是使用静态优先权，还是用动态优先 权，以及如何确定进程的优先权。

- 静态：静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。
- 动态：动态优先权是指在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间 的增加而改变的，以便获得更好的调度性能。例如，我们可以规定，在就绪队列中的进程， 随其等待时间的增长，其优先权以速率 a 提高。

##### C 高响应比优先调度算法

在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业 的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先 级随着等待时间的增加而以速率 a 提高，则长作业在等待一定的时间后，必然有机会分配 到处理机。该优先权的变化规律可描述为：

![image-20201020104024760](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvlnaiouij30ax01yjrf.jpg)

#### 3 基于时间片的轮转调度算法

##### 1．时间片轮转法

1) 基本原理

在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列， 每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到 几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号 来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中 新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一 给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应 所有用户的请求。

2) 时间片大小的确定

在时间片轮转算法中，时间片的大小对系统性能有很大的影响，如选择很小的时间片 将有利于短作业，因为它能较快地完成，但会频繁地发生中断、进程上下文的切换，从而 增加系统的开销；反之，如选择太长的时间片，使得每个进程都能在一个时间片内完成， 时间片轮转算法便退化为 FCFS 算法，无法满足交互式用户的需求。一个较为可取的大小是， 时间片略大于一次典型的交互所需要的时间。这样可使大多数进程在一个时间片内完成。

##### 2. 多级反馈队列调度

**多级反馈 = FCFS + 多级就绪队列（每个队列的时间片时间不一样，依次递增；优先级依次降低）**

应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高， 第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片 的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例 如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第 i+1 个队列的时间片要 比第 i 个队列的时间片长一倍。

![image-20201020104833949](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjvlvrwz0wj30f007z0tb.jpg)

当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待 调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一 个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第 三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第 n 队列后，在第 n 队列中便采取按时间片轮转的方式运行。

仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1)队 列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时， 又有新进程进入优先权较高的队列(第 1～(i-1)中的任何一个队列)，则此时新进程将抢占正 在运行进程的处理机，即由调度程序把正在运行的进程放回到第 i 队列的末尾，把处理机分 配给新到的高优先权进程。

### 2.8.6  实时调度

可以按不同方式对实时调度算法加以分类

- 根据实时任务（截止时间）性质的不同，
  - 硬实时调度算法：必须满足；
  - 软实时调度算法：尽最大努力；
- 周期性
  - 周期和非周期（非周期连着一个deadline）
- 按调度方式的不同，又可分为非抢占调度算法和抢占调度算法； 还可因调度程序调度时间的不同而分成静态调度算法和动态调 度算法，前者是指在进程执行前，调度程序便已经决定了各进程间的执行顺序，而后者则 是在进程的执行过程中，由调度程序届时根据情况临时决定将哪一进程投入运行。





# 第三章 存储管理



# 第四章 设备管理



# 第五章 文件管理